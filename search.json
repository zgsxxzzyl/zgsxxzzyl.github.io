[{"title":"ANTLR参考","url":"/2020/06/18/ANTLR%E5%8F%82%E8%80%83/","content":"概述ANTLR（ANother Tool for Language Recognition 另一种语言识别工具）是功能强大的解析器生成器，用于读取，处理，执行或翻译结构化文本或二进制文件。它被广泛用于构建语言，工具和框架。ANTLR通过语法生成可以构建和遍历语法树的语法分析器。（转自官方）\n下载：https://www.antlr.org/download.html\n文档：https://github.com/antlr/antlr4/blob/master/doc/index.md\nIDE插件：https://www.antlr.org/tools.html\n官方教程：https://github.com/antlr/antlr4/blob/master/doc/getting-started.md\n流程\nANTLR定义一个g4的文件类型，编写语法规则文件。\ng4文件是ANTLR生成词法解析规则和语法解析规则的基础。\n\n使用工具生成解析代码。\n\n依赖生成的解析代码实现自己的功能。\n\n\n一. 创建g4文件简单例子在一个临时目录下创建Hello.g4文件。在文件中写入以下内容：\n&#x2F;&#x2F; Define a grammar called Hellogrammar Hello;r  : &#39;hello&#39; ID ;         &#x2F;&#x2F; match keyword hello followed by an identifierID : [a-z]+ ;             &#x2F;&#x2F; match lower-case identifiersWS : [ \\t\\r\\n]+ -&gt; skip ; &#x2F;&#x2F; skip spaces, tabs, newlines\n\n注意：定义语法名称需要首字母大写，因为生成的文件和类命名会使用到\n二. 生成解析器1. 安装工具2. 执行命令antlr4 Hello.g4\n\n三. 解析器源码依赖&lt;dependency&gt;  &lt;groupId&gt;org.antlr&lt;/groupId&gt;  &lt;artifactId&gt;antlr4&lt;/artifactId&gt;  &lt;version&gt;4.8&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt;  &lt;groupId&gt;org.antlr&lt;/groupId&gt;  &lt;artifactId&gt;antlr4-runtime&lt;/artifactId&gt;  &lt;version&gt;4.8&lt;/version&gt;&lt;/dependency&gt;\n\n代码\n&lt;Grammar&gt;Lexer.java: 词法分析器源码；\n&lt;Grammar&gt;Parser.java: 语法分析器源码；\n&lt;Grammar&gt;Listener.java: Listener 接口；\n&lt;Grammar&gt;BaseListener.java: Listener 默认实现；\n&lt;Grammar&gt;Visitor.java: Visitor 接口；\n&lt;Grammar&gt;BaseVisitor.java: Visitor 默认实现；\n\n如何使用：\npublic static void main(String[] args) throws Exception &#123;    //代码流    ANTLRInputStream input = new ANTLRInputStream(\"int a = 12; \");    //使用词法分析器生成Token序列    Java8Lexer lexer = new Java8Lexer(input);    CommonTokenStream tokens = new CommonTokenStream(lexer);    //使用语法分析器将Token序列串联成AST    Java8Parser parser = new Java8Parser(tokens);    ParseTree tree = parser.expressionName();    //Visito模式或者Listener模式遍历AST    System.out.println(\"Visitor:\");    Java8Visitor evalByVisitor = new Java8BaseVisitor();    evalByVisitor.visit(tree);    //Listener模式遍历AST    System.out.println(\"Listener:\");    ParseTreeWalker walker = new ParseTreeWalker();    Java8Listener evalByListener = new Java8BaseListener();    walker.walk(evalByListener, tree);&#125;\n\n辅助工具","tags":["Java"]},{"title":"Docker中安装部署MySQL","url":"/2019/10/24/Docker%E4%B8%AD%E5%AE%89%E8%A3%85%E9%83%A8%E7%BD%B2MySQL/","content":"Docker中安装部署MySQL安装启动\n参考文档\n安装前要选择安装版本，访问官方链接，找到适合的版本，这里我选择5.7版本\n\n# 拉去mysql镜像 docker pull mysql/mysql-server:tagdocker pull mysql/mysql-server:5.7# 查看是否全部镜像docker images# 选择镜像，启动容器 docker run --name=container_name -d image_name:tag# -d 后台启动 -p 容器3306端口映射外部端口3308 --name 给容器实例命名mysql5.7# docker run -p 3346:3306 --name mysql-slave4 -e MYSQL_ROOT_PASSWORD=123456 -d mysql:5.7docker run --name=mysql5.7 -p 3308:3306 -d mysql/mysql-server:5.7# 容器启动过程中会重新初始化数据库，生成随机密码，查看容器启动日志docker logs mysql5.7 2&gt;&amp;1 | grep GENERATED# 登录数据库docker exec -it mysql5.7 mysql -uroot -p# 改密码ALTER USER 'root'@'localhost' IDENTIFIED BY 'password';# 默认mysql的root用户不支持远程访问，开启访问权限GRANT ALL ON *.* TO root@'%' IDENTIFIED BY 'password' WITH GRANT OPTION;flush privileges;# 进入dockerdocker exec -it mysql5.7 bash# 容器mysql部署路径cd /var/lib/mysql#启动、重启、停止、删除容器docker start mysql5.7docker restart mysql5.7docker stop mysql5.7docker rm mysql5.7\n\n容器挂载本地配置和数据目录docker run --name=mysql5.7 \\--mount type=bind,src=/opt/mysql.docker/my.cnf,dst=/etc/my.cnf \\--mount type=bind,src=/opt/mysql.docker/datadir,dst=/var/lib/mysql \\-p 3308:3306 \\-d mysql/mysql-server:5.7\n","tags":["Docker","MySQL","数据库","部署文档"]},{"title":"Docker安装部署","url":"/2019/10/23/Docker%E5%AE%89%E8%A3%85%E9%83%A8%E7%BD%B2/","content":"Docker安装部署\n官方文档\n\nLinux环境下部署\n卸载旧版本\n\nsudo yum remove docker \\                  docker-client \\                  docker-client-latest \\                  docker-common \\                  docker-latest \\                  docker-latest-logrotate \\                  docker-logrotate \\                  docker-engine\n\n\n在新主机上首次安装Docker Engine-Community之前，需要设置Docker存储库。\n\nsudo yum install -y yum-utils \\  device-mapper-persistent-data \\  lvm2\n\nsudo yum-config-manager \\    --add-repo \\    https://download.docker.com/linux/centos/docker-ce.repo\n\n\n安装\n\nsudo yum install -y docker-ce docker-ce-cli containerd.io\n\n\n启动\n\nsudo systemctl start docker\n\n\n卸载\n\n# 卸载Docker软件包：sudo yum remove docker-ce# 主机上的映像，容器，卷或自定义配置文件不会自动删除。要删除所有图像，容器和卷：sudo rm -rf &#x2F;var&#x2F;lib&#x2F;docker\n","tags":["Docker","部署文档"]},{"title":"Docker常用命令","url":"/2019/10/22/Docker%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/","content":"Docker常用命令\n官方文档\n\n启动docker进程systemctl start docker\n\n搜索可用镜像docker search xxNAME           # 镜像仓库DESCRIPTION    # 镜像描述信息STARS          # 镜像收藏数OFFICIAL       # 是否为docker官方发布的镜像AUTOMATED      # 是否为自动化构建的镜像，关于自动化构建，可以查看官方文档：https://docs.docker.com/docker-hub/builds/#how-automated-builds-work\n拉去镜像docker pull [OPTIONS] NAME[:TAG|@DIGEST]\n列出本地全部镜像docker images\n查看镜像的详情docker inspect [OPTIONS] NAME|ID [NAME|ID...]docker image inspect nginx:latest | grep -i version\n\n删除镜像docker rmi [OPTIONS] IMAGE [IMAGE...]\n基于镜像创建并启动容器docker run [OPTIONS] IMAGE [COMMAND] [ARG...]-d, --detach                         Run container in background and print container ID-t, --tty                            Allocate a pseudo-TTY-p, --publish list                   Publish a container's port(s) to the host-P, --publish-all                    Publish all exposed ports to random ports#基于镜像启动容器实例docker run -t -i IMAGE /bin/bash\n删除容器docker rm [OPTIONS] CONTAINER [CONTAINER...]\n启动容器docker start [OPTIONS] CONTAINER [CONTAINER...]\n查看启动容器日志Usage:  docker logs [OPTIONS] CONTAINERFetch the logs of a containerOptions:      --details        Show extra details provided to logs  -f, --follow         Follow log output      --since string   Show logs since timestamp (e.g. 2013-01-02T13:23:37) or relative (e.g. 42m for 42 minutes)      --tail string    Number of lines to show from the end of the logs (default \"all\")  -t, --timestamps     Show timestamps      --until string   Show logs before a timestamp (e.g. 2013-01-02T13:23:37) or relative (e.g. 42m for 42 minutes)\n# 查看容器近30分钟日志docker logs --since 30m CONTAINER_ID# 查看某时间之后的日志docker logs -t --since=\"2019-08-02T13:23:37\" CONTAINER_ID# 查看某时间段日志：docker logs -t --since=\"2019-08-02T13:23:37\" --until \"2019-08-03T12:23:37\" CONTAINER_ID\n\n查看启动的实例docker ps [OPTIONS]-a, --all             Show all containers (default shows just running)\n修改容器端口映射# 直接修改配置文件/var/lib/docker/containers/[CONTAINER ID]/config.v2.json# 容器3306端口映射到外部3310端口docker run -dit --privileged -p 3310:3306 --name=CONTAINNAME IMAGE /usr/sbin/init\n进入容器docker exec -it [CONTAINER ID] bashdocker exec -it [CONTAINER ID] /bin/sh\n导入导出容器docker export [imagename] &gt; [url]docker import [url] &gt; [imagename]\n\n拷贝docker cp [OPTIONS] CONTAINER:SRC_PATH DEST_PATHdocker cp [OPTIONS] SRC_PATH CONTAINER:DEST_PATH\n\n基于容器创建镜像docker commit containid imagename\n\n挂载目录docker run -v &lt;host&gt;:&lt;container&gt;:[rw|ro]\n\n历史记录docker run -di \\--name=tomcat8081 \\-p 8081:8080 \\-v /opt/tomcat.docker/tomcat8081/logs:/usr/local/tomcat/logs \\-v /opt/tomcat.docker/tomcat8081/conf:/usr/local/tomcat/conf \\-v /opt/tomcat.docker/tomcat8081/webapps:/usr/local/tomcat/webapps \\tomcat:8.5-jdk8\n","tags":["Docker"]},{"title":"Fork/Join框架详细介绍","url":"/2020/04/13/Fork-Join%E6%A1%86%E6%9E%B6%E8%AF%A6%E7%BB%86%E4%BB%8B%E7%BB%8D/","content":"\nhttps://docs.oracle.com/javase/tutorial/essential/concurrency/forkjoin.html\n\n前言理解这个框架前，我们需要知道这个框架设计的目标是为了解决什么问题？\n为什么不可以用已有的框架来解决？\n举例说明：对一个数组进行求和操作，如果这个数组非常大，我们会选择分段求和最后汇总\n\n上图所示，0-999表示数组的下标，如果使用ThreadPoolExecutor创建线程池，可以考虑一下分割成上面的任务需要多少个线程。这里需要用到7个线程来实现求和，如果再分割多次，最后需要的线程会很多，显然不是我们所想要的。\n为了满足我们的需求，Java从JDK7开始引入了Fork/Join框架来解决这类问题，利用多个处理器，是为可以递归分解为较小部分的工作而设计的。目标是使用所有可用的处理能力来增强应用程序的性能。\nFork/Join是ExecutorService接口的实现（这个接口用来实现线程池的，譬如我们常用的ThreadPoolExecutor），与其他实现ExecutorService的线程池一样，Fork/Join框架将任务分配给线程池中的工作线程。\n与其他线程池不同的是，它使用了工作窃取算法（work-stealing），工作用尽的工作线程可以从其他仍很忙的线程中窃取任务。举个例子，0-499这个线程的子线程都计算完了，500-999子线程还在计算500-749，如果0-499这个线程等待500-999这个线程返回结果再去汇总这样会浪费资源，工作窃取算法会使执行0-499这个线程执行750-999，这样可以提高效率。\nFork/Join核心类\nForkJoinPool\n\nForkJoinTask\n\nRecursiveAction\n\nRecursiveTask\n\n\n","tags":["Java"]},{"title":"Git常用命令","url":"/2019/10/22/Git-%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/","content":"Git配置SSH key\n相关：https://blog.csdn.net/hao495430759/article/details/80673568\n\n(1)生成并部署SSH key安装好Git客户端后，打开git bash，输入以下命令生成user1的SSH Key：\nssh-keygen -t rsa -C \"user1@email.com\"\n\n在当前用户的.ssh目录下会生成id_rsa私钥文件和id_rsa.pub公钥文件，将id_rsa.pub中的内容添加至user1的github中。然后在git bash中输入以下命令测试该用户的SSH密钥是否生效：\nssh -T git@github.com\n\n若连接成功则提示Hi user1! You’ve successfully authenticated, but GitHub does not provide shell access.\n注：该命令仅限于文件名为id_rsa的密钥。\n接着生成user2的密钥，注意不能再使用默认的文件名id_rsa，否则会覆盖之前密钥文件：\nssh-keygen -t rsa -f ~/.ssh/id_rsa2 -C \"user2@email.com\"\n\n再将该用户的公钥文件添加至github中。测试user2的ssh连接时需要指定密钥文件：\nssh -T git@github.com -i ~/.ssh/id_rsa2\n\n也可以使用ssh agent添加密钥后进行测试。因为系统默认只读取id_rsa，为了让ssh识别新的私钥，可以使用ssh-agent手动添加私钥：\nssh-agent bashssh-add ~/.ssh/id_rsa2\n\n注：该方法仅限当前窗口有效，打开新的窗口则ssh连接失败。\n(2)配置config文件在.ssh目录下创建一个config文本文件，每个账号配置一个Host节点。主要配置项说明：\nHost    主机别名HostName    服务器真实地址IdentityFile    私钥文件路径PreferredAuthentications    认证方式User    用户名\n\n配置文件内容\n# 配置user1Host u1.github.comHostName github.comIdentityFile C:\\\\Users\\\\Administrator\\\\.ssh\\\\id_rsaPreferredAuthentications publickeyUser user1# 配置user2Host u2.github.comHostName github.comIdentityFile C:\\\\Users\\\\Administrator\\\\.ssh\\\\id_rsa2PreferredAuthentications publickeyUser user2\n\n再通过终端测试SSH Key是否生效\nssh -T git@u1.github.comssh -T git@u2.github.com\n\n(3)配置用户名和邮箱如果之前配置过全局的用户名和邮箱，需要取消相关配置，再在各仓库下配置相应的用户名和邮箱。\ngit config --global --unset user.namegit config --global --unset user.email\n\n为各仓库单独配置用户名和邮箱\ngit config user.name \"user1\"git config user.email \"user1@email.com\"\n\n如果原先使用HTTPS通信，则需要修改远程仓库地址\ngit remote rm origingit remote add origin git@u1.github.com:xxx/xxxxx.git\n\n操作命令\n从远端合并代码到本地\n\n# 1.配置上游地址(只需要一次)git remote add upstream 你上游项目的地址# 2.获取上游更新git fetch upstream# 3.合并到本地分支git merge upstream/master# 4.提交推送git push origin master\n\n\n首次配置git时候测试连接\n\nssh -T git@192.168.99.168\n\n\n生成密钥\n\ngit config –global user.name ‘username’git config –global user.email ‘example@email.com'ssh-keygen -t rsa -C 'example@email.com'\n\n\n撤销上次commit\n\n# 注意，仅仅是撤回commit操作，写的代码仍然保留。git reset --soft HEAD^\nGit中文乱码解决git status不能显示中文\n现象status查看有改动但未提交的文件时总只显示数字串，显示不出中文文件名，非常不方便。如下图：\n\n原因在默认设置下，中文文件名在工作区状态输出，中文名不能正确显示，而是显示为八进制的字符编码。\n\n解决办法将git 配置文件 core.quotepath项设置为false。 quotepath表示引用路径，加上–global表示全局配置\n\n\ngit bash 终端输入命令：\ngit config --global core.quotepath false\n\n通过修改配置文件来解决中文乱码[gui]encoding = utf-8# 代码库统一使用utf-8[i18n]commitencoding = utf-8# log编码[svn]pathnameencoding = utf-8# 支持中文路径[core]quotepath = false# status引用路径不再是八进制（反过来说就是允许显示中文了）\n","tags":["Git"]},{"title":"GitLab安装部署","url":"/2019/12/31/GitLab%E5%AE%89%E8%A3%85%E9%83%A8%E7%BD%B2/","content":"安装部署\nhttps://docs.gitlab.com/omnibus/manual_install.html\n\n\n配置ssh免密之后发现还是需要输入密码\n网上的说法是：rpm安装过程当中会创建git用户，但是这个用户处在锁定状态，用下面这个命令解锁\n# 解锁sudo passwd -u -f git# 查看所有账号cat /etc/passwd# 查看xxx账户状态，是否被锁定passwd -S xxx# 锁定xxx账号usermod -L xxx\n\nGitLab钩子\n\nhttps://docs.gitlab.com/ee/administration/custom_hooks.html\n\n/var/opt/gitlab/git-data/repositories//opt/gitlab/embedded/service/gitlab-shell/hooks\n\n汉化\n\nhttps://gitlab.com/xhang/gitlab/-/wikis/home\n\n# 获取当前版本，版本可能不一致gitlab_version=$(sudo cat /opt/gitlab/embedded/service/gitlab-rails/VERSION)# 克隆汉化版本库git clone https://gitlab.com/xhang/gitlab.git# 如果已经克隆过，则进行更新git fetch# 导出gitlab_version版本的汉化补丁git diff v$&#123;gitlab_version&#125; v$&#123;gitlab_version&#125;-zh &gt; ../$&#123;gitlab_version&#125;-zh.diff# 停止 gitlabsudo gitlab-ctl stop# 如果patch命令不存在 yum install -y patchsudo patch -d /opt/gitlab/embedded/service/gitlab-rails -p1 &lt; $&#123;gitlab_version&#125;-zh.diff# 停止gitlabsudo gitlab-ctl stopsudo gitlab-ctl startsudo gitlab-ctl reconfigure\n\n\n","tags":["部署文档","GitLab"]},{"title":"GitLab配置启动HTTPS","url":"/2019/10/22/GitLab%E9%85%8D%E7%BD%AE%E5%90%AF%E5%8A%A8HTTPS/","content":"#gitlab配置启用httpsopenssl genrsa -des3 -out /etc/gitlab/ssl/gitlab.com.key 2048openssl rsa -in certificate_before.key -out certificate_after.keyopenssl req -x509 -nodes -days 365 -newkey rsa:2048 -keyout /etc/gitlab/ssl/gitlab.com.key -out /etc/gitlab/ssl/gitlab.com.crtfirewall-cmd --permanent --add-service=httpssystemctl reload firewalldgitlab-ctl reconfigure\n","tags":["部署文档","GitLab"]},{"title":"HttpComponents组件介绍","url":"/2020/01/16/HttpComponents%E7%BB%84%E4%BB%B6%E4%BB%8B%E7%BB%8D/","content":"HttpComponents概述超文本传输协议（HTTP）可能是当今Internet上使用的最重要的协议。Web服务，具有网络功能的设备以及网络计算的增长继续将HTTP协议的作用扩展到用户驱动的Web浏览器之外，同时增加了需要HTTP支持的应用程序的数量。\nHttpComponents是为扩展而设计的，同时提供了对基本HTTP协议的强大支持，对于构建HTTP感知的客户端和服务器应用程序（例如Web浏览器，Web Spider，HTTP代理，Web服务传输库或利用或扩展HTTP协议以进行分布式通信。\nHttpCore\n是一组低级HTTP传输组件，可用于以最小的占用空间构建自定义客户端和服务器端HTTP服务。HttpCore支持两种I/O模型：基于经典Java I/O的阻塞I/O模型和基于Java NIO的非阻塞事件驱动的I/O模型。\n阻塞I/O模型可能更适合于数据密集型低延迟方案，而非阻塞模型可能更适合于高延迟方案，在原始数据吞吐量中，原始数据吞吐量的重要性不如处理数千个同时HTTP连接的能力。资源高效的方式。\n\n\nHttpCore教程HTML / PDF\nHttpCore 示例\n\nHttpClient\n是基于HttpCore的HTTP/1.1兼容HTTP代理实现。它还为客户端身份验证，HTTP状态管理和HTTP连接管理提供了可重用的组件。HttpComponents Client是Commons HttpClient 3.x的继承者和替代者。强烈建议Commons HttpClient用户进行升级。\n\n\nHttpClient教程HTML / PDF\nHttpClient 示例\n\nAsynch HttpClient\n是基于HttpCore NIO和HttpClient组件的HTTP/1.1兼容HTTP代理实现。它是Apache HttpClient的补充模块，适用于特殊情况，在特殊情况下，就原始数据吞吐量而言，处理大量并发连接的能力比性能更为重要。\n\n\nHttpAsyncClient 示例\n\n","tags":["Java"]},{"title":"IDEA实用技能","url":"/2020/07/17/IDEA%E5%AE%9E%E7%94%A8%E6%8A%80%E8%83%BD/","content":"查询依赖关系\n近期处理一个模块比较多的项目，存在多个模块引用不同版本的依赖，抱着精简的心态，我们来处理一下\n\n查看依赖有很多种方式：\n\n查看项目的全部依赖\n\n\n\n查看指定模块的依赖\n\n\n但是在第一种的情况下，我们想知道是哪个模块引用的该怎么办？\n\n在指定模块右键或F12打开设置\n\n\n\n通过查看依赖设置我们可以知道这个依赖的具体保存位置\n\n\n\n在我们查询的依赖上右键，Find Usages或者直接Ctrl+G，我们就看到了这个依赖是哪个项目引用的\n\n\n\n\n接下来我们看一下引用关系，在maven找到这个模块，Show Dependencies\n\n\n\n我们就看到了\n\n\n\n在这个地方我们可以方便的解决依赖冲突，找了一个存在依赖的模块\n\n\n\n我们看到Jackson-annotations这个依赖冲突，只需要在指定的依赖后右键Exclude\n\n\n\n我们排除的是jackson-module-jaxb-annotations里面的依赖，所以选定jackson-module-jaxb-annotations这个依赖，F12，我们看到IDEA已经在pom文件里替我们做了修改\n\n\n","tags":["Java","IDEA"]},{"title":"JDK原生工具介绍","url":"/2019/12/18/JDK%E5%8E%9F%E7%94%9F%E5%B7%A5%E5%85%B7%E4%BB%8B%E7%BB%8D/","content":"native2ascii\nnative2ascii.exe 是Java的一个文件转码工具，是将特殊各异的内容转为用指定的编码标准文体形式统一的表现出来，它通常位于JDK_home\\bin目录下，安装好Java SE后，可在命令行直接使用 native2ascii命令进行转码。\n\nnative2ascii -[options] [inputfile] [outputfile]\n国际化resources.properties文件，中文字符转换为Unicode字符：native2ascii resources.properties tmp.properties或者 native2ascii -encoding Unicode resources.properties tmp.properties 注意：Unicode首字母必须大写国际化resources.properties文件，Unicode字符转换为中文字符： native2ascii -reverse -encoding GB2312 resources.properties tmp.properties\n","tags":["Java"]},{"title":"JDK安装部署","url":"/2019/10/22/JDK%E5%AE%89%E8%A3%85%E9%83%A8%E7%BD%B2/","content":"下载Oracle JRE 8 下载链接\n选择jdk-8u211-linux-x64.rpm下载\n# 卸载全部包含java的包rpm -e --nodeps `rpm -qa|grep java`# 查看安装的路径rpm -qpl jdk-8u211-linux-x64.rpm# 安装rpm -i jdk-8u211-linux-x64.rpm\n\n配置环境变量export JAVA_HOME&#x3D;&quot;&#x2F;usr&#x2F;java&#x2F;jdk1.8.0_211-amd64&quot;export PATH&#x3D;&quot;$JAVA_HOME&#x2F;bin:$PATH&quot;export CLASSPATH&#x3D;&quot;.:$JAVA_HOME&#x2F;lib&quot;\n","tags":["Java","部署文档"]},{"title":"JVM参数文档","url":"/2020/03/16/JVM%E5%8F%82%E6%95%B0%E6%96%87%E6%A1%A3/","content":"\nhttps://docs.oracle.com/javase/8/docs/technotes/guides/vm/gctuning/index.html\nhttps://docs.oracle.com/javase/8/docs/technotes/tools/unix/java.html\n\n\n\n\n参数名称 \n含义\n默认值\n说明\n\n\n\n-Xms\n设置堆的初始大小（以字节为单位）\n初始大小将设置为为老一代和年轻一代分配的大小之和\n此值必须是1024的倍数且大于1 MB。在字母后面加上k或K表示千字节，m或M表示兆字节，g或G表示千兆字节。\n\n\n-Xmx\n指定内存分配池的最大大小（以字节为单位）\n默认值是在运行时根据系统配置选择的\n此值必须是1024的倍数且大于2 MB\n\n\nexport JAVA_OPTIONS=\"$&#123;JAVA_OPTIONS&#125; -server -Xms6144m -Xmx6144m -Xmn2048m -Xss256k -XX:PermSize=512m -XX:MaxPermSize=1024m  -XX:SurvivorRatio=2 -XX:+UseConcMarkSweepGC         -XX:+CMSParallelRemarkEnabled         -XX:+UseCMSCompactAtFullCollection         -XX:CMSFullGCsBeforeCompaction=3         -XX:+UseFastAccessorMethods         -XX:+UseCMSInitiatingOccupancyOnly         -XX:CMSInitiatingOccupancyFraction=80         -XX:+DoEscapeAnalysis         -XX:+EliminateAllocations         -XX:+HeapDumpOnOutOfMemoryError         -XX:-UseGCOverheadLimit         -XX:+TraceClassLoading         -XX:+CMSClassUnloadingEnabled         -XX:+PrintClassHistogram         -Djava.awt.headless=true         -XX:+UseParNewGC         -XX:ParallelGCThreads=4         -Doracle.jdbc.useThreadLocalBufferCache=false         -Doracle.jdbc.maxCachedBufferSize=0         -Dfile.encoding=utf-8i         -Dsun.zip.disableMemoryMapping=true        -Djava.rmi.server.hostname=192.168.99.67 -Dcom.sun.management.jmxremote.port=8989 -Dcom.sun.management.jmxremote.ssl=false -Dcom.sun.management.jmxremote.authenticate=false -Djavax.management.builder.initial=weblogic.management.jmx.mbeanserver.WLSMBeanServerBuilder\"\n","tags":["Java"]},{"title":"JavaSPI介绍","url":"/2019/10/23/JavaSPI%E4%BB%8B%E7%BB%8D/","content":"Service Provider Interface\n在classpath下创建META-INF/services/\n在services文件夹下创建接口名字的文件，并在文件中添加实现的类列表ServiceLoader&lt;DriverService&gt; serviceLoader = ServiceLoader.load(DriverService.class);for (DriverService ds : serviceLoader) &#123;    System.out.println(ds.getClass().getName());    ds.onStartUp();&#125;\n\n\n\n源码解读PREFIX就是定义好的文件\npublic final class ServiceLoader&lt;S&gt;    implements Iterable&lt;S&gt;&#123;    private static final String PREFIX = \"META-INF/services/\";\n\nconfigs是Enumeration&lt;URL&gt;类型，可以迭代\nprivate boolean hasNextService() &#123;    if (nextName != null) &#123;        return true;    &#125;    if (configs == null) &#123;        try &#123;            String fullName = PREFIX + service.getName();            if (loader == null)                configs = ClassLoader.getSystemResources(fullName);            else                configs = loader.getResources(fullName);        &#125; catch (IOException x) &#123;            fail(service, \"Error locating configuration files\", x);        &#125;    &#125;    while ((pending == null) || !pending.hasNext()) &#123;        if (!configs.hasMoreElements()) &#123;            return false;        &#125;        pending = parse(service, configs.nextElement());    &#125;    nextName = pending.next();    return true;&#125;\n","tags":["Java"]},{"title":"JavaScript实用操作指南","url":"/2020/08/05/JavaScript%E5%AE%9E%E7%94%A8%E6%93%8D%E4%BD%9C%E6%8C%87%E5%8D%97/","content":"一、JavaScript参考https://developer.mozilla.org/zh-CN/docs/Web/JavaScript/Reference\n","tags":["JavaScript"]},{"title":"Java中常用却存在性能的问题","url":"/2020/01/10/Java%E4%B8%AD%E5%B8%B8%E7%94%A8%E5%8D%B4%E5%AD%98%E5%9C%A8%E6%80%A7%E8%83%BD%E7%9A%84%E9%97%AE%E9%A2%98/","content":"System.currentTimeMillis()测试代码public static void main(String[] args) &#123;    long start = System.nanoTime();    singleThread(100);    System.out.println(\"single: \" + (System.nanoTime() - start));    start = System.nanoTime();    multiThread(100);    System.out.println(\"multi: \" + (System.nanoTime() - start));&#125;public static void singleThread(int size) &#123;    for (int i = 0; i &lt; size; i++) &#123;        System.currentTimeMillis();    &#125;&#125;public static void multiThread(int size) &#123;    CountDownLatch latch = new CountDownLatch(size);    for (int i = 0; i &lt; size; i++) &#123;        new Thread(() -&gt; &#123;            try &#123;                System.currentTimeMillis();            &#125; finally &#123;                latch.countDown();            &#125;        &#125;).start();    &#125;    try &#123;        latch.await();    &#125; catch (InterruptedException e) &#123;        e.printStackTrace();    &#125;&#125;\n分析System.currentTimeMillis()调用会与系统交互，频繁访问或者高并发会造成严重的争用\n结果single: 17727multi: 58580004\n解决思路\n创建一个类，在类中维护一个线程，定时去同步\npublic class CurrentTimeMillisClock &#123;    private volatile long now;    private CurrentTimeMillisClock() &#123;        this.now = System.currentTimeMillis();        scheduleTick();    &#125;    private void scheduleTick() &#123;        new ScheduledThreadPoolExecutor(1, runnable -&gt; &#123;            Thread thread = new Thread(runnable, \"current-time-millis\");            thread.setDaemon(true);            return thread;        &#125;).scheduleAtFixedRate(() -&gt; &#123;            now = System.currentTimeMillis();        &#125;, 1, 1, TimeUnit.MILLISECONDS);    &#125;    public long now() &#123;        return now;    &#125;    public static CurrentTimeMillisClock getInstance() &#123;        return SingletonHolder.INSTANCE;    &#125;    private static class SingletonHolder &#123;        private static final CurrentTimeMillisClock INSTANCE = new                CurrentTimeMillisClock();    &#125;&#125;\n\n\n","tags":["Java"]},{"title":"Java中如何格式化内容","url":"/2020/03/24/Java%E4%B8%AD%E5%A6%82%E4%BD%95%E6%A0%BC%E5%BC%8F%E5%8C%96%E5%86%85%E5%AE%B9/","content":"\nJava中经常会用到格式化内容输出，简单写个文档，看看自己还有哪些遗漏\nhttps://docs.oracle.com/javase/8/docs/api/\n\nString.format常规类型、字符类型和数值类型的格式说明符的语法如下：  %[argument_index$][flags][width][.precision]conversion\n\n\n可选的 argument_index 是一个十进制整数，用于表明参数在参数列表中的位置。第一个参数由 “1$“  引用，第二个参数由 “2$“ 引用，依此类推。\n\n可选 flags 是修改输出格式的字符集。有效标志集取决于转换类型。\n\n\n\nFlag\nGeneral\nCharacter\nIntegral\nFloating Point\nDate/Time\nDescription\n\n\n\n‘-‘\ny\ny\ny\ny\ny\nThe result will be left-justified.\n\n\n‘#’\ny1\n-\ny3\ny\n-\nThe result should use a conversion-dependent alternate form\n\n\n‘+’\n-\n-\ny4\ny\n-\nThe result will always include a sign\n\n\n‘  ‘\n-\n-\ny4\ny\n-\nThe result will include a leading space for positive values\n\n\n‘0’\n-\n-\ny\ny\n-\nThe result will be zero-padded\n\n\n‘,’\n-\n-\ny2\ny5\n-\nThe result will include locale-specific grouping separators\n\n\n‘(‘\n-\n-\ny4\ny5\n-\nThe result will enclose negative numbers in parentheses\n\n\n\n可选 width 是一个非负十进制整数，表明要向输出中写入的最少字符数。\n\n可选 precision 是一个非负十进制整数，通常用来限制字符数。特定行为取决于转换类型。\n\n必须 conversion 是一个表明应该如何格式化参数的字符。给定参数的有效转换集取决于参数的数据类型。\n\n\n\n\n\n%\n[argument_index$]（下标）\nFlags（标志）\nWidth（宽度）\nPrecision（精度）\nConversions（转换格式）\n\n\n\n\n%\n1$\n0\n8\n\nx\n%1$08x\n\n\n","tags":["Java"]},{"title":"Java中的引用","url":"/2020/01/09/Java%E4%B8%AD%E7%9A%84%E5%BC%95%E7%94%A8/","content":"Reference\n在Java中提供了四个级别的引用：强引用，软引用，弱引用和虚引用。在这四个引用类型中，只有强引用FinalReference类是包内可见，其他三种引用类型均为public，可以在应用程序中直接使用。引用类型的类结构如图所示。\n\n强引用 FinalReference\nJava中的引用，类似C语言中最难的指针。（我是C语言入门编程，指针的概念还是很深入我心。）通过引用，可以对堆中的对象进行操作。如：\n\nStringBuffer stringBuffer = new StringBuffer(\"Helloword\");\n变量str指向StringBuffer实例所在的堆空间，通过str可以操作该对象。\n\n强引用的特点：\n强引用可以直接访问目标对象。\n强引用所指向的对象在任何时候都不会被系统回收。JVM宁愿抛出OOM异常，也不会回收强引用所指向的对象。\n强引用可能导致内存泄漏。\n\n\n\n软引用 SoftReference\n软引用是除了强引用外，最强的引用类型。可以通过java.lang.ref.SoftReference使用软引用。一个持有软引用的对象，不会被JVM很快回收，JVM会根据当前堆的使用情况来判断何时回收。当堆使用率临近阈值时，才会去回收软引用的对象。因此，软引用可以用于实现对内存敏感的高速缓存。\nSoftReference的特点是它的一个实例保存对一个Java对象的软引用， 该软引用的存在不妨碍垃圾收集线程对该Java对象的回收。也就是说，一旦SoftReference保存了对一个Java对象的软引用后，在垃圾线程对 这个Java对象回收前，SoftReference类所提供的get()方法返回Java对象的强引用。一旦垃圾线程回收该Java对象之后，get()方法将返回null。\n\n下面举一个例子说明软引用的使用方法。\n在你的IDE设置参数 -Xmx2m -Xms2m规定堆内存大小为2m。\n@Testpublic void test3()&#123;    MyObject obj = new myObject();    SoftReference sf = new SoftReference&lt;&gt;(obj);    obj = null;    System.gc();    //        byte[] bytes = new byte[1024*100];    //        System.gc();    System.out.println(\"是否被回收\"+sf.get());&#125;\n运行结果：\n是否被回收cn.zyzpp.MyObject@42110406\n打开被注释掉的new byte[1024*100]语句，这条语句请求一块大的堆空间，使堆内存使用紧张。并显式的再调用一次GC，结果如下：\n是否被回收null\n说明在系统内存紧张的情况下，软引用被回收。\n弱引用 PhantomReference\n弱引用是一种比软引用较弱的引用类型。在系统GC时，只要发现弱引用，不管系统堆空间是否足够，都会将对象进行回收。在java中，可以用java.lang.ref.WeakReference实例来保存对一个Java对象的弱引用。\n\npublic void test3()&#123;    MyObject obj = new MyObject();    WeakReference sf = new WeakReference(obj);    obj = null;    System.out.println(\"是否被回收\"+sf.get());    System.gc();    System.out.println(\"是否被回收\"+sf.get());&#125;\n运行结果：\n是否被回收cn.zyzpp.MyObject@42110406是否被回收null\n软引用，弱引用都非常适合来保存那些可有可无的缓存数据，如果这么做，当系统内存不足时，这些缓存数据会被回收，不会导致内存溢出。而当内存资源充足时，这些缓存数据又可以存在相当长的时间，从而起到加速系统的作用。\n弱引用WeakHashMap\nWeakHashMap类在java.util包内，它实现了Map接口，是HashMap的一种实现，它使用弱引用作为内部数据的存储方案。WeakHashMap是弱引用的一种典型应用，它可以作为简单的缓存表解决方案。\n\n以下两段代码分别使用WeakHashMap和HashMap保存大量的数据：\n@Testpublic void test4()&#123;    Map map;    map = new WeakHashMap&lt;String,Object&gt;();    for (int i =0;i&lt;10000;i++)&#123;        map.put(\"key\"+i,new byte[i]);    &#125;    //        map = new HashMap&lt;String,Object&gt;();    //        for (int i =0;i&lt;10000;i++)&#123;    //            map.put(\"key\"+i,new byte[i]);    //        &#125;&#125;\n使用-Xmx2M限定堆内存，使用WeakHashMap的代码正常运行结束，而使用HashMap的代码段抛出异常\njava.lang.OutOfMemoryError: Java heap space\n由此可见，WeakHashMap会在系统内存紧张时使用弱引用，自动释放掉持有弱引用的内存数据。\n但如果WeakHashMap的key都在系统内持有强引用，那么WeakHashMap就退化为普通的HashMap，因为所有的表项都无法被自动清理。\n虚引用 WeakReference\n虚引用是所有类型中最弱的一个。一个持有虚引用的对象，和没有引用几乎是一样的，随时可能被垃圾回收器回收。当试图通过虚引用的get()方法取得强引用时，总是会失败。并且，虚引用必须和引用队列一起使用，它的作用在于跟踪垃圾回收过程。\n当垃圾回收器准备回收一个对象时，如果发现它还有虚引用，就会在垃圾回收后，销毁这个对象，将这个虚引用加入引用队列。程序可以通过判断引用队列中是否已经加入了虚引用，来了解被引用的对象是否将要被垃圾回收。如果程序发现某个虚引用已经被加入到引用队列，那么就可以在所引用的对象的内存被回收之前采取必要的行动。\n\npublic void test3()&#123;    MyObject obj = new MyObject();    ReferenceQueue&lt;Object&gt; referenceQueue = new ReferenceQueue&lt;&gt;();    PhantomReference sf = new PhantomReference&lt;&gt;(obj,referenceQueue);    obj = null;    System.out.println(\"是否被回收\"+sf.get());    System.gc();    System.out.println(\"是否被回收\"+sf.get());&#125;\n运行结果：\n是否被回收null是否被回收null\n对虚引用的get()操作，总是返回null，因为sf.get()方法的实现如下：\npublic T get() &#123;    return null;&#125;\n","tags":["Java"]},{"title":"Java二进制操作方法","url":"/2020/03/16/Java%E4%BA%8C%E8%BF%9B%E5%88%B6%E6%93%8D%E4%BD%9C%E6%96%B9%E6%B3%95/","content":"定义二进制\n二进制用0b开头\n\nint i &#x3D; 0b11;\n\n二进制转换//二进制字符串String b = Integer.toBinaryString(3);//同理String b = Integer.toString(3,2);//二进制字符串转intint i = Integer.parseInt(b, 2);\n\n移位intint i1 = 0b11, i2 = 0b10;System.out.println(Integer.toBinaryString(i1 &lt;&lt; 1));System.out.println(Integer.toBinaryString(i1 &gt;&gt; 1));System.out.println(Integer.toBinaryString(i1 &amp; i2));System.out.println(Integer.toBinaryString(~i1));System.out.println(Integer.toBinaryString(i1 | i2));System.out.println(Integer.toBinaryString(i1 ^ i2));\nBigInteger//11    00BigInteger bi1 = new BigInteger(\"3\"),bi2 = new BigInteger(\"0\");//左移System.out.println(bi1.shiftLeft(1).toString(2));//右移System.out.println(bi1.shiftRight(1).toString(2));//与System.out.println(bi1.and(bi2).toString(2));//非System.out.println(bi1.not().toString(2));//或System.out.println(bi1.or(bi2).toString(2));//异或System.out.println(bi1.xor(bi2).toString(2));\n\n除基倒取余法public static void binaryToDecimal(int n) &#123;    int t = 0; // 用来记录位数    int bin = 0; // 用来记录最后的二进制数    int r = 0; // 用来存储余数    while (n != 0) &#123;        r = n % 2;        n = n / 2;        bin += r * Math.pow(10, t);        t++;    &#125;    System.out.println(bin + \"\\n\");&#125;\n","tags":["Java","算法相关"]},{"title":"Java函数式接口","url":"/2020/06/04/Java%E5%87%BD%E6%95%B0%E5%BC%8F%E6%8E%A5%E5%8F%A3/","content":"一、简介1.1 @FunctionalInterface在JDK 8中引入了FunctionalInterface接口，其源代码定义如下：\n@Documented@Retention(RetentionPolicy.RUNTIME)@Target(ElementType.TYPE)public @interface FunctionalInterface &#123;&#125;\n\n1.2 特征\n有且仅有一个抽象方法\n允许定义静态方法\n允许定义默认方法\n允许java.lang.Object中的public方法\n该注解不是必须的，如果一个接口符合”函数式接口”定义，那么加不加该注解都没有影响。加上该注解能够更好地让编译器进行检查。如果编写的不是函数式接口，但是加上了@FunctionalInterface，那么编译器会报错\n\n@FunctionalInterfacepublic interface TestInterface &#123;    // 抽象方法    public void sub();    // java.lang.Object中的方法不是抽象方法    public boolean equals(Object var1);    // default不是抽象方法    public default void defaultMethod()&#123;    &#125;    // static不是抽象方法    public static void staticMethod()&#123;    &#125;&#125;\n\n二、示例2.1 定义接口/**多参数无返回*/@FunctionalInterfacepublic interface NoReturnMultiParam &#123;    void method(int a, int b);&#125;/**无参无返回值*/@FunctionalInterfacepublic interface NoReturnNoParam &#123;    void method();&#125;/**一个参数无返回*/@FunctionalInterfacepublic interface NoReturnOneParam &#123;    void method(int a);&#125;/**多个参数有返回值*/@FunctionalInterfacepublic interface ReturnMultiParam &#123;    int method(int a, int b);&#125;/*** 无参有返回*/@FunctionalInterfacepublic interface ReturnNoParam &#123;    int method();&#125;/**一个参数有返回值*/@FunctionalInterfacepublic interface ReturnOneParam &#123;    int method(int a);&#125;\n\n2.2 使用示例语法形式为 () -&gt; {}，其中 () 用来描述参数列表，{} 用来描述方法体，-&gt; 为 lambda运算符 ，读作(goes to)。\n//无参无返回NoReturnNoParam noReturnNoParam = () -&gt; &#123;    System.out.println(\"NoReturnNoParam\");&#125;;noReturnNoParam.method();//一个参数无返回NoReturnOneParam noReturnOneParam = (int a) -&gt; &#123;    System.out.println(\"NoReturnOneParam param:\" + a);&#125;;noReturnOneParam.method(6);//多个参数无返回NoReturnMultiParam noReturnMultiParam = (int a, int b) -&gt; &#123;    System.out.println(\"NoReturnMultiParam param:\" + \"&#123;\" + a +\",\" + + b +\"&#125;\");&#125;;noReturnMultiParam.method(6, 8);//无参有返回值ReturnNoParam returnNoParam = () -&gt; &#123;    System.out.print(\"ReturnNoParam\");    return 1;&#125;;int res = returnNoParam.method();System.out.println(\"return:\" + res);//一个参数有返回值ReturnOneParam returnOneParam = (int a) -&gt; &#123;    System.out.println(\"ReturnOneParam param:\" + a);    return 1;&#125;;int res2 = returnOneParam.method(6);System.out.println(\"return:\" + res2);//多个参数有返回值ReturnMultiParam returnMultiParam = (int a, int b) -&gt; &#123;    System.out.println(\"ReturnMultiParam param:\" + \"&#123;\" + a + \",\" + b +\"&#125;\");    return 1;&#125;;int res3 = returnMultiParam.method(6, 8);System.out.println(\"return:\" + res3);\n2.3 简化示例//1.简化参数类型，可以不写参数类型，但是必须所有参数都不写NoReturnMultiParam lamdba1 = (a, b) -&gt; &#123;    System.out.println(\"简化参数类型\");&#125;;lamdba1.method(1, 2);//2.简化参数小括号，如果只有一个参数则可以省略参数小括号NoReturnOneParam lambda2 = a -&gt; &#123;    System.out.println(\"简化参数小括号\");&#125;;lambda2.method(1);//3.简化方法体大括号，如果方法条只有一条语句，则可以胜率方法体大括号NoReturnNoParam lambda3 = () -&gt; System.out.println(\"简化方法体大括号\");lambda3.method();//4.如果方法体只有一条语句，并且是 return 语句，则可以省略方法体大括号ReturnOneParam lambda4 = a -&gt; a+3;System.out.println(lambda4.method(5));ReturnMultiParam lambda5 = (a, b) -&gt; a+b;System.out.println(lambda5.method(1, 1));\n\n2.4 表达式引用方法有时候我们不是必须要自己重写某个匿名内部类的方法，我们可以可以利用 lambda表达式的接口快速指向一个已经被实现的方法。\n语法\n方法归属者::方法名 静态方法的归属者为类名，普通方法归属者为对象\npublic class Exe1 &#123;    public static void main(String[] args) &#123;        ReturnOneParam lambda1 = a -&gt; doubleNum(a);        System.out.println(lambda1.method(3));        //lambda2 引用了已经实现的 doubleNum 方法        ReturnOneParam lambda2 = Exe1::doubleNum;        System.out.println(lambda2.method(3));        Exe1 exe = new Exe1();        //lambda4 引用了已经实现的 addTwo 方法        ReturnOneParam lambda4 = exe::addTwo;        System.out.println(lambda4.method(2));    &#125;    /**     * 要求     * 1.参数数量和类型要与接口中定义的一致     * 2.返回值类型要与接口中定义的一致     */    public static int doubleNum(int a) &#123;        return a * 2;    &#125;    public int addTwo(int a) &#123;        return a + 2;    &#125;&#125;\n\n2.5 构造方法的引用一般我们需要声明接口，该接口作为对象的生成器，通过 类名::new 的方式来实例化对象，然后调用方法返回对象。\ninterface ItemCreatorBlankConstruct &#123;    Item getItem();&#125;interface ItemCreatorParamContruct &#123;    Item getItem(int id, String name, double price);&#125;public class Exe2 &#123;    public static void main(String[] args) &#123;        ItemCreatorBlankConstruct creator = () -&gt; new Item();        Item item = creator.getItem();        ItemCreatorBlankConstruct creator2 = Item::new;        Item item2 = creator2.getItem();        ItemCreatorParamContruct creator3 = Item::new;        Item item3 = creator3.getItem(112, \"鼠标\", 135.99);    &#125;\n\n三、常用函数式接口jdk默认的接口定义在java.util.function包中，常用的有：\n\nPredicate\n\nboolean test(T t);\n\n\nSupplier\n\nT get();\n\n\nConsumer\n\nvoid accept(T t);\n\n\nFunction\n\nR apply(T t);\n\n四、参考https://www.cnblogs.com/haixiang/p/11029639.html\n","tags":["Java"]},{"title":"Java图像相关操作","url":"/2019/12/19/Java%E5%9B%BE%E5%83%8F%E7%9B%B8%E5%85%B3%E6%93%8D%E4%BD%9C/","content":"\nhttps://www.cnblogs.com/donghb/p/7637990.html\n\nBufferedImageBufferedImage image = new BufferedImage(IMG_WIDTH, IMG_HEIGHT, BufferedImage.TYPE_INT_RGB);image = image.getSubimage(50, 50, 20, 20);\n\nImageIOImageIO.write(image, \"jpg\", new File(\"C:\\\\Users\\\\lenovo\\\\Desktop\\\\image.jpg\"));\n\nGraphics，Graphics2D\nGraphics类提供基本绘图方法，Graphics2D类提供更强大的绘图能力。\nGraphics类提供基本的几何图形绘制方法，主要有：画线段、画矩形、画圆、画带颜色的图形、画椭圆、画圆弧、画多边形等。\n\nGraphicspublic class TransparentImage &#123;    private static int IMG_WIDTH = 100;    private static int IMG_HEIGHT = 100;    public static void main(String[] args) throws IOException &#123;        BufferedImage image = new BufferedImage(IMG_WIDTH, IMG_HEIGHT, BufferedImage.TYPE_INT_RGB);        Graphics g = image.getGraphics();        g.drawLine(0, 0, 100, 100);        ImageIO.write(image, \"jpg\", new File(\"C:\\\\Users\\\\lenovo\\\\Desktop\\\\image.jpg\"));                        // 向页面输出图像    &#125;&#125;\n\n\n画一条线\n\ng.drawLine(0, 0, 100, 100);\n\n\n画矩形\n\ng.drawRect(0,0,50,50);g.setColor(Color.lightGray);g.fillRect(50,50,20,20);\n\n\n画圆\n\ng.drawRoundRect(5, 5, 30, 30, 30, 30);g.setColor(Color.lightGray);g.fillRoundRect(30, 30, 30, 30, 30, 30);\n\nGraphics2Dpublic class RenderingHintCase &#123;    public static void main(String[] args) throws IOException &#123;        BufferedImage image = new BufferedImage(260, 80, BufferedImage.TYPE_INT_BGR);        //获取Graphics2D对象        Graphics2D graphics = image.createGraphics();        //开启文字抗锯齿        graphics.setRenderingHint(RenderingHints.KEY_TEXT_ANTIALIASING, RenderingHints.VALUE_TEXT_ANTIALIAS_ON);        //设置字体        Font font = new Font(\"Algerian\", Font.ITALIC, 40);        graphics.setFont(font);        //向画板上写字        graphics.drawString(\"This is test!\", 10, 60);        graphics.dispose();        ImageIO.write(image, \"jpg\", new File(\"C:\\\\Users\\\\lenovo\\\\Desktop\\\\demo.jpg\"));    &#125;&#125;\n","tags":["Java"]},{"title":"Java序列化","url":"/2019/12/12/Java%E5%BA%8F%E5%88%97%E5%8C%96/","content":"简介Java序列化是指把Java对象转换为字节序列的过程；而Java反序列化是指把字节序列恢复为Java对象的过程。从而达到网络传输、本地存储的效果。\n序列化Serializable\n实现Serializable接口，会自动将非transient修饰的变量序列化\n\npackage org.serial;import java.io.Serializable;public class User implements Serializable &#123;    private static final long serialVersionUID = -184170424740238078L;    private String name;    private String sex;    public String getName() &#123;        return name;    &#125;    public void setName(String name) &#123;        this.name = name;    &#125;    public String getSex() &#123;        return sex;    &#125;    public void setSex(String sex) &#123;        this.sex = sex;    &#125;&#125;\n\n测试类：\npackage org.serial;import java.io.*;public class SerializableUtil &#123;    public static Object deserializable(byte[] bytes) &#123;        try (ObjectInputStream objectInputStream = new ObjectInputStream(new ByteArrayInputStream(bytes))) &#123;            Object o = objectInputStream.readObject();            return o;        &#125; catch (IOException e) &#123;            e.printStackTrace();        &#125; catch (ClassNotFoundException e) &#123;            e.printStackTrace();        &#125;        return null;    &#125;    public static byte[] serializable(Object obj) &#123;        try (ByteArrayOutputStream byteArrayOutputStream = new ByteArrayOutputStream();             ObjectOutputStream objectOutputStream = new ObjectOutputStream(byteArrayOutputStream);) &#123;            objectOutputStream.writeObject(obj);            return byteArrayOutputStream.toByteArray();        &#125; catch (IOException e) &#123;            e.printStackTrace();        &#125;        return null;    &#125;    public static void main(String[] args) &#123;        User user = new User();        user.setName(\"zhang\");        user.setSex(\"man\");        byte[] serializable = SerializableUtil.serializable(user);        User deserializable = (User)SerializableUtil.deserializable(serializable);        System.out.println(deserializable.toString());    &#125;&#125;\n\nExternalizable\n实现Externalizable\n\npackage org.serial;import java.io.Externalizable;import java.io.IOException;import java.io.ObjectInput;import java.io.ObjectOutput;public class Car implements Externalizable &#123;    private String name;    private String color;    @Override    public void writeExternal(ObjectOutput objectOutput) throws IOException &#123;        objectOutput.writeObject(name);        objectOutput.writeObject(color);    &#125;    @Override    public void readExternal(ObjectInput objectInput) throws IOException, ClassNotFoundException &#123;        String name = (String) objectInput.readObject();        String color = (String) objectInput.readObject();    &#125;    public String getName() &#123;        return name;    &#125;    public void setName(String name) &#123;        this.name = name;    &#125;    public String getColor() &#123;        return color;    &#125;    public void setColor(String color) &#123;        this.color = color;    &#125;&#125;\n\n注意Externalizable接口实现方式一定要有默认的无参构造函数\nExternalizable不需要产生序列化ID而Serializable需要\n相比较Serializable,Externalizable序列化、反序列更加快速，占用相比较小的内存\n","tags":["Java"]},{"title":"Java文件复制","url":"/2020/03/24/Java%E6%96%87%E4%BB%B6%E5%A4%8D%E5%88%B6/","content":"一、使用FileStreams复制private static void copyFileUsingFileStreams(File source, File dest)    throws IOException &#123;    InputStream input = null;    OutputStream output = null;    try &#123;        input = new FileInputStream(source);        output = new FileOutputStream(dest);        byte[] buf = new byte[1024];        int bytesRead;        while ((bytesRead = input.read(buf)) ！= -1) &#123;            output.write(buf, 0, bytesRead);        &#125;    &#125; finally &#123;        input.close();        output.close();    &#125;&#125;\n\n二、使用FileChannel复制private static void copyFileUsingFileChannels(File source, File dest) throws IOException &#123;    FileChannel inputChannel = null;    FileChannel outputChannel = null;    try &#123;        inputChannel = new FileInputStream(source).getChannel();        outputChannel = new FileOutputStream(dest).getChannel();        outputChannel.transferFrom(inputChannel, 0, inputChannel.size());    &#125; finally &#123;        inputChannel.close();        outputChannel.close();    &#125;&#125;\n\n三、使用Commons IO复制private static void copyFileUsingApacheCommonsIO(File source, File dest)    throws IOException &#123;    FileUtils.copyFile(source, dest);&#125;\n\n源码：\nprivate static void doCopyFile(final File srcFile, final File destFile, final boolean preserveFileDate)    throws IOException &#123;    if (destFile.exists() &amp;&amp; destFile.isDirectory()) &#123;        throw new IOException(\"Destination '\" + destFile + \"' exists but is a directory\");    &#125;    try (FileInputStream fis = new FileInputStream(srcFile);         FileChannel input = fis.getChannel();         FileOutputStream fos = new FileOutputStream(destFile);         FileChannel output = fos.getChannel()) &#123;        final long size = input.size(); // TODO See IO-386        long pos = 0;        long count = 0;        while (pos &lt; size) &#123;            final long remain = size - pos;            count = remain &gt; FILE_COPY_BUFFER_SIZE ? FILE_COPY_BUFFER_SIZE : remain;            final long bytesCopied = output.transferFrom(input, pos, count);            if (bytesCopied == 0) &#123; // IO-385 - can happen if file is truncated after caching the size                break; // ensure we don't loop forever            &#125;            pos += bytesCopied;        &#125;    &#125;    final long srcLen = srcFile.length(); // TODO See IO-386    final long dstLen = destFile.length(); // TODO See IO-386    if (srcLen != dstLen) &#123;        throw new IOException(\"Failed to copy full contents from '\" +                              srcFile + \"' to '\" + destFile + \"' Expected length: \" + srcLen + \" Actual: \" + dstLen);    &#125;    if (preserveFileDate) &#123;        destFile.setLastModified(srcFile.lastModified());    &#125;&#125;\n\n四、使用Java7的Files类复制private static void copyFileUsingJava7Files(File source, File dest)    throws IOException &#123;    Files.copy(source.toPath(), dest.toPath());&#125;\n\n五、测试package snippet;import org.apache.commons.io.FileUtils;import java.io.*;import java.nio.channels.FileChannel;import java.nio.file.Files;public class CopyFilesExample &#123;    public static void main(String[] args) throws InterruptedException,            IOException &#123;        File source = new File(\"F:\\\\INSTALL_HISTORY\\\\ideaIU-2019.1.1.exe\");        File dest = new File(\"F:\\\\TEST\\\\ideaIU-2019.1.1_1.exe\");        // copy file using FileStreams        long start = System.nanoTime();        long end;        copyFileUsingFileStreams(source, dest);        System.out.printf(\"%-50s = %20d\\n\", \"Time taken by FileStreams Copy\", (System.nanoTime() - start));        // copy files using java.nio.FileChannelsource = new File(\"C:\\\\Users\\\\nikos7\\\\Desktop\\\\files\\\\sourcefile2.txt\");        dest = new File(\"F:\\\\TEST\\\\ideaIU-2019.1.1_2.exe\");        start = System.nanoTime();        copyFileUsingFileChannels(source, dest);        end = System.nanoTime();        System.out.printf(\"%-50s = %20d\\n\", \"Time taken by FileChannels Copy\", (System.nanoTime() - start));        // copy file using Java 7 Files classsource = new File(\"C:\\\\Users\\\\nikos7\\\\Desktop\\\\files\\\\sourcefile3.txt\");        dest = new File(\"F:\\\\TEST\\\\ideaIU-2019.1.1_3.exe\");        start = System.nanoTime();        copyFileUsingJava7Files(source, dest);        end = System.nanoTime();        System.out.printf(\"%-50s = %20d\\n\", \"Time taken by Java7 Files Copy\", (System.nanoTime() - start));        // copy files using apache commons iosource = new File(\"C:\\\\Users\\\\nikos7\\\\Desktop\\\\files\\\\sourcefile4.txt\");        dest = new File(\"F:\\\\TEST\\\\ideaIU-2019.1.1_4.exe\");        start = System.nanoTime();        copyFileUsingApacheCommonsIO(source, dest);        end = System.nanoTime();        System.out.printf(\"%-50s = %20d\\n\", \"Time taken by Apache Commons IO Copy\", (System.nanoTime() - start));    &#125;    private static void copyFileUsingFileStreams(File source, File dest)            throws IOException &#123;        InputStream input = null;        OutputStream output = null;        try &#123;            input = new FileInputStream(source);            output = new FileOutputStream(dest);            byte[] buf = new byte[1024];            int bytesRead;            while ((bytesRead = input.read(buf)) &gt; 0) &#123;                output.write(buf, 0, bytesRead);            &#125;        &#125; finally &#123;            input.close();            output.close();        &#125;    &#125;    private static void copyFileUsingFileChannels(File source, File dest)            throws IOException &#123;        FileChannel inputChannel = null;        FileChannel outputChannel = null;        try &#123;            inputChannel = new FileInputStream(source).getChannel();            outputChannel = new FileOutputStream(dest).getChannel();            outputChannel.transferFrom(inputChannel, 0, inputChannel.size());        &#125; finally &#123;            inputChannel.close();            outputChannel.close();        &#125;    &#125;    private static void copyFileUsingJava7Files(File source, File dest)            throws IOException &#123;        Files.copy(source.toPath(), dest.toPath());    &#125;    private static void copyFileUsingApacheCommonsIO(File source, File dest)            throws IOException &#123;        FileUtils.copyFile(source, dest);    &#125;&#125;\n\n结果：\nTime taken by FileStreams Copy                     &#x3D;           3307186847Time taken by FileChannels Copy                    &#x3D;            355407223Time taken by Java7 Files Copy                     &#x3D;            434544647Time taken by Apache Commons IO Copy               &#x3D;           2018366048\n","tags":["Java"]},{"title":"Java断点续传","url":"/2020/01/20/Java%E6%96%AD%E7%82%B9%E7%BB%AD%E4%BC%A0/","content":"原理\n所谓断点续传，就是指从文件已经下载好的地方开始继续下载。所以下载端传给Web服务器的时候要多加一条信息，那就是从哪个字节开始下载。了解到这些，我们就可以开发了。\n\nRange\nThe Range 是一个请求首部，告知服务器返回文件的哪一部分。在一个  Range 首部中，可以一次性请求多个部分，服务器会以 multipart 文件的形式将其返回。如果服务器返回的是范围响应，需要使用 206 Partial Content 状态码。假如所请求的范围不合法，那么服务器会返回  416 Range Not Satisfiable 状态码，表示客户端错误。服务器允许忽略  Range  首部，从而返回整个文件，状态码用 200 。\n\nContent-Range\n在HTTP协议中，响应首部 Content-Range 显示的是一个数据片段在整个文件中的位置。\n\n示例代码","tags":["Java"]},{"title":"Java泛型的协变与逆变","url":"/2019/11/14/Java%E6%B3%9B%E5%9E%8B%E7%9A%84%E5%8D%8F%E5%8F%98%E4%B8%8E%E9%80%86%E5%8F%98/","content":"泛型擦除Java的泛型本质上不是真正的泛型，而是利用了类型擦除（type erasure），比如下面的代码就会出现错误：\n// 这里会编译错误public void hello(List&lt;String&gt; list)&#123;&#125;public void hello(List&lt;Integer&gt; list)&#123;&#125;\n\n报的错误是：both methods  have same erasure\n原因是java在编译的时候会把泛型，上面的&lt;String&gt;和&lt;Integer&gt;都给擦除掉（其实并没有真正的被擦除，javap -l -p -v -c可以看到LocalVariableTypeTable里面有方法参数类型的签名）。\n协变与逆变理解了类型擦除有助于我们理解泛型的协变与逆变，现有几个类如下：\nPlant　　Fruit　　Apple　　Banana　　Orange\n其中Apple、Banana、Orange是Fruit的子类，Fruit是Plant的子类。我们来看下下面的代码：\npublic static void main(String[] args) &#123;    List&lt;Fruit&gt; list = new ArrayList&lt;Apple&gt;();\t\t//编译错误&#125;\n\n泛型没有内建的协变类型，无法将List&lt;Fruit&gt;和ArrayList&lt;Apple&gt;关联起来，所以在编译阶段就会出现错误。\n协变于是我们可以利用通配符实现泛型的协变：&lt;? extends T&gt;子类通配符；这个通配符定义了?继承自T，可以帮助我们实现向上转换：\npublic static void main(String[] args) &#123;    List&lt;? extends Fruit&gt; list = new ArrayList&lt;Apple&gt;();&#125;\n\n这里我们要理解当转换之后list中的数据类型是什么。虽然将Apple类型赋值给了list，但是list的类型是? extends Fruit，把? extends Fruit看成一个整体，我们能确定list的具体类型肯定是Fruit或者Fruit的父类(因为一个类只能有一个直接父类，所以确定了Fruit，那么Fruit的父类则都是可以确定的)，而不能确定list的类型是Fruit的子类当中具体的哪一个？（有多个类都继承自Fruit），所以这也就直接导致了一旦使用了&lt;? extends T&gt;向上转换之后，不能再向list中添加任何类型的对象了，这个时候只能选择从list当中get数据而不能add。\npublic static void main(String[] args) &#123;    List&lt;? extends Fruit&gt; list = new ArrayList&lt;Apple&gt;();    list.add(new Apple());\t//编译错误    list.add(new Banana());\t//编译错误    list.add(new Orange());\t//编译错误    list.add(new Fruit());\t//编译错误&#125;\n\n另外还需要注意的是，这个时候从list当中get出来的数据不再是Apple，而是Fruit或者Fruit的父类：\npublic static void main(String[] args) &#123;    List&lt;? extends Fruit&gt; list = new ArrayList&lt;Apple&gt;();    Fruit fruit = list.get(0);    Plant plant = list.get(0);    Apple apple = list.get(0);\t//编译错误&#125;\n\n逆变逆变则和协变相反，它是向下转换：\npublic static void main(String[] args) &#123;    List&lt;? super Fruit&gt; list = new ArrayList&lt;Fruit&gt;();    list.add(new Apple());    list.add(new Fruit());    list.add(new Plant());\t//编译错误&#125;\n\n逆变使用通配符? super T（超类通配符），如上面代码，Fruit是Apple的超类，则这个时候对于JVM来说，它能确定list的类型的超类肯定是Apple或者Apple的父类，换言之该类型就是Apple或者Apple的子类，所以和上面的协变一样，既然确定了类型的范围，那么list能够add的类型也就是Apple或者Apple的子类了。\nPECS是指Producer Extends, Consumer Super\n总结 ? extends T和 ? super T 通配符的特征，我们可以得出以下结论：\n\n如果你想从一个数据类型里获取数据，使用 ? extends T通配符\n如果你想把对象写入一个数据结构里，使用? super T通配符\n如果你既想存，又想取，那就别用通配符。\n\n","tags":["Java"]},{"title":"Java泛型简介","url":"/2020/01/09/Java%E6%B3%9B%E5%9E%8B%E7%AE%80%E4%BB%8B/","content":"泛型(Generics)\n泛型类\n//此处T可以随便写为任意标识，常见的如T、E、K、V等形式的参数常用于表示泛型//在实例化泛型类时，必须指定T的具体类型public class Generic&lt;T&gt;&#123;    //key这个成员变量的类型为T,T的类型由外部指定    private T key;    public Generic(T key) &#123; //泛型构造方法形参key的类型也为T，T的类型由外部指定        this.key = key;    &#125;    public T getKey()&#123; //泛型方法getKey的返回值类型为T，T的类型由外部指定        return key;    &#125;&#125;\n\n泛型接口\n//定义一个泛型接口public interface Generator&lt;T&gt; &#123;    public T next();&#125;\n\n泛型方法\n/** * 泛型方法的基本介绍 * @param tClass 传入的泛型实参 * @return T 返回值为T类型 * 说明： *     1）public 与 返回值中间&lt;T&gt;非常重要，可以理解为声明此方法为泛型方法。 *     2）只有声明了&lt;T&gt;的方法才是泛型方法，泛型类中的使用了泛型的成员方法并不是泛型方法。 *     3）&lt;T&gt;表明该方法将使用泛型类型T，此时才可以在方法中使用泛型类型T。 *     4）与泛型类的定义一样，此处T可以随便写为任意标识，常见的如T、E、K、V等形式的参数常用于表示泛型。 */public &lt;T&gt; T genericMethod(Class&lt;T&gt; tClass)throws InstantiationException ,  IllegalAccessException&#123;        T instance = tClass.newInstance();        return instance;&#125;\n\n\n","tags":["Java"]},{"title":"Java源码解读之Arrays.parallelSort()","url":"/2020/05/28/Java%E6%BA%90%E7%A0%81%E8%A7%A3%E8%AF%BB%E4%B9%8BArrays-parallelSort/","content":"\n在学习Fork/Join框架的时候，了解到Arrays.parallelSort()的底层实现用到了Fork/Join，所以看了一下这个方法的源码，记录一下自己的学习过程。\n\npublic static void parallelSort(int[] a) &#123;    int n = a.length, p, g;    if (n &lt;= MIN_ARRAY_SORT_GRAN ||        (p = ForkJoinPool.getCommonPoolParallelism()) == 1)        DualPivotQuicksort.sort(a, 0, n - 1, null, 0, 0);    else        new ArraysParallelSortHelpers.FJInt.Sorter        (null, a, new int[n], 0, n, 0,         ((g = n / (p &lt;&lt; 2)) &lt;= MIN_ARRAY_SORT_GRAN) ?         MIN_ARRAY_SORT_GRAN : g).invoke();&#125;\n\nMIN_ARRAY_SORT_GRAN这个是并行排序的阈值，如果大于这个值采用并行执行，并行用到了Fork/Join。\nForkJoinPool.getCommonPoolParallelism()这个方法的源码，这里看注释说明返回公共线程池的并行度，这里我追了一下源头，应该是根据电脑的CPU核数算出来的，暂时没深究。\n/**  * Returns the targeted parallelism level of the common pool.  *  * @return the targeted parallelism level of the common pool  * @since 1.8  */public static int getCommonPoolParallelism() &#123;    return commonParallelism;&#125;\n\n下面主要看一下DualPivotQuicksort.sort（双轴快速排序）这个方法的实现，\nstatic void sort(int[] a, int left, int right,                 int[] work, int workBase, int workLen) &#123;    // Use Quicksort on small arrays    if (right - left &lt; QUICKSORT_THRESHOLD) &#123;        sort(a, left, right, true);        return;    &#125;\t...&#125;\n\n这个地方判断如果排序的数量小于快速排序的阈值采用快速排序。然后看一下sort(a, left, right, true);这个方法，如果小于INSERTION_SORT_THRESHOLD用插入排序，这个方法不详细说了，了解一下Dual-Pivot Quicksort（新快速排序算法）\n/**  * Sorts the specified range of the array by Dual-Pivot Quicksort.  *  * @param a the array to be sorted  * @param left the index of the first element, inclusive, to be sorted  * @param right the index of the last element, inclusive, to be sorted  * @param leftmost indicates if this part is the leftmost in the range  */private static void sort(int[] a, int left, int right, boolean leftmost) &#123;    int length = right - left + 1;    if (length &lt; INSERTION_SORT_THRESHOLD)\n","tags":["Java"]},{"title":"Java线程池介绍","url":"/2020/04/13/Java%E7%BA%BF%E7%A8%8B%E6%B1%A0%E4%BB%8B%E7%BB%8D/","content":"参数介绍int corePoolSize\n该线程池中核心线程数最大值\n\n核心线程：线程池新建线程的时候，如果当前线程总数小于corePoolSize，则新建的是核心线程，如果超过corePoolSize，则新建的是非核心线程，核心线程默认情况下会一直存活在线程池中，即使这个核心线程啥也不干(闲置状态)。如果指定ThreadPoolExecutor的allowCoreThreadTimeOut这个属性为true，那么核心线程如果不干活(闲置状态)的话，超过一定时间(时长下面参数决定)，就会被销毁掉。\nint maximumPoolSize\n该线程池中线程总数最大值\n\n线程总数 = 核心线程数 + 非核心线程数。\nlong keepAliveTime\n该线程池中非核心线程闲置超时时长\n\n一个非核心线程，如果不干活(闲置状态)的时长超过这个参数所设定的时长，就会被销毁掉，如果设置allowCoreThreadTimeOut = true，则会作用于核心线程。\nTimeUnit unit\nkeepAliveTime的单位\n\nTimeUnit是一个枚举类型，其包括：\n\nNANOSECONDS : 1微毫秒 = 1微秒 / 1000\nMICROSECONDS : 1微秒 = 1毫秒 / 1000\nMILLISECONDS : 1毫秒 = 1秒 /1000\nSECONDS : 秒\nMINUTES : 分\nHOURS : 小时\nDAYS : 天\n\nBlockingQueue&lt;Runnable&gt; workQueue\n该线程池中的任务队列：维护着等待执行的Runnable对象\n\n当所有的核心线程都在干活时，新添加的任务会被添加到这个队列中等待处理，如果队列满了，则新建非核心线程执行任务。\n常用的workQueue类型：\n\nSynchronousQueue：这个队列接收到任务的时候，会直接提交给线程处理，而不保留它，如果所有线程都在工作怎么办？那就新建一个线程来处理这个任务！所以为了保证不出现&lt;线程数达到了maximumPoolSize而不能新建线程&gt;的错误，使用这个类型队列的时候，maximumPoolSize一般指定成Integer.MAX_VALUE，即无限大\nLinkedBlockingQueue：这个队列接收到任务的时候，如果当前线程数小于核心线程数，则新建线程(核心线程)处理任务；如果当前线程数等于核心线程数，则进入队列等待。由于这个队列没有最大值限制，即所有超过核心线程数的任务都将被添加到队列中，这也就导致了maximumPoolSize的设定失效，因为总线程数永远不会超过corePoolSize\nArrayBlockingQueue：可以限定队列的长度，接收到任务的时候，如果没有达到corePoolSize的值，则新建线程(核心线程)执行任务，如果达到了，则入队等候，如果队列已满，则新建线程(非核心线程)执行任务，又如果总线程数到了maximumPoolSize，并且队列也满了，则发生错误\nDelayQueue：队列内元素必须实现Delayed接口，这就意味着你传进去的任务必须先实现Delayed接口。这个队列接收到任务时，首先先入队，只有达到了指定的延时时间，才会执行任务\n\nThreadFactory threadFactory\n创建线程的工厂，这是一个接口，你new他的时候需要实现他的Thread newThread(Runnable r)方法，一般用不上。\n\nRejectedExecutionHandler handler\n超出maximumPoolSize异常处理类，这玩意儿就是抛出异常专用的\n\n线程池运行机制\n线程数量未达到corePoolSize，则新建一个线程(核心线程)执行任务\n线程数量达到了corePools，则将任务移入队列等待\n队列已满，新建线程(非核心线程)执行任务\n队列已满，总线程数又达到了maximumPoolSize，就会由(RejectedExecutionHandler)抛出异常\n\nJava通过Executors提供四种线程池分别为：\n\nnewCachedThreadPool创建一个可缓存线程池，如果线程池长度超过处理需要，可灵活回收空闲线程，若无可回收，则新建线程。\n\nnewFixedThreadPool 创建一个定长线程池，可控制线程最大并发数，超出的线程会在队列中等待。\n\nnewScheduledThreadPool 创建一个定长线程池，支持定时及周期性任务执行。\n\nnewSingleThreadExecutor 创建一个单线程化的线程池，它只会用唯一的工作线程来执行任务，保证所有任务按照指定顺序(FIFO, LIFO, 优先级)执行。\n\n\n","tags":["Java"]},{"title":"Java线程池解析","url":"/2020/03/23/Java%E7%BA%BF%E7%A8%8B%E6%B1%A0%E8%A7%A3%E6%9E%90/","content":"线程池概念\n相关文章：https://juejin.im/post/5d1882b1f265da1ba84aa676\n\n线程池： 简单理解，它就是一个管理线程的池子。\n\n它帮我们管理线程，避免增加创建线程和销毁线程的资源损耗。因为线程其实也是一个对象，创建一个对象，需要经过类加载过程，销毁一个对象，需要走GC垃圾回收流程，都是需要资源开销的。\n提高响应速度。 如果任务到达了，相对于从线程池拿线程，重新去创建一条线程执行，速度肯定慢很多。\n重复利用。 线程用完，再放回池子，可以达到重复利用的效果，节省资源。\n\n线程池的创建线程池可以通过ThreadPoolExecutor来创建，我们来看一下它的构造函数：\npublic ThreadPoolExecutor(int corePoolSize,                          int maximumPoolSize,                          long keepAliveTime,TimeUnit unit,                          BlockingQueue&lt;Runnable&gt; workQueue,                          ThreadFactory threadFactory,                          RejectedExecutionHandler handler)\n\n几个核心参数的作用：\n\ncorePoolSize： 线程池核心线程数最大值\nmaximumPoolSize： 线程池最大线程数大小\nkeepAliveTime： 线程池中非核心线程空闲的存活时间大小\nunit： 线程空闲存活时间单位\nworkQueue： 存放任务的阻塞队列\nthreadFactory： 用于设置创建线程的工厂，可以给创建的线程设置有意义的名字，可方便排查问题。\nhandler： 线城池的饱和策略事件，主要有四种类型\n\n","tags":["Java"]},{"title":"Java语言解析XML的几种方式","url":"/2020/03/06/Java%E8%AF%AD%E8%A8%80%E8%A7%A3%E6%9E%90XML%E7%9A%84%E5%87%A0%E7%A7%8D%E6%96%B9%E5%BC%8F/","content":"(1)DOM解析\nDOM是html和xml的应用程序接口(API)，以层次结构（类似于树型）来组织节点和信息片段，映射XML文档的结构，允许获取和操作文档的任意部分，是W3C的官方标准\n\n【优点】\n①允许应用程序对数据和结构做出更改。\n②访问是双向的，可以在任何时候在树中上下导航，获取和操作任意部分的数据。\n\n【缺点】①通常需要加载整个XML文档来构造层次结构，消耗资源大。\n【解析详解】\n①构建Document对象：DocumentBuilderFactory dbf = DocumentBuilderFactory.newInstance();DocumentBuilder db = dbf.newDocumentBuilder();InputStream is = Thread.currentThread().getContextClassLoader().getResourceAsStream(xml文件);Document doc = db.parse(is);\n②遍历DOM对象\nDocument：    XML文档对象，由解析器获取\nNodeList：    节点数组\nNode：    节点(包括element、# text)\nElement：    元素，可用于获取属性参数\n\n\n\n(2)SAX(Simple API for XML)解析\n流型中的”推”模型分析方式。通过事件驱动，每发现一个节点就引发一个事件，事件推给事件处理器，通过回调方法完成解析工作，解析XML文档的逻辑需要应用程序完成\n\n【优势】\n①不需要等待所有数据都被处理，分析就能立即开始。\n②只在读取数据时检查数据，不需要保存在内存中。\n③可以在某个条件得到满足时停止解析，不必解析整个文档。\n④效率和性能较高，能解析大于系统内存的文档。\n\n【缺点】\n①需要应用程序自己负责TAG的处理逻辑（例如维护父/子关系等），文档越复杂程序就越复杂。\n②单向导航，无法定位文档层次，很难同时访问同一文档的不同部分数据，不支持XPath。\n\n【原理】简单的说就是对文档进行顺序扫描，当扫描到文档(document)开始与结束、元素(element)开始与结束时通知事件处理函数(回调函数)，进行相应处理，直到文档结束\n【事件处理器类型】\n①访问XML DTD：DTDHandler\n②低级访问解析错误：ErrorHandler\n③访问文档内容：ContextHandler\n\n【DefaultHandler类】SAX事件处理程序的默认基类，实现了DTDHandler、ErrorHandler、ContextHandler和EntityResolver接口，通常做法是，继承该基类，重写需要的方法，如startDocument()\n【创建SAX解析器】SAXParserFactory saxf = SAXParserFactory.newInstance();SAXParser sax = saxf.newSAXParser();\n注：关于遍历\n\n①深度优先遍历(Depthi-First Traserval)\n②广度优先遍历(Width-First Traserval)\n\n(3)JDOM(Java-based Document Object Model)\nJava特定的文档对象模型。自身不包含解析器，使用SAX\n\n【优点】\n①使用具体类而不是接口，简化了DOM的API。\n②大量使用了Java集合类，方便了Java开发人员。\n\n【缺点】\n①没有较好的灵活性。\n②性能较差。\n\n(4)DOM4J(Document Object Model for Java)\n简单易用，采用Java集合框架，并完全支持DOM、SAX和JAXP\n\n【优点】\n①大量使用了Java集合类，方便Java开发人员，同时提供一些提高性能的替代方法。\n②支持XPath。\n③有很好的性能。\n\n【缺点】\n①大量使用了接口，API较为复杂。\n\n(5)StAX(Streaming API for XML)\n流模型中的拉模型分析方式。提供基于指针和基于迭代器两种方式的支持,JDK1.6新特性\n\n【和推式解析相比的优点】\n①在拉式解析中，事件是由解析应用产生的，因此拉式解析中向客户端提供的是解析规则，而不是解析器。\n②同推式解析相比，拉式解析的代码更简单，而且不用那么多库。\n③拉式解析客户端能够一次读取多个XML文件。\n④拉式解析允许你过滤XML文件和跳过解析事件。\n\n【简介】StAX API的实现是使用了Java Web服务开发（JWSDP）1.6，并结合了Sun Java流式XML分析器(SJSXP)-它位于javax.xml.stream包中。XMLStreamReader接口用于分析一个XML文档，而XMLStreamWriter接口用于生成一个XML文档。XMLEventReader负责使用一个对象事件迭代子分析XML事件-这与XMLStreamReader所使用的光标机制形成对照。\n总结DOM4J\n","tags":["Java","XML"]},{"title":"Jenkins和SonarQube集成","url":"/2019/10/25/Jenkins%E5%92%8CSonarQube%E9%9B%86%E6%88%90/","content":"Jenkins和SonarQube集成安装插件SonarQube Scanner for Jenkins\n系统管理 - 插件管理\n可选插件（没有内容点立即获取）\n过滤 - 搜索SonarQube\n安装SonarQube Scanner for Jenkins\n安装成功 - 重启\n\n配置插件\n系统管理 - 系统设置 - SonarQube servers\n\n给项目配置启动SonarQube\n创建一个maven项目\n\n配置maven项目\n\n配置SonarQube构建环境 - Pre Steps/Post Steps - Add pre-build step - Execute SonarQube Scanner\n//多模块配置sonar.projectKey=project_keysonar.projectName=project_namesonar.projectVersion=1.0sonar.sourceEncoding=UTF-8sonar.modules=root,coreroot.sonar.projectBaseDir=./root.sonar.modules=com.thirdserviceroot.sonar.sources=src/main/javaroot.sonar.java.binaries=target/classescore.sonar.projectBaseDir=third/core/core.sonar.modules=com.bridgecore.sonar.sources=src/main/javacore.sonar.java.binaries=target/classes\n\n配置参数相关问题(注意)\n\n\nmysql参数设置问题17:08:15.777 DEBUG: Upload report17:08:22.648 DEBUG: POST 500 http:&#x2F;&#x2F;192.168.99.108:9000&#x2F;api&#x2F;ce&#x2F;submit?projectKey&#x3D;bi_build_sonar&amp;projectName&#x3D;bi_build_sonar | time&#x3D;6864ms17:08:22.662 INFO: ------------------------------------------------------------------------17:08:22.663 INFO: EXECUTION FAILURE17:08:22.663 INFO: ------------------------------------------------------------------------17:08:22.663 INFO: Total time: 5:01.152s17:08:22.951 INFO: Final Memory: 47M&#x2F;1469M17:08:22.951 INFO: ------------------------------------------------------------------------17:08:22.951 ERROR: Error during SonarQube Scanner execution17:08:22.951 ERROR: Failed to upload report - An error has occurred. Please contact your administratorWARN: Unable to locate &#39;report-task.txt&#39; in the workspace. Did the SonarScanner succeeded?ERROR: SonarQube scanner exited with non-zero code: 1\nSHOW VARIABLES LIKE &#39;max_allowed_packet&#39;;修改&#x2F;etc&#x2F;my.cnf文件：max_allowed_packet &#x3D; 100M\n\n\n","tags":["部署文档","Jenkins","SonarQube"]},{"title":"Jenkins安装部署","url":"/2019/10/22/Jenkins%E5%AE%89%E8%A3%85%E9%83%A8%E7%BD%B2/","content":"Jenkins搭建指南(CentOS7)\n下载链接\nwget -i https://pkg.jenkins.io/redhat-stable/jenkins-2.164.3-1.1.noarch.rpm\n安装手册\n\n软件要求\nJava\nMaven# 安装到 /opt/ 路径下tar xzvf apache-maven-3.6.1-bin.tar.gz -C /opt/\n# 修改系统环境变量vim /etc/profile\n在最后一行添加下面的内容# customer settingsexport JAVA_HOME=/usr/java/jdk1.8.0_211-amd64export MVN_HOME=/opt/apache-maven-3.6.1export PATH=$JAVA_HOME/bin:$MVN_HOME/bin:$PATH\nSubversionyum install subversion\n\n\n\n安装启动#安装rpm -i jenkins-2.164.3-1.1.noarch.rpm#启动service jenkins start\n\n配置项目系统管理 &gt; 插件管理 &gt; 可选插件SonarQube ScannerMaven Integration\n集成SonarQube全局工具配置JDKSonarQube ScannerMaven\n","tags":["部署文档","Jenkins"]},{"title":"MacBook实用技能","url":"/2019/12/24/MacBook%E5%AE%9E%E7%94%A8%E6%8A%80%E8%83%BD/","content":"系统快捷键\n\n\n键\n说明\n\n\n\n⌘⌥⎋\n强制退出\n\n\n重装系统https://support.apple.com/zh-cn/HT204904\n关闭自动更新AppStore → Preference → Automatically check for updates\n关于shell\n在 Mac 上将 zsh 用作默认 Shell\n\n配置环境变量\n# 旧版本Mac系统的环境变量，加载顺序为：/etc/profile\t\t\t\t\t\t\t\t/etc/paths~/.bash_profile~/.bash_login~/.profile~/.bashrc\n\nsudo vi /etc/zprofile# 中间用冒号隔开export PATH=$PATH:&lt;PATH 1&gt;:&lt;PATH 2&gt;:&lt;PATH 3&gt;:------:&lt;PATH N&gt;# environment variableexport JAVA_HOME=/Library/Java/JavaVirtualMachines/jdk1.8.0_231.jdk/Contents/Homeexport MVN_HOME=/opt/apache-maven-3.6.2export PATH=$JAVA_HOME/bin:$MVN_HOME/bin:$PATHexport CLASSPATH=.:$JAVA_HOME/lib\n\n修改主机名称\n\n在某些情况下，主机名称会改变成bogon，用下面这个命令修改\n\nsudo scutil --set HostName XXXX\n\n命令行下载\ncurl [options...] &lt;url&gt;-O, --remote-name   Write output to a file named as the remote file    --remote-name-all Use the remote file name for all URLscurl -O &lt;URL&gt;\n\n权限授予\n\n某些情况下，如果发现某些应用无法启动，可能是因为权限的问题\n\n# 查看当前路径下文件的全部权限ls -l# 授权chmod [ugoa...][[+-=][rwxX]...][,...]其中：u 表示该文件的拥有者，g 表示与该文件的拥有者属于同一个群体(group)者，o 表示其他以外的人，a 表示这三者皆是。+ 表示增加权限、- 表示取消权限、= 表示唯一设定权限。r 表示可读取，w 表示可写入，x 表示可执行，X 表示只有当该文件是个子目录或者该文件已经被设定过为可执行。r=4，w=2，x=1其他参数说明：-c : 若该文件权限确实已经更改，才显示其更改动作-f : 若该文件权限无法被更改也不要显示错误讯息-v : 显示权限变更的详细资料-R : 对目前目录下的所有文件与子目录进行相同的权限变更(即以递回的方式逐个变更)--help : 显示辅助说明--version : 显示版本\n\n\n\nGit命令\n一直没有遇到自己喜欢的图形化\n\n# 查看文件跟踪状态git status# 把文件加入到跟踪索引git add &lt;file&gt;# 移除文件跟踪，并且保留文件git rm --cached &lt;file&gt;\n\nIDEA常用快捷键(macOS)\n\n\n名称\n键\n说明\n\n\n\nImplementation(s)\n⌥⌘B\n查看实现类\n\n\nEvaluate Expression…\n⌥F8\nDEBUG模式下调试参数\n\n\nRun to Cursor\n⌥F9\n运行到这一行\n\n\nGenerate…\n⌘N\n代码生成\n\n\nFile…\n⇧⌘O\n文件打开\n\n\nFind Usages\n⌥F7\n查找类的使用\n\n\nShow Context Actions\n⌥↩\n导入依赖\n\n\nFind in Path…\n⇧⌘F\n在路径中查询\n\n\nReformat Code\n⌥⌘L\n格式化代码\n\n\nDelete Line\n⌘⌦\n删除一行\n\n\nLast Edit Location\n⇧⌘⌦\n退到上一次编辑的地方\n\n\n按键符号⌘ == Command⇧ == Shift⇪ == Caps Lock⌥ == Option⌃ == Control↩ == Return/Enter⌫ == Delete⌦ == 向前删除键（Fn+Delete）↑ == 上箭头↓ == 下箭头← == 左箭头→ == 右箭头⇞ == Page Up（Fn+↑）⇟ == Page Down（Fn+↓）Home == Fn + ←End == Fn + →⇥ == 右制表符（Tab键）⇤ == 左制表符（Shift+Tab）⎋ == Escape (Esc)⏏ == 电源开关键\n","tags":["Mac"]},{"title":"Maven打包介绍","url":"/2019/10/22/Maven%E6%89%93%E5%8C%85%E4%BB%8B%E7%BB%8D/","content":"依赖JAR方式一&lt;build&gt;    &lt;!--maven-assembly-plugin打包方式运行assembly:single--&gt;    &lt;plugins&gt;        &lt;plugin&gt;            &lt;artifactId&gt;maven-assembly-plugin&lt;/artifactId&gt;            &lt;version&gt;3.1.1&lt;/version&gt;            &lt;configuration&gt;                &lt;archive&gt;                    &lt;manifest&gt;                        &lt;mainClass&gt;com.yss.jdbc.util.Sample&lt;/mainClass&gt;                    &lt;/manifest&gt;                &lt;/archive&gt;                &lt;descriptorRefs&gt;                    &lt;descriptorRef&gt;jar-with-dependencies&lt;/descriptorRef&gt;                &lt;/descriptorRefs&gt;            &lt;/configuration&gt;            &lt;executions&gt;                &lt;execution&gt;                    &lt;id&gt;make-assembly&lt;/id&gt;  &lt;!--继承合并--&gt;                    &lt;phase&gt;package&lt;/phase&gt;  &lt;!--绑定到打包阶段--&gt;                    &lt;goals&gt;                        &lt;goal&gt;single&lt;/goal&gt;                    &lt;/goals&gt;                &lt;/execution&gt;            &lt;/executions&gt;        &lt;/plugin&gt;    &lt;/plugins&gt;&lt;/build&gt;\n方式二&lt;plugin&gt;    &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;    &lt;artifactId&gt;maven-jar-plugin&lt;/artifactId&gt;    &lt;version&gt;2.4&lt;/version&gt;    &lt;configuration&gt;        &lt;archive&gt;            &lt;addMavenDescriptor&gt;false&lt;/addMavenDescriptor&gt;            &lt;manifest&gt;&lt;!--MANIFEST.MF文件设置--&gt;                &lt;mainClass&gt;com.XX.Main&lt;/mainClass&gt;                &lt;addClasspath&gt;true&lt;/addClasspath&gt;                &lt;classpathPrefix&gt;lib/&lt;/classpathPrefix&gt;            &lt;/manifest&gt;        &lt;/archive&gt;        &lt;outputDirectory&gt;target/deploy/svntool&lt;/outputDirectory&gt;    &lt;/configuration&gt;&lt;/plugin&gt;&lt;plugin&gt;    &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;    &lt;artifactId&gt;maven-dependency-plugin&lt;/artifactId&gt;    &lt;version&gt;2.4&lt;/version&gt;    &lt;executions&gt;        &lt;execution&gt;            &lt;id&gt;copy-dependencies&lt;/id&gt;            &lt;phase&gt;package&lt;/phase&gt;            &lt;goals&gt;                &lt;goal&gt;copy-dependencies&lt;/goal&gt;            &lt;/goals&gt;            &lt;configuration&gt;                &lt;outputDirectory&gt;target/deploy/svntool/lib&lt;/outputDirectory&gt;            &lt;/configuration&gt;        &lt;/execution&gt;    &lt;/executions&gt;&lt;/plugin&gt;&lt;/plugins&gt;\n\n可执行JAR方式一&lt;build&gt;    &lt;!--maven-assembly-plugin打包方式运行assembly:single--&gt;    &lt;plugins&gt;        &lt;plugin&gt;            &lt;artifactId&gt;maven-assembly-plugin&lt;/artifactId&gt;            &lt;version&gt;3.1.1&lt;/version&gt;            &lt;configuration&gt;                &lt;archive&gt;                    &lt;manifest&gt;                        &lt;mainClass&gt;com.yss.jdbc.util.Sample&lt;/mainClass&gt;                    &lt;/manifest&gt;                &lt;/archive&gt;                &lt;descriptorRefs&gt;                    &lt;descriptorRef&gt;jar-with-dependencies&lt;/descriptorRef&gt;                &lt;/descriptorRefs&gt;            &lt;/configuration&gt;            &lt;executions&gt;                &lt;execution&gt;                    &lt;id&gt;make-assembly&lt;/id&gt;  &lt;!--继承合并--&gt;                    &lt;phase&gt;package&lt;/phase&gt;  &lt;!--绑定到打包阶段--&gt;                    &lt;goals&gt;                        &lt;goal&gt;single&lt;/goal&gt;                    &lt;/goals&gt;                &lt;/execution&gt;            &lt;/executions&gt;        &lt;/plugin&gt;    &lt;/plugins&gt;&lt;/build&gt;\n方式二&lt;plugin&gt;    &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;    &lt;artifactId&gt;maven-jar-plugin&lt;/artifactId&gt;    &lt;version&gt;2.4&lt;/version&gt;    &lt;configuration&gt;        &lt;archive&gt;            &lt;addMavenDescriptor&gt;false&lt;/addMavenDescriptor&gt;            &lt;manifest&gt;&lt;!--MANIFEST.MF文件设置--&gt;                &lt;mainClass&gt;com.XX.Main&lt;/mainClass&gt;                &lt;addClasspath&gt;true&lt;/addClasspath&gt;                &lt;classpathPrefix&gt;lib/&lt;/classpathPrefix&gt;            &lt;/manifest&gt;        &lt;/archive&gt;        &lt;outputDirectory&gt;target/deploy/svntool&lt;/outputDirectory&gt;    &lt;/configuration&gt;&lt;/plugin&gt;&lt;plugin&gt;    &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;    &lt;artifactId&gt;maven-dependency-plugin&lt;/artifactId&gt;    &lt;version&gt;2.4&lt;/version&gt;    &lt;executions&gt;        &lt;execution&gt;            &lt;id&gt;copy-dependencies&lt;/id&gt;            &lt;phase&gt;package&lt;/phase&gt;            &lt;goals&gt;                &lt;goal&gt;copy-dependencies&lt;/goal&gt;            &lt;/goals&gt;            &lt;configuration&gt;                &lt;outputDirectory&gt;target/deploy/svntool/lib&lt;/outputDirectory&gt;            &lt;/configuration&gt;        &lt;/execution&gt;    &lt;/executions&gt;&lt;/plugin&gt;&lt;/plugins&gt;\n生成JAR文件后增加时间戳自带属性实现&lt;properties&gt;    &lt;maven.build.timestamp.format&gt;yyyyMMddHHmmss&lt;/maven.build.timestamp.format&gt;&lt;/properties&gt;\n\n&lt;build&gt;    &lt;finalName&gt;        $&#123;project.artifactId&#125;-$&#123;project.version&#125;.$&#123;maven.build.timestamp&#125;    &lt;/finalName&gt;&lt;/build&gt;\n\nMaven自带时间戳使用${maven.build.timestamp}，但是时区是UTC。\n如果要使用GMT+8，就需要插件提供支持，以下两个插件可以实现。\nbuildnubmer-maven-plugin&lt;build&gt;    &lt;finalName&gt;        $&#123;project.artifactId&#125;-$&#123;project.version&#125;_$&#123;timestamp&#125;    &lt;/finalName&gt;    &lt;plugin&gt;        &lt;groupId&gt;org.codehaus.mojo&lt;/groupId&gt;        &lt;artifactId&gt;buildnumber-maven-plugin&lt;/artifactId&gt;        &lt;version&gt;1.4&lt;/version&gt;        &lt;configuration&gt;            &lt;timestampFormat&gt;yyyyMMdd&lt;/timestampFormat&gt;        &lt;/configuration&gt;        &lt;executions&gt;            &lt;execution&gt;                &lt;goals&gt;                    &lt;goal&gt;create-timestamp&lt;/goal&gt;                &lt;/goals&gt;            &lt;/execution&gt;        &lt;/executions&gt;        &lt;inherited&gt;false&lt;/inherited&gt;    &lt;/plugin&gt;&lt;/build&gt;\n\nbuild-helper-maven-plugin&lt;build&gt;    &lt;finalName&gt;ProjectName-$&#123;current.time&#125;&lt;/finalName&gt;    &lt;plugins&gt;        &lt;plugin&gt;            &lt;groupId&gt;org.codehaus.mojo&lt;/groupId&gt;            &lt;artifactId&gt;build-helper-maven-plugin&lt;/artifactId&gt;            &lt;version&gt;1.9.1&lt;/version&gt;            &lt;executions&gt;                &lt;execution&gt;                    &lt;id&gt;timestamp-property&lt;/id&gt;                    &lt;goals&gt;                        &lt;goal&gt;timestamp-property&lt;/goal&gt;                    &lt;/goals&gt;                &lt;/execution&gt;            &lt;/executions&gt;            &lt;configuration&gt;                &lt;name&gt;current.time&lt;/name&gt;                &lt;pattern&gt;yyyyMMdd-HHmmss&lt;/pattern&gt;                &lt;timeZone&gt;GMT+8&lt;/timeZone&gt;            &lt;/configuration&gt;        &lt;/plugin&gt;    &lt;/plugins&gt;&lt;/build&gt;\n","tags":["Maven"]},{"title":"Maven私服搭建","url":"/2020/03/10/Maven%E7%A7%81%E6%9C%8D%E6%90%AD%E5%BB%BA/","content":"Nexus\nhttps://help.sonatype.com/repomanager3/installation\n\n","tags":["部署文档","Maven"]},{"title":"MySQL复制-基于二进制日志文件","url":"/2020/04/17/MySQL-Replication-Binary/","content":"\n 参考文档\n\n修改配置文件\n 配置介绍\n\n\nMaster数据库\n\n编辑配置文件vim /etc/my.cnf，文件内容如下\n[mysqld]# 必须配置的服务id，一般配置主机的ipserver-id=168# 必须配置，开启二进制log-bin=mysql-bin# 下面都是可选配置# 要同步的数据库binlog-do-db=demo# 同步表# replicate-do-table=user\n\n\nSlave数据库\n\n修改配置文件如下\n[mysqld]# 必须配置server-id=169# 下面都是可选配置sync_binlog=0innodb_flush_log_at_trx_commit=2slave-skip-errors=all# 配置忽略的数据库# binlog-ignore-db=mysql# 配置同步的数据库# replicate-do-db=demo\n\n\n重启修改配置后的数据库\n\nsystemctl restart mysqld\n\n在Master创建用户用于同步CREATE USER &#39;slave&#39;@&#39;%&#39; IDENTIFIED BY &#39;123456&#39;;GRANT REPLICATION SLAVE ON *.* TO &#39;slave&#39;@&#39;%&#39;;flush privileges;\n\n查看Master二进制文件信息# 锁住全部表FLUSH TABLES WITH READ LOCK;# 同步完解锁unlock tables;# File和Position的参数是我们配置Slave的时候需要的SHOW MASTER STATUS;+------------------+----------+--------------+------------------+-------------------+| File             | Position | Binlog_Do_DB | Binlog_Ignore_DB | Executed_Gtid_Set |+------------------+----------+--------------+------------------+-------------------+| mysql-bin.000001 |     1077 |              |                  |                   |+------------------+----------+--------------+------------------+-------------------+\n\nSlave配置连接\n在Slave配置连接Master信息 命令详解\n\n登录MySQL命令控制台\n# MASTER_HOST 主机地址# MASTER_USER Master创建好的用户# MASTER_PASSWORD 密码# MASTER_PORT 端口，可选# MASTER_LOG_FILE 二进制文件名# MASTER_LOG_POS 开始同步位置CHANGE MASTER TO    MASTER_HOST&#x3D;&#39;192.168.99.168&#39;,    MASTER_USER&#x3D;&#39;slave&#39;,    MASTER_PASSWORD&#x3D;&#39;123456&#39;,    MASTER_PORT&#x3D;&#39;3306&#39;,    MASTER_LOG_FILE&#x3D;&#39;mysql-bin.000002&#39;,    MASTER_LOG_POS&#x3D;2216;\n\n\n启动\n\n# 启动start slave;\n\n\n查看Slave\n\n输入show slave status\\G，会显示类似如下\nmysql&gt; show slave status\\G;*************************** 1. row ***************************               Slave_IO_State: Waiting for master to send event                  Master_Host: 192.168.99.168                  Master_User: slave                  Master_Port: 3306                Connect_Retry: 60              Master_Log_File: mysql-bin.000003          Read_Master_Log_Pos: 700               Relay_Log_File: LENOVO-PC-relay-bin.000002                Relay_Log_Pos: 867        Relay_Master_Log_File: mysql-bin.000003             Slave_IO_Running: Yes            Slave_SQL_Running: Yes              Replicate_Do_DB: demo          Replicate_Ignore_DB: mysql           Replicate_Do_Table:       Replicate_Ignore_Table:      Replicate_Wild_Do_Table:  Replicate_Wild_Ignore_Table:                   Last_Errno: 0                   Last_Error:                 Skip_Counter: 0          Exec_Master_Log_Pos: 700              Relay_Log_Space: 1079              Until_Condition: None               Until_Log_File:                Until_Log_Pos: 0           Master_SSL_Allowed: No           Master_SSL_CA_File:           Master_SSL_CA_Path:              Master_SSL_Cert:            Master_SSL_Cipher:               Master_SSL_Key:        Seconds_Behind_Master: 0Master_SSL_Verify_Server_Cert: No                Last_IO_Errno: 0                Last_IO_Error:               Last_SQL_Errno: 0               Last_SQL_Error:  Replicate_Ignore_Server_Ids:             Master_Server_Id: 168                  Master_UUID: bd1531fb-f568-11e9-bc4b-46afd4d32e02             Master_Info_File: mysql.slave_master_info                    SQL_Delay: 0          SQL_Remaining_Delay: NULL      Slave_SQL_Running_State: Slave has read all relay log; waiting for more updates           Master_Retry_Count: 86400                  Master_Bind:      Last_IO_Error_Timestamp:     Last_SQL_Error_Timestamp:               Master_SSL_Crl:           Master_SSL_Crlpath:           Retrieved_Gtid_Set:            Executed_Gtid_Set:                Auto_Position: 0         Replicate_Rewrite_DB:                 Channel_Name:           Master_TLS_Version:       Master_public_key_path:        Get_master_public_key: 0            Network_Namespace:1 row in set (0.00 sec)ERROR:No query specified\n\n注意显示状态是这样表示成功连到Master：\nSlave_IO_Running: YesSlave_SQL_Running: Yes\n不是这个状态会有错误显示\n# 每次重新配置Slave需要停止stop slave\n\n注意事项\n配置前务必将两个数据库手工同步\n\n","tags":["MySQL","数据库"]},{"title":"MySQL复制-基于全局事务标识符","url":"/2020/04/17/MySQL-Replication-GTID/","content":"\n官方参考文档\n\n全局事务标识符全局事务标识符（GTID）是创建的唯一标识符，并且与在源服务器（主服务器）上提交的每个事务相关联。该标识符不仅对于它起源的服务器是唯一的，而且在给定复制拓扑中的所有服务器上也是唯一的。GTID表示为一对坐标，并用冒号（:）分隔，如下所示：\nGTID &#x3D; source_id:transaction_id\nsource_id：主服务器上的uuid\ntransaction_id：提交的事务id\n例如，最初要在服务器上使用UUID提交的第二十三笔交易 3E11FA47-71CA-11E1-9E33-C80AA9429562具有以下GTID：3E11FA47-71CA-11E1-9E33-C80AA9429562:23\nGTID集：2174B383-5441-11E8-B90A-C80AA9429562:1-3, 24DA167-0C0C-11E8-8442-00059A3C7B00:1-19\n事务的GTID通过mysqlbinlog命令可以查询出来\n设置复制1. 如果复制已经在运行，则通过将它们设置为只读来同步两个服务器。SET @@GLOBAL.read_only &#x3D; ON;\n\n通过上面的命令，使主从都变成只读状态，然后开始同步。\n2. 停止两个服务器。3. 重新启动两个启用了GTID并配置了正确选项的服务器。\n主服务器配置\n\n###########必须############server-id=142log-bin=mysql-bingtid_mode=ONenforce-gtid-consistency=ON###########可选############\n\n\n从服务器配置\n\n###########必须############server-id=168gtid_mode=ONenforce-gtid-consistency=ON###########可选############\n\n4. 指示从属服务器将主服务器用作复制数据源并使用自动定位在从服务器端执行\nCHANGE MASTER TO  MASTER_HOST &#x3D; host,  MASTER_PORT &#x3D; port,  MASTER_USER &#x3D; user,  MASTER_PASSWORD &#x3D; password,  MASTER_AUTO_POSITION &#x3D; 1;\n\n5. 进行新的备份包含没有GTID的事务的二进制日志不能在启用了GTID的服务器上使用，因此在此之前进行的备份不能与新配置一起使用。\n在主服务器端执行\nFLUSH LOGS\n\n6. 启动从属服务器，然后在两台服务器上禁用只读模式，以便它们可以接受更新。START SLAVE;\n\nSET @@GLOBAL.read_only &#x3D; OFF;\n","tags":["MySQL","数据库"]},{"title":"MySQL性能优化","url":"/2019/11/12/MySQL%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/","content":"慢查询配置\nMySQL的慢查询日志是MySQL提供的一种日志记录，它是用来记录在MySQL中响应时间超过阀值的语句。系统默认情况下，MySQL并不启动慢查询日志，需要我们手动来设置这个参数，当然，如果不是调优需要的话，一般不建议启动该参数，因为开启慢查询日志会或多或少带来一定的性能影响。\n\n默认情况下slow_query_log的值为OFF，表示慢查询日志是禁用的，可以通过设置slow_query_log的值来开启，如下所示：\nmysql&gt; show variables like &#39;%slow_query_log%&#39;+---------------------+-------------------------------+| Variable_name       | Value                         |+---------------------+-------------------------------+| slow_query_log      | OFF                           || slow_query_log_file | &#x2F;var&#x2F;lib&#x2F;mysql&#x2F;mysql-slow.log |+---------------------+-------------------------------+2 rows in set (0.00 sec)\n\n开启慢查询日志：\nmysql&gt; set global slow_query_log&#x3D;1;Query OK, 0 rows affected (0.00 sec)\n\n然后看状态：\nmysql&gt; show variables like &#39;%slow_query_log%&#39;;+---------------------+-------------------------------+| Variable_name       | Value                         |+---------------------+-------------------------------+| slow_query_log      | ON                            || slow_query_log_file | &#x2F;var&#x2F;lib&#x2F;mysql&#x2F;mysql-slow.log |+---------------------+-------------------------------+2 rows in set (0.00 sec)\n\n使用set global slow_query_log=1开启了慢查询日志只对当前数据库生效，如果MySQL重启后则会失效。如果要永久生效，就必须修改配置文件my.cnf（其它系统变量也是如此）。\n例如如下所示：\n[root@mysql ~]# vim &#x2F;etc&#x2F;my.cnfslow_query_log&#x3D;1slow_query_log_file&#x3D;&#x2F;var&#x2F;lib&#x2F;mysql&#x2F;mysql-slow.log\n\n参数说明：\n\nslow_query_log 慢查询开启状态；\nslow_query_log_file 慢查询日志存放的位置；\nlong_query_time查询超过多少秒才记录。\n\n日志分析工具\n MySQL 自带了一个查看慢日志的工具 mysqldumpslow，执行mysqldumpslow –help 可以查看其相关参数和说明：\n\n[root@mysql ~]# mysqldumpslow --helpUsage: mysqldumpslow [ OPTS... ] [ LOGS... ]Parse and summarize the MySQL slow query log. Options are  --verbose    verbose  --debug      debug  --help       write this text to standard output  -v           verbose  -d           debug  -s ORDER     what to sort by (al, at, ar, c, l, r, t), &#39;at&#39; is default                al: average lock time                ar: average rows sent                at: average query time                 c: count                 l: lock time                 r: rows sent                 t: query time  -r           reverse the sort order (largest last instead of first)  -t NUM       just show the top n queries  -a           don&#39;t abstract all numbers to N and strings to &#39;S&#39;  -n NUM       abstract numbers with at least n digits within names  -g PATTERN   grep: only consider stmts that include this string  -h HOSTNAME  hostname of db server for *-slow.log filename (can be wildcard),               default is &#39;*&#39;, i.e. match all  -i NAME      name of server instance (if using mysql.server startup script)  -l           don&#39;t subtract lock time from total time\n\n参数解释：\n\n-s:是表示按照何种方式排序；\nc: 访问计数；\nl: 锁定时间；\nr: 返回记录；\nt: 查询时间；\nal:平均锁定时间；\nar:平均返回记录数；\nat:平均查询时间；\n-t:是top n的意思，即为返回前面多少条的数据；\n-g:后边可以写一个正则匹配模式，大小写不敏感的。\n\n例如，得到返回记录集最多的10个SQL：\nmysqldumpslow -s r -t 10 /mysql/mysql_slow.log\n\n得到访问次数最多的10个SQL：\nmysqldumpslow -s c -t 10 /mysql/mysql_slow.log\n","tags":["MySQL","数据库"]},{"title":"Netty源码分析","url":"/2020/07/08/Netty%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90/","content":"一、介绍官网：https://netty.io/\nNetty是一个NIO客户端服务端框架。\n二、要素ChannelHandler处理和拦截I/O操作，并且将处理后的数据传至下一个管道\n三、源码分析Netty版本：4.1.44.Final\nChannelHandler调用过程注册ServerBootstrap.childHandler(ChannelHandler childHandler)\nprivate void register0(ChannelPromise promise) &#123;    try &#123;        // check if the channel is still open as it could be closed in the mean time when the register        // call was outside of the eventLoop        if (!promise.setUncancellable() || !ensureOpen(promise)) &#123;            return;        &#125;        boolean firstRegistration = neverRegistered;        doRegister();        neverRegistered = false;        registered = true;        // Ensure we call handlerAdded(...) before we actually notify the promise. This is needed as the        // user may already fire events through the pipeline in the ChannelFutureListener.        pipeline.invokeHandlerAddedIfNeeded();        safeSetSuccess(promise);        pipeline.fireChannelRegistered();        // Only fire a channelActive if the channel has never been registered. This prevents firing        // multiple channel actives if the channel is deregistered and re-registered.        if (isActive()) &#123;            if (firstRegistration) &#123;                pipeline.fireChannelActive();            &#125; else if (config().isAutoRead()) &#123;                // This channel was registered before and autoRead() is set. This means we need to begin read                // again so that we process inbound data.                //                // See https://github.com/netty/netty/issues/4805                beginRead();            &#125;        &#125;    &#125; catch (Throwable t) &#123;        // Close the channel directly to avoid FD leak.        closeForcibly();        closeFuture.setClosed();        safeSetFailure(promise, t);    &#125;&#125;\n\n四、相关文章认真的 Netty 源码解析（一）\n认真的 Netty 源码解析（二）\nhttps://www.jianshu.com/nb/22889712\nhttps://www.jianshu.com/p/46861a05ce1e\n","tags":["Java","Netty"]},{"title":"Oracle历史记录","url":"/2020/06/03/Oracle%E5%8E%86%E5%8F%B2%E8%AE%B0%E5%BD%95/","content":"&#x2F;*分为四步 *&#x2F;&#x2F;*第1步：创建临时表空间  *&#x2F;create temporary tablespace yuhang_temptempfile &#39;D:\\oracledata\\yuhang_temp.dbf&#39;size 50mautoextend onnext 50m maxsize 20480mextent management local;&#x2F;*第2步：创建数据表空间  *&#x2F;create tablespace yuhang_dataloggingdatafile &#39;D:\\oracledata\\yuhang_data.dbf&#39;size 50mautoextend onnext 50m maxsize 20480mextent management local;&#x2F;*第3步：创建用户并指定表空间  *&#x2F;create user yuhang identified by yuhangdefault tablespace yuhang_datatemporary tablespace yuhang_temp;&#x2F;*第4步：给用户授予权限  *&#x2F;grant connect,resource,dba to yuhang;\n","tags":["数据库","Oracle","SQL"]},{"title":"Quartz框架介绍","url":"/2020/06/03/Quartz%E6%A1%86%E6%9E%B6%E4%BB%8B%E7%BB%8D/","content":"\nhttps://www.w3cschool.cn/quartz_doc/\n\n我们需要明白 Quartz 的几个核心概念，这样理解起 Quartz 的原理就会变得简单了。\n\nJob\n表示一个工作，要执行的具体内容。此接口中只有一个方法，如下：\n\n\nvoid execute(JobExecutionContext context)\n\nJobDetail\n表示一个具体的可执行的调度程序，Job 是这个可执行程调度程序所要执行的内容，另外 JobDetail 还包含了这个任务调度的方案和策略。\n\nTrigger\n代表一个调度参数的配置，什么时候去调。\n\nScheduler\n代表一个调度容器，一个调度容器中可以注册多个 JobDetail 和 Trigger。当 Trigger 与 JobDetail 组合，就可以被 Scheduler 容器调度了。\n\n\n示例代码：\nScheduler scheduler = StdSchedulerFactory.getDefaultScheduler();// and start it offscheduler.start();// define the job and tie it to our HelloJob classJobDetail job = newJob(HelloJob.class)    .withIdentity(\"job1\", \"group1\")    .usingJobData(\"COUNT\", 1)    .build();// Trigger the job to run now, and then repeat every 40 secondsTrigger trigger = newTrigger()    .withIdentity(\"trigger1\", \"group1\")    .startNow()    .withSchedule(simpleSchedule()                  .withIntervalInSeconds(1)                  .repeatForever())    .build();// Tell apacheusage.quartz to schedule the job using our triggerscheduler.scheduleJob(job, trigger);// scheduler.shutdown();\n","tags":["Java"]},{"title":"RPC框架介绍","url":"/2020/02/28/RPC%E6%A1%86%E6%9E%B6%E4%BB%8B%E7%BB%8D/","content":"RMIC:\\Program Files\\Java\\jdk1.8.0_211\\jre\\lib\\rt.jar!\\java\\rmi\nHessian","tags":["RPC"]},{"title":"R语言开发环境部署","url":"/2019/10/23/R%E5%BC%80%E5%8F%91%E7%8E%AF%E5%A2%83%E9%83%A8%E7%BD%B2/","content":"R语言介绍：R是用于统计分析、绘图的语言和操作环境。R是属于GNU系统的一个自由、免费、源代码开放的软件，它是一个用于统计计算和统计制图的优秀工具。\nR语言开发环境\n官方网站\n下载地址\n\nR语言开发工具 RStudio\n官方网站\n下载地址\n\n相关学习网站：https://www.w3cschool.cn/r/r_environment_setup.html\n未完待续。。。\n","tags":["部署文档","R"]},{"title":"SQL指南","url":"/2020/09/01/SQL%E6%8C%87%E5%8D%97/","content":""},{"title":"PING命令使用","url":"/2019/11/04/PING%E5%91%BD%E4%BB%A4%E4%BD%BF%E7%94%A8/","content":"一、ping基本使用详解在网络中ping是一个十分强大的TCP/IP工具。它的作用主要为：\n\n用来检测网络的连通情况和分析网络速度\n\n根据域名得到服务器IP\n\n根据ping返回的TTL值来判断对方所使用的操作系统及数据包经过路由器数量。\n\n\n我们通常会用它来直接ping ip地址，来测试网络的连通情况。\n\n类如这种，直接ping ip地址或网关，ping通会显示出以上数据，有朋友可能会问，bytes=32；time&lt;1ms；TTL=128 这些是什么意思。\nbytes值：数据包大小，也就是字节。\ntime值：响应时间，这个时间越小，说明你连接这个地址速度越快。\nTTL值：Time To Live,表示DNS记录在DNS服务器上存在的时间，它是IP协议包的一个值，告诉路由器该数据包何时需要被丢弃。可以通过Ping返回的TTL值大小，粗略地判断目标系统类型是Windows系列还是UNIX/Linux系列。\n默认情况下，Linux系统的TTL值为64或255，WindowsNT/2000/XP系统的TTL值为128，Windows98系统的TTL值为32，UNIX主机的TTL值为255。\n因此一般TTL值：\n100~130ms之间，Windows系统 ；\n240~255ms之间，UNIX/Linux系统。\n当然，我们今天主要了解并不是这些，而是ping的其它参考。\nping命令除了直接ping网络的ip地址，验证网络畅通和速度之外，它还有这些用法。\n\n二、ping -t的使用不间断地Ping指定计算机，直到管理员中断。\n\n这就说明电脑连接路由器是通的，网络效果很好。下面按按住键盘的Ctrl+c终止它继续ping下去，就会停止了，会总结出运行的数据包有多少，通断的有多少了。\n三、ping -a的使用ping-a解析计算机名与NetBios名。就是可以通过ping它的ip地址，可以解析出主机名。\n\n四、ping -n的使用在默认情况下，一般都只发送四个数据包，通过这个命令可以自己定义发送的个数，对衡量网络速度很有帮助，比如我想测试发送10个数据包的返回的平均时间为多少，最快时间为多少，最慢时间为多少就可以通过以下获知：\n\n从以上我就可以知道在给47.93.187.142发送10个数据包的过程当中，返回了10个，没有丢失，这10个数据包当中返回速度最快为32ms，最慢为55ms，平均速度为37ms。说明我的网络良好。\n如果对于一些不好的网络，比如监控系统中非常卡顿，这样测试，返回的结果可能会显示出丢失出一部分，如果丢失的比较多的话，那么就说明网络不好，可以很直观的判断出网络的情况。\n五、ping -l size的使用-l size：发送size指定大小的到目标主机的数据包。\n在默认的情况下Windows的ping发送的数据包大小为32byte，最大能发送65500byte。当一次发送的数据包大于或等于65500byte时，将可能导致接收方计算机宕机。所以微软限制了这一数值；这个参数配合其它参数以后危害非常强大，比如攻击者可以结合-t参数实施DOS攻击。（所以它具有危险性，不要轻易向别人计算机使用）。\n例如：ping -l 65500 -t  211.84.7.46\n会连续对IP地址执行ping命令，直到被用户以Ctrl+C中断.\n\n这样它就会不停的向211.84.7.46计算机发送大小为65500byte的数据包，如果你只有一台计算机也许没有什么效果，但如果有很多计算机那么就可以使对方完全瘫痪，网络严重堵塞，由此可见威力非同小可。\n六、ping -r count的使用在“记录路由”字段中记录传出和返回数据包的路由，探测经过的\n路由个数，但最多只能跟踪到9个路由。\nping -n 1 -r 9 202.102.224.25 （发送一个数据包，最多记录9个路由）\n\n将经过 9个路由都显示出来了，可以看上图。\nping命令用的较多的就这6类的，大家有可能在项目中会用到的。\n七、批量ping网段对于一个网段ip地址众多，如果单个检测实在麻烦，那么我们可以直接批量ping网段检测，那个ip地址出了问题，一目了然。\n先看代码，直接在命令行窗口输入：\nfor /L %D in (1,1,255) do ping 10.168.1.%D\nIP地址段修改成你要检查的IP地址段。\n\n当输入批量命令后，那么它就自动把网段内所有的ip地址都ping完为止。\n那么这段for /L %D in(1,1,255) do ping 10.168.1.%D 代码是什么意思呢？\n代码中的这个(1,1,255)就是网段起与始，就是检测网段192.168.1.1到192.168.1.255之间的所有的ip地址，每次逐增1，直接到1到255这255个ip检测完为止。\n"},{"title":"Nginx-安装部署","url":"/2019/11/12/Nginx%E5%AE%89%E8%A3%85%E9%83%A8%E7%BD%B2/","content":"下载\n官方下载\n文档\n\n安装解压到安装路径即可\n启动nginx -s [ stop | quit | reopen | reload ]\n","tags":["部署文档","Nginx"]},{"title":"SonarQube安装部署","url":"/2019/10/23/SonarQube%E5%AE%89%E8%A3%85%E9%83%A8%E7%BD%B2/","content":"\n详细查看官方文档\n\n安装前准备环境Centos7(Linux version 3.10.0-957.el7.x86_64):vm.max_map_count 大于或等于262144fs.file-max 大于或等于65536运行SonarQube的用户可以打开至少65536个文件描述符运行SonarQube的用户可以打开至少2048个线程\nOracle JRE 8下载链接    - 选择jdk-8u211-linux-x64.rpm下载\n# 查看安装的路径rpm -qpl jdk-8u211-linux-x64.rpm## 安装rpm -i jdk-8u211-linux-x64.rpm\nMySQL 5.7下载链接 参考文档\n下载mysql80-community-release-el7-3.noarch.rpm\n# 安装rpm源sudo rpm -Uvh mysql80-community-release-el7-3.noarch.rpm# 编辑，找到Enable to use MySQL 5.7，改为enabled=1，其他版本设置成enabled=0vim /etc/yum.repos.d/mysql-community.repo# 检查只有MySQL 5.7启动yum repolist enabled | grep mysql# 安装MySQLsudo yum install mysql-community-server# 启动MySQL服务器sudo service mysqld start# MySQL服务器的状态sudo service mysqld status# 查看超级用户的密码sudo grep 'temporary password' /var/log/mysqld.log# 登录mysqlmysql -uroot -p# 修改密码ALTER USER 'root'@'localhost' IDENTIFIED BY 'MyNewPass4!';# 修改密码校验set global validate_password_policy=0;set global validate_password_length=1;# 默认mysql的root用户不支持远程访问，开启访问权限GRANT ALL ON *.* TO root@'%' IDENTIFIED BY '123456' WITH GRANT OPTION;update user set host='%' where user='root';flush privileges;# 创建数据库sonarqubeCREATE DATABASE `sonarqube` CHARACTER SET 'utf8';新增用户sonarqube并授予sonarqube数据库全部权限rant all privileges on sonarqube.* to sonarqube@'%' identified by \"password\";开启3306端口irewall-cmd --add-port=3306/tcp(a)数据库目录var/lib/mysql/(b)配置文件usr/share /mysql（mysql.server命令及配置文件）etc/my.cnf(c)相关命令/usr/bin（mysqladmin mysqldump等命令）# (d)启动脚本/etc/rc.d/init.d/（启动脚本文件mysql的目录）\n安装SonarQube1. 下载 SonarQube当前版本： 7.7 下载链接\n2. 解压得到当前路径: /opt/sonarqube-7.7\n3. 修改配置文件vim /opt/sonarqube-7.7/conf/sonar.properties\n# 对应的数据库信息sonar.jdbc.username=sonar.jdbc.password=sonar.jdbc.url=\n4. 新增用户SonarQube不能以root启动\n# 添加用户adduser sonarqube# 设置密码passwd sonarqube# 授权chown -R sonarqube:sonarqube /opt/sonarqube-7.7\n5.默认SonarQube启动在9000端口firewall-cmd --add-port=9000/tcpsystemctl stop firewalldsystemctl disable firewalld\n6.以服务启动SonarQube\n创建文件\n\nvim /etc/systemd/system/sonarqube.service\n\n\n添加下面内容：\n\n[Unit]Description=SonarQube serviceAfter=syslog.target network.target[Service]Type=simpleUser=sonarqubeGroup=sonarqubePermissionsStartOnly=trueExecStart=/bin/nohup /bin/java -Xms32m -Xmx32m -Djava.net.preferIPv4Stack=true -jar /opt/sonarqube-7.7/lib/sonar-application-7.7.jarStandardOutput=syslogLimitNOFILE=65536LimitNPROC=8192TimeoutStartSec=5Restart=always[Install]WantedBy=multi-user.target\n\n\n安装启动\n\nsu sonarqube# 注册服务sudo systemctl enable sonarqube.service# 启动服务sudo systemctl start sonarqube.service# 重启sudo systemctl restart sonarqube.service\n\n查看日志\n\nvim /opt/sonarqube-7.7/logs/web.log\n\n常见问题\n使用sudo命令时，出现问题：\n\n\n​         编辑vim /etc/sudoers\nroot    ALL=(ALL:ALL) ALLsonarqube    ALL=(ALL:ALL) ALL\n\n\n扫描成功但是上传失败\n\n可能是因为mysql数据库上传数据限制了包的大小，查看web.log日志\nCaused by: com.mysql.jdbc.PacketTooBigException: Packet for query is too large (6980220 &gt; 4194304). You can change this value on the server by setting the max_allowed_packet&#39; variable.\n\n# For advice on how to change settings please see# http://dev.mysql.com/doc/refman/5.7/en/server-configuration-defaults.html[mysqld]max_allowed_packet=100M\n","tags":["部署文档","SonarQube"]},{"title":"SQL历史记录","url":"/2019/10/22/SQL%E5%8E%86%E5%8F%B2%E8%AE%B0%E5%BD%95/","content":"SQL历史记录select logon_time,       last_call_et \"time inactive\",       nvl(s.username, 'ORACLE PROCESS') username,       s.machine,       s.program,       s.sid session_id,       s.status,       sql_text,       ss.value \"CPU used\",       trunc(buffer_gets / (executions + 1)) \"BUFF-EXEC\",       trunc(buffer_gets / (rows_processed + 1)) \"BUFF-ROWS\",       first_load_time,       executions,       parse_calls,       disk_reads,       buffer_gets,       rows_processed  from v$session s, v$sesstat ss, v$statname sn, v$sqlarea sawhere s.sid = ss.sid   and ss.statistic# = sn.statistic#   and sn.name = 'CPU used by this session'   and s.sql_address = sa.address   and s.sql_hash_value = sa.hash_value   and last_call_et &gt; 5000  --超过5秒不释放的sqlorder by machine, status, program, last_call_et asc;\n\nselect ss.value \"CPU used\",       sa.SQL_FULLTEXT,       sql_text,       s.status,       last_call_et \"time inactive\",       nvl(s.username, 'ORACLE PROCESS') username,       s.sid,     s.serial#,       logon_time,       s.machine,       s.program,       s.sid session_id,       trunc(buffer_gets / (executions + 1)) \"BUFF-EXEC\",       trunc(buffer_gets / (rows_processed + 1)) \"BUFF-ROWS\",       first_load_time,       executions,       parse_calls,       disk_reads,       buffer_gets,       rows_processed  from v$session s, v$sesstat ss, v$statname sn, v$sqlarea sa where s.sid = ss.sid   and ss.statistic# = sn.statistic#   and sn.name = 'CPU used by this session'   and s.sql_address = sa.address   and s.sql_hash_value = sa.hash_value--   and status='ACTIVE'--   and username=''--   and last_call_et &gt; 1000 order by ss.value desc\nbigint类型转换为datetime类型假设 1164691264437 是 Java 里的“日期时间”：即：自1970-01-01 00:00:00以来的毫秒数\nmysql&gt; select from_unixtime(1164691264437&#x2F;1000);+-----------------------------------+| from_unixtime(1164691264437&#x2F;1000) |+-----------------------------------+| 2006-11-28 13:21:04               |+-----------------------------------+\ndatetime类型转换为bigint类型假设 “2011-05-31 23:59:59” 是 Java 里的“日期时间”：即：自1970-01-01 00:00:00以来的毫秒数\nmysql&gt; select UNIX_TIMESTAMP(&#39;2011-05-31 23:59:59&#39;);+-----------------------------------+| from_unixtime(1306857599&#x2F;1000) |+-----------------------------------+\n\nMYSQL查询锁# 查询是否锁表show OPEN TABLES where In_use &gt; 0;# 查看所有进程# MySQL:show processlist;# mariabd:show full processlist;# 杀掉指定mysql连接的进程号kill $pid# 查看正在锁的事务SELECT * FROM INFORMATION_SCHEMA.INNODB_LOCKS;# 查看等待锁的事务SELECT * FROM INFORMATION_SCHEMA.INNODB_LOCK_WAITS;# 查看innodb引擎的运行时信息show engine innodb status\\G;# 查看造成死锁的sql语句，分析索引情况，然后优化sql语句；# 查看服务器状态show status like &#39;%lock%&#39;;# 查看超时时间：show variables like &#39;%timeout%&#39;;\n","tags":["SQL"]},{"title":"SonarQube插件开发","url":"/2020/05/11/SonarQube%E6%8F%92%E4%BB%B6%E5%BC%80%E5%8F%91/","content":"\n官方文档\n最近涉及到开发sonarqube的一些插件工作，记录一下工作需要的内容。\n\nSonarQube开发分为三部分：web服务开发、计算引擎开发、扫描开发。针对这三种开发方式，其官方为我们提供了三种远程调试方式。\nDebugging web server extensions\n修改配置文件：conf/sonar.properties\nsonar.web.javaAdditionalOpts=-agentlib:jdwp=transport=dt_socket,server=y,suspend=y,address=8000\n\nDebugging compute engine extensions\n修改配置文件：conf/sonar.properties\nsonar.ce.javaAdditionalOpts=-agentlib:jdwp=transport=dt_socket,server=y,suspend=y,address=8000\n\nDebugging scanner extensions\n控制台命令窗口设置环境变量\nexport SONAR_SCANNER_OPTS=\"-agentlib:jdwp=transport=dt_socket,server=y,suspend=y,address=8000\"\nset SONAR_SCANNER_OPTS=\"-agentlib:jdwp=transport=dt_socket,server=y,suspend=y,address=8000\"\n然后在需要检查的代码根路径执行扫描\nmvnDebug sonar:sonar\n或者\nsonar-scanner\n","tags":["SonarQube"]},{"title":"Wireshark操作指南","url":"/2020/07/22/Wireshark%E6%93%8D%E4%BD%9C%E6%8C%87%E5%8D%97/","content":"简介就不介绍了，百度去吧。附上下载地址\nhttps://www.wireshark.org/download.html\n操作记录查看数据包是哪个进程发送的\n背景：今天使用wireshark分析数据包，看到一个奇怪的包。我什么时候给小米请求东西了。\n\n\n\n选择这个包，我们看到下面一系列参数，Src Port：64240说明我们这个端口被占用\n\n\n\n打开命令提示符，查询这个端口被PID为8536的进程占用\n\nC:\\Users\\lenovo&gt;netstat -ano|findstr 64240  TCP    192.168.96.142:64240   118.26.252.226:5222    ESTABLISHED     8536\n\n\n开始想到打开任务管理器，结果发现没有这个PID\n\n\n\n可以使用命令提示符\n\nC:\\Users\\lenovo&gt;tasklist|findstr 8536wps.exe                       8536 Console                    1     12,000 K\n\n\n系统工具里面有个资源监视器，找不到可以直接搜索，打开，选择网路，然后PID排个序就找到8536了，原来是WPS，太坑了，立马干掉他\n\n\n\n相关命令\n\ntaskkill /f /t /im Tencentdl.exe\n\nFoxmail收取邮件发生了什么\n","tags":["Wireshark"]},{"title":"char、varchar、varchar2的区别","url":"/2020/04/08/char%E3%80%81varchar%E3%80%81varchar2%E7%9A%84%E5%8C%BA%E5%88%AB/","content":"1、长度上的区别\nCHAR的长度是固定的，VARCHAR2的长度是可以变化的。\n例如，存储字符zhidao串“abc”，对于CHAR (20)，表示存储的字符占20个字节，而同样的VARCHAR2 (20)就只占3个字节的长度，20只是最大值，而且当存储的字符小于20时，按实际的长度来存储。\n2、意义上的区别\nVARCHAR是VARCHAR2的同义词，工业标准的VARCHAR类型可以用来存储空字符串，但是Oracle自己开发了一个数据类型VARCHAR2，这个类型不是一个标准的VARCHAR，它在数据库中varchar列可以存储空字符串的特性改为存储NULL值。\n\n3、空间大小上的区别\nVARCHAR2比CHAR要节省空间，VARCHAR2在效率上也比CHAR差一些，所以如果想获得效率，就必须牺牲一定的空间，这就是在数据库设计上常说的‘以空间换效率’。\nVARCHAR2虽然比CHAR节省空间，但如果一个VARCHAR2列经常被修改，且每次被修改数据的长度不同会引起‘行迁移’现象。\n","tags":["数据库","Oracle"]},{"title":"javaagent开发指南","url":"/2020/04/15/javaagent%E5%BC%80%E5%8F%91%E6%8C%87%E5%8D%97/","content":"场景：你需要在Java进程中获取所有已知加载类的字节码。或者你想要调试运行时发生的某种类型的instrumentation。\n看这篇文章前你需要了解：Java字节码。\n下面介绍如何获取加载到JVM中的所有类的字节码。\njavaagent\n通常，我们可以把javaagent当成一个JVM插件。一种专门的jar文件，它可以利用JVM提供的InstrumentationAPI。Java1.5提供了InstrumentationAPI。\n\n\n成功创建一个javaagent需要三个环节：\n代理类代理类必须有premain方法，当Java虚拟机启动时，在执行main函数之前，JVM会先运行-javaagent所指定jar包内Premain-Class这个类的premain方法，其中，该方法可以签名如下：\n\npublicstaticvoidpremain(StringagentArgs,Instrumentationinst)\npublicstaticvoidpremain(StringagentArgs)\n\nJVM会优先加载1签名的方法，加载成功忽略2，如果1没有，加载2方法。这个逻辑在sun.instrument.InstrumentationImpl类中。\n一些元信息（告诉JVM为我们的代理类提供哪些功能）定义一个MANIFEST.MF文件，必须包含Premain-Class选项，且指定我们的代理类，通常也会加入Can-Redefine-Classes和Can-Retransform-Classes选项。\n将代理类和MANIFEST.MF文件打成jar包。\n一种使JVM加载jar文件和代理的方式使用参数-javaagent:agent.jar=[agentArgs]启动要代理类中的premain方法。例如：\njava-javaagent:sample-agent.jar=hello-jarsample-release.jar\n\n\nagentmain\n定义一个MANIFEST.MF文件，文件中必须包含Agent-Class\n创建一个Agent-Class指定的类，该类必须包含agentmain方法（参数和premian相同）\n将MANIFEST.MF和Agent类打成jar包\n将jar包载入目标虚拟机。目标虚拟机将会自动执行agentmain方法执行方法逻辑，同时，ClassFileTransformer也会长期有效，在每一个类加载器加载Class的时候都会拦截\n\n\n相关文章：https://www.cnblogs.com/stateis0/p/9062199.htmlhttps://www.cnblogs.com/stateis0/p/9062201.htmlhttps://www.jrebel.com/blog/java-bytecode-tutorialhttps://blogs.oracle.com/ouchina/javaagent\n","tags":["Java"]},{"title":"二叉树遍历","url":"/2020/04/01/%E4%BA%8C%E5%8F%89%E6%A0%91%E9%81%8D%E5%8E%86/","content":"\n二叉树遍历有三种遍历方式，前、中、后。这些不多介绍了。\n如果使用代码实现有可以有多种不同的方式。本文着重讲解这几种方式，并且探究不同方式的时间和空间复杂度。\n\n定义二叉树public class TreeNode &#123;    int val;    TreeNode left;    TreeNode right;    TreeNode(int x) &#123;        val = x;    &#125;&#125;\n\n前序遍历递归法public static void preorderTraversal(TreeNode root) &#123;    if (root != null) &#123;        System.out.println(root.val);        preorderTraversal(root.left);        preorderTraversal(root.right);    &#125;&#125;\n\n迭代法public List&lt;Integer&gt; preorderTraversal(TreeNode root) &#123;    LinkedList&lt;TreeNode&gt; stack = new LinkedList&lt;&gt;();    LinkedList&lt;Integer&gt; output = new LinkedList&lt;&gt;();    if (root == null) &#123;        return output;    &#125;    stack.add(root);    while (!stack.isEmpty()) &#123;        TreeNode node = stack.pollLast();        output.add(node.val);        if (node.right != null) &#123;            stack.add(node.right);        &#125;        if (node.left != null) &#123;            stack.add(node.left);        &#125;    &#125;    return output;&#125;\n\n莫里斯法public List&lt;Integer&gt; preorderTraversal(TreeNode root) &#123;    LinkedList&lt;Integer&gt; output = new LinkedList&lt;&gt;();    TreeNode node = root;    while (node != null) &#123;        if (node.left == null) &#123;            output.add(node.val);            node = node.right;        &#125;        else &#123;            TreeNode predecessor = node.left;            while ((predecessor.right != null) &amp;&amp; (predecessor.right != node)) &#123;                predecessor = predecessor.right;            &#125;            if (predecessor.right == null) &#123;                output.add(node.val);                predecessor.right = node;                node = node.left;            &#125;            else&#123;                predecessor.right = null;                node = node.right;            &#125;        &#125;    &#125;    return output;&#125;\n\n中序遍历递归法public static void inorderTraversal(TreeNode root) &#123;    if (root != null) &#123;        inorderTraversal(root.left);        System.out.println(root.val);        inorderTraversal(root.right);    &#125;&#125;\n\n迭代法public List&lt;Integer&gt; inorderTraversal(TreeNode root) &#123;    List&lt;Integer&gt; res = new ArrayList&lt;&gt;();    Stack&lt;TreeNode&gt; stack = new Stack&lt;&gt;();    TreeNode curr = root;    while (curr != null || !stack.isEmpty()) &#123;        while (curr != null) &#123;            stack.push(curr);            curr = curr.left;        &#125;        curr = stack.pop();        res.add(curr.val);        curr = curr.right;    &#125;    return res;&#125;\n\n莫里斯法public List&lt;Integer&gt; inorderTraversal(TreeNode root) &#123;    List&lt;Integer&gt; ldr = new ArrayList&lt;Integer&gt;();    TreeNode cur = root;    TreeNode pre = null;    while(cur!=null)&#123;        if(cur.left==null)&#123;//左子树为空，输出当前节点，将其右孩子作为当前节点            ldr.add(cur.val);            cur = cur.right;        &#125;        else&#123;            pre = cur.left;//左子树            while(pre.right!=null&amp;&amp;pre.right!=cur)&#123;//找到前驱节点，即左子树中的最右节点                pre = pre.right;            &#125;            //如果前驱节点的右孩子为空，将它的右孩子设置为当前节点。当前节点更新为当前节点的左孩子。            if(pre.right==null)&#123;                pre.right = cur;                cur = cur.left;            &#125;            //如果前驱节点的右孩子为当前节点，将它的右孩子重新设为空（恢复树的形状）。输出当前节点。当前节点更新为当前节点的右孩子。            if(pre.right==cur)&#123;                pre.right = null;                ldr.add(cur.val);                cur = cur.right;            &#125;        &#125;    &#125;    return ldr;&#125;\n\n后序遍历递归法public static void postorderTraversal(TreeNode root) &#123;    if (root != null) &#123;        postorderTraversal(root.left);        postorderTraversal(root.right);        System.out.println(root.val);    &#125;&#125;\n\n迭代法public List&lt;Integer&gt; postorderTraversal(TreeNode root) &#123;    LinkedList&lt;TreeNode&gt; stack = new LinkedList&lt;&gt;();    LinkedList&lt;Integer&gt; output = new LinkedList&lt;&gt;();    if (root == null) &#123;        return output;    &#125;    stack.add(root);    while (!stack.isEmpty()) &#123;        TreeNode node = stack.pollLast();        output.addFirst(node.val);        if (node.left != null) &#123;            stack.add(node.left);        &#125;        if (node.right != null) &#123;            stack.add(node.right);        &#125;    &#125;    return output;&#125;\n\n莫里斯法\n\n总结\n\n\n\n时间复杂度\n空间复杂度\n\n\n\n递归\n\n\n\n\n迭代\n\n\n\n\n莫里斯\n\n\n\n\n","tags":["算法相关"]},{"title":"元注解介绍","url":"/2020/01/09/%E5%85%83%E6%B3%A8%E8%A7%A3%E4%BB%8B%E7%BB%8D/","content":"元注解：元注解的作用就是负责注解其他注解。Java5.0定义了4个标准的meta-annotation类型，它们被用来提供对其它 annotation类型作说明。Java5.0定义的元注解：\n\n@Target,\n@Retention,\n@Documented,\n@Inherited　\n\n这些类型和它们所支持的类在java.lang.annotation包中可以找到。下面我们看一下每个元注解的作用和相应分参数的使用说明。\n@Target说明了Annotation所修饰的对象范围：Annotation可被用于 packages、types（类、接口、枚举、Annotation类型）、类型成员（方法、构造方法、成员变量、枚举值）、方法参数和本地变量（如循环变量、catch参数）。在Annotation类型的声明中使用了target可更加明晰其修饰的目标。\n\n作用：用于描述注解的使用范围（即：被描述的注解可以用在什么地方）\n取值(ElementType)有：\nCONSTRUCTOR:用于描述构造器\nFIELD:用于描述域\nLOCAL_VARIABLE:用于描述局部变量\nMETHOD:用于描述方法\nPACKAGE:用于描述包\nPARAMETER:用于描述参数\nTYPE:用于描述类、接口(包括注解类型) 或enum声明\n\n\n\n@Retention定义了该Annotation被保留的时间长短：某些Annotation仅出现在源代码中，而被编译器丢弃；而另一些却被编译在class文件中；编译在class文件中的Annotation可能会被虚拟机忽略，而另一些在class被装载时将被读取（请注意并不影响class的执行，因为Annotation与class在使用上是被分离的）。使用这个meta-Annotation可以对 Annotation的“生命周期”限制。\n\n作用：表示需要在什么级别保存该注释信息，用于描述注解的生命周期（即：被描述的注解在什么范围内有效）\n取值（RetentionPoicy）有：\nSOURCE:在源文件中有效（即源文件保留）\nCLASS:在class文件中有效（即class保留）\nRUNTIME:在运行时有效（即运行时保留）\n\n\n\n@Documented用于描述其它类型的annotation应该被作为被标注的程序成员的公共API，因此可以被例如javadoc此类的工具文档化。Documented是一个标记注解，没有成员。\n@Inherited元注解是一个标记注解，@Inherited阐述了某个被标注的类型是被继承的。如果一个使用了@Inherited修饰的annotation类型被用于一个class，则这个annotation将被用于该class的子类。\n\n注意：@Inherited annotation类型是被标注过的class的子类所继承。类并不从它所实现的接口继承annotation，方法并不从它所重载的方法继承annotation。\n\n当@Inherited annotation类型标注的annotation的Retention是RetentionPolicy.RUNTIME，则反射API增强了这种继承性。如果我们使用java.lang.reflect去查询一个@Inherited annotation类型的annotation时，反射代码检查将展开工作：检查class和其父类，直到发现指定的annotation类型被发现，或者到达类继承结构的顶层。\n\n\n@自定义注解使用@interface自定义注解时，自动继承了java.lang.annotation.Annotation接口，由编译程序自动完成其他细节。在定义注解时，不能继承其他的注解或接口。@interface用来声明一个注解，其中的每一个方法实际上是声明了一个配置参数。方法的名称就是参数的名称，返回值类型就是参数的类型（返回值类型只能是基本类型、Class、String、enum）。可以通过default来声明参数的默认值。\n定义注解格式：\npublic @interface 注解名 {定义体}\n注解参数的可支持数据类型：\n\n所有基本数据类型（int,float,boolean,byte,double,char,long,short)\nString类型\nClass类型\nenum类型\nAnnotation类型\n以上所有类型的数组\n\nAnnotation类型里面的参数该怎么设定:\n\n只能用public或默认(default)这两个访问权修饰.例如,String value();这里把方法设为default默认类型 　\n参数成员只能用基本类型byte,short,char,int,long,float,double,boolean八种基本数据类型和 String,Enum,Class,annotations等数据类型,以及这一些类型的数组.例如,String value();这里的参数成员就为String\n如果只有一个参数成员,最好把参数名称设为”value”,后加小括号.例:下面的例子FruitName注解就只有一个参数成员\n\n","tags":["Java"]},{"title":"关于JVM对反射调用的优化","url":"/2019/11/12/%E5%85%B3%E4%BA%8EJVM%E5%AF%B9%E5%8F%8D%E5%B0%84%E8%B0%83%E7%94%A8%E7%9A%84%E4%BC%98%E5%8C%96/","content":"关于JVM对反射调用的优化Java中对反射的优化使用反射调用某个类的方法，jvm内部有两种方式\n1. JNI使用native方法进行反射操作。\n2. pure-Java生成bytecode进行反射操作，即生成类sun.reflect.GeneratedMethodAccessor，它是一个被反射调用方法的包装类，代理不同的方法，类后缀序号会递增。这种方式第一次调用速度较慢，较之第一种会慢3-4倍，但是多次调用后速度会提升20倍\n对于使用JNI的方式，因为每次都要调用native方法再返回，速度会比较慢。所以，当一个方法被反射调用的次数超过一定次数（默认15次）时，JVM内部会进行优化，使用第2种方法，来加快运行速度。\nJVM有两个参数来控制这种优化\n-Dsun.reflect.inflationThreshold=&lt;value&gt;\nvalue默认为15，即反射调用某个方法15次后，会由JNI的方式变为pure-java的方式\n-Dsun.reflect.noInflation=true\n默认为false。当设置为true时，表示在第一次反射调用时，就转为pure-java的方式\n下面是一个验证反射优化的样例：\npublic class TestMethodInvoke &#123;    public static void main(String[] args) throws Exception &#123;        Class&lt;?&gt; clz = Class.forName(\"A\");        Object o = clz.newInstance();        Method m = clz.getMethod(\"foo\", String.class);        for (int i = 0; i &lt; 100; i++) &#123;            m.invoke(o, Integer.toString(i));        &#125;    &#125;&#125;\n\npublic class A &#123;    public void foo(String name) &#123;        System.out.println(\"Hello, \" + name);    &#125;&#125;\n\n配置如下JVM参数，使得在第一次反射调用时，就转为pure-java的方式\n-Dsun.reflect.noInflation=true\n如何关闭JVM对反射调用的优化？想关闭JVM对反射优化怎么办?\nJVM中只提供了两个参数，因此，没有办法完全关闭反射优化。\n一种能想到的接近于关闭反射优化的方法就是将inflationThreshold设为的一个特别大的数。\ninflationThreshold是java中的int型值，可以考虑把其设置为Integer.MAX_VALUE ((2^31)-1)。\n$ java-Dsun.reflect.inflationThreshold&#x3D;2147483647MyApp\n","tags":["Java"]},{"title":"关于Java中的变量","url":"/2019/11/28/%E5%85%B3%E4%BA%8EJava%E4%B8%AD%E7%9A%84%E5%8F%98%E9%87%8F/","content":"成员变量\n存在于堆内存中，和类一起创建\n\n\n实例变量（不以static修饰）\n\n实例变量则从该类的实例被创建起开始存在，直到系统完全销毁这个实例，实例变量的作用域与对应实例的生存范围相同\n\n类变量（以static修饰）\n\n类变量从该类的准备阶段起开始存在，直到系统完全销毁这个类，类变量的作用域与这个类的生存范围相同\n局部变量\n存在于栈内存中，当方法执行完成，回收内存\n\n\n形参（方法签名中定义的变量）\n\n在定义方法签名时定义的变量，形参的作用域在整个方法中都有效\n\n方法局部变量（在方法内定义）\n\n在方法体内定义的局部变量，它的作用域是从定义该变量的地方生效，到该方法结束时失效\n\n代码块局部变量（在代码块内定义）\n\n这个局部变量的作用域从定义该变量的地方生效，到该代码结束时失效。\n","tags":["Java"]},{"title":"前端数据存储详细介绍","url":"/2020/09/01/%E5%89%8D%E7%AB%AF%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8%E8%AF%A6%E7%BB%86%E4%BB%8B%E7%BB%8D/","content":""},{"title":"哀悼日网站全站变灰代码","url":"/2020/04/07/%E5%93%80%E6%82%BC%E6%97%A5%E7%BD%91%E7%AB%99%E5%85%A8%E7%AB%99%E5%8F%98%E7%81%B0%E4%BB%A3%E7%A0%81/","content":"第一种：修改CSS文件html &#123;    filter: progid:DXImageTransform.Microsoft.BasicImage(grayscale=1);    -webkit-filter: grayscale(100%);&#125;\n\n第二种：在网页的&lt;head&gt;标签内加入以下代码&lt;style type=\"text/css\"&gt;    html &#123;        filter: progid:DXImageTransform.Microsoft.BasicImage(grayscale=1);        -webkit-filter: grayscale(100%);&#125;&lt;/style&gt;\n\n第三种：修改&lt;html&gt;标签加入内联样式&lt;html style=\"filter: progid:DXImageTransform.Microsoft.BasicImage(grayscale=1);             -webkit-filter: grayscale(100%);\"&gt;\n\n第四种：bodybody *&#123;    -webkit-filter: grayscale(100%); /* webkit */    -moz-filter: grayscale(100%); /*firefox*/    -ms-filter: grayscale(100%); /*ie9*/    -o-filter: grayscale(100%); /*opera*/    filter: grayscale(100%);    filter:progid:DXImageTransform.Microsoft.BasicImage(grayscale=1);    filter:gray; /*ie9- */&#125;\n\n第五种：Nginx sub_filterlocation / &#123;    root   /opt/app/code/;    random_index on;    index  index.html index.htm;    sub_filter '&lt;h1&gt;Admin' '&lt;h1&gt;ggggg';  //第一个参数是要被替换的，第二个参数是替换后的    sub_filter_once off;   //替换所有的，默认是on，替换第一个&#125;\n","tags":["前端开发"]},{"title":"如何保护自己的Java代码","url":"/2020/04/15/%E5%A6%82%E4%BD%95%E4%BF%9D%E6%8A%A4%E8%87%AA%E5%B7%B1%E7%9A%84Java%E4%BB%A3%E7%A0%81/","content":"\n代码混淆是为了防止反编译。如果没有对代码混淆，那么其他人很容易就可以得到你的项目中的所有代码。而混淆之后，其他人就没那么容易获得了。\n保护软件有着双重意义： 一是保护软件的知识产权 (intellectual property)， 防止被人盗用； 二是保护软件中可能隐含的诸如技术漏洞等私密信息， 防止被人利用。 就保护思路而言， 目前主要有两条： 一条是加密 (encryption)， 另一条是代码混淆 (obfuscation)。 两者的主要区别是前者需解密 (decryption)， 后者则不需要——因为后者只是将代码换成普通人难以读懂、 在计算机上却仍能运行， 且功能相同的形式， 很多网站采用的 JavaScript 代码混淆就是很好的例子。\n\nProGuard\n官方网站\nProGuard是最流行的Java字节码优化器。它使Java和Android应用程序的体积缩小了90％，速度提高了20％。ProGuard还通过混淆类，字段和方法的名称来提供最小的保护，以防止逆向工程。\nProGuard可以免费使用来处理您的应用程序，无论是否商业。ProGuard代码本身受版权保护，并根据GNU通用公共许可证（GPL）版本2进行分配。该用户手册也受版权保护，并且只能以其原始形式与未经修改的代码一起重新分发。\n\n看一下 https://www.guardsquare.com/en/products/proguard/manual/gui\n","tags":["代码混淆"]},{"title":"常见网络协议报文头格式","url":"/2020/07/22/%E5%B8%B8%E8%A7%81%E7%BD%91%E7%BB%9C%E5%8D%8F%E8%AE%AE%E6%8A%A5%E6%96%87%E5%A4%B4%E6%A0%BC%E5%BC%8F/","content":"序言常见的一些协议类型\nUDPUDP报头结构\n\n源端口（16bits）：用来标识源端应用进程\n目的端口（16bits）：用来标识目的端应用进程\n长度字段（16bits）：标明UDP头部和UDP数据的总长度，字节计\n校验和（16bits）：用来对UDP头部和UDP数据进行校验，需要添加UDP伪头部参与计算\n\nTCPTCP报头结构\n\n源端口(Source Port，16bits)：源端口字段包含初始化通信的端口号。源端口和IP地址的作用是标识报文的返回地址。\n目的端口(Destination Port，16bits)：目的端口字段定义传输的目的地。这个端口指明接收方计算机上的应用程序接口。\n序列号（Sequence Number，32bits）：该字段用来标识TCP源端设备向目的端设备发送的字节流，它表示在这个报文段中的第几个数据字节。\n确认号（Acknowledge Number，32bits）：TCP使用32位的确认号字段标识期望收到的下一个段的第一个字节，并声明此前的所有数据已经正确无误地收到。因此，确认号应该是上次已成功收到的数据字节序列号加1。收到确认号的源计算机会知道特定的段已经被收到。确认号的字段只在ACK标志被设置时才有效。\n数据偏移（Data Offset，4bits）：该字段字段表示TCP头部大小，以4字节为单位，最长60字节。\n保留字段（Reserved，6bits）：为将来定义新的用途保留，均置0。\n控制位(Control Bits，6bits)：共6位，每一位标志可以打开一个控制功能。\nURG(Urgent Pointer Field Significant，1bit)：紧急指针字段标志，与紧急指针字段配合使用。表示TCP包的紧急指针字段有效，用来保证TCP连接不被中断，并且督促中间齐备尽快处理这些数据。\nACK（Acknowledgement field significant，1bit）：确认字段标志。取1时表示应答字段有效，也即TCP应答号将包含在TCP段中，为0无效。\nPSH(Push Function，1bit)：推功能。Push操作指在数据包到达接收端以后，立即送给应用层/应用程序，而不是在缓冲区中排队，等填满之后再向上交付。\nRST（Reset the connection，1bit）：重置连接。这个标志表示表示连接复位请求，用来复位那些产生错误的连接，也被用来拒绝错误和非法的数据包。当RST=1时，表示呈现严重错误，必须断开连接，然后再重建传输连接。\nSYN（Synchronize sequence numbers，1bit）：同步序列号。表示同步序号，用来建立连接。\nFIN（No more data from sender，1bit）：表示发送端已经发送到数据末尾，数据传送完成，发送FIN标志位的TCP段，连接将被断开。\n\n\n窗口（Window，16bits）：默示报文段发送方的接管窗口，单位为字节。此窗口告诉对方，“在未收到我的确认时，你可以发送的数据的字节数至多是此窗口的大小“。\n校验和（Checksum，16bits）：TCP头包括16位的校验和字段用于错误检查。源主机基于部分IP头信息，TCP头和数据内容计算一个校验和，目的主机也要进行相同的计算，如果收到的内容没有错误，两个计算应该完全一样，从而证明数据的有效性。\n紧急指针（Urgent Pointer，16bits）：紧急指针字段是一个可选的16位指针，指向段内的最后一个字节位置，这个字段只在URG标志被设置时才有效。\n选项（Option，长度不定）：至少1字节的可变长字段，标识哪个选项（有多种选项类型，比如”窗口扩大因子”、”时间戳”等选项）有效。如果没有选项，这个字节等于0，说明选项的结束。这个字节等于1表示无需再有操作；等于2表示下四个字节包括源机器的最大长度（Maximum Segment Size，MSS）等。\n填充（Padding，长度不定）：这个字段中加入额外的零，以保证TCP头是32比特的整数倍。\n\n","tags":["网络"]},{"title":"树状结构数据库设计","url":"/2020/05/25/%E6%A0%91%E7%8A%B6%E7%BB%93%E6%9E%84%E6%95%B0%E6%8D%AE%E5%BA%93%E8%AE%BE%E8%AE%A1/","content":"\n了解Modified Preorder Tree\n\nid，本节点的primary keyparent_id，其值为父节点的primary keykey，忘了学名叫啥了，你可以称为线索level，表示当前节点到根节点的距离其中，key字段的值为：从跟节点到父节点的primary key，中间用任意非数字符号分割。\n例如以下树状结构\n├── a│   ├── d│   │   ├── p│   │   ├── q│   │   └── r│   ├── e│   └── f├── b│   ├── x│   ├── y│   └── z├── c\n对应的数据库表值为：\n| id | value | parent_id | key    | level || 1  | a     | 0         | &quot;-&quot;    | 1     || 2  | b     | 0         | &quot;-&quot;    | 1     || 3  | c     | 0         | &quot;-&quot;    | 1     || 4  | d     | 1         | &quot;1-&quot;   | 2     || 5  | e     | 1         | &quot;1-&quot;   | 2     || 6  | f     | 1         | &quot;1-&quot;   | 2     || 7  | x     | 2         | &quot;2-&quot;   | 2     || 8  | y     | 2         | &quot;2-&quot;   | 2     || 9  | z     | 2         | &quot;2-&quot;   | 2     || 10 | p     | 4         | &quot;1-4-&quot; | 3     || 11 | q     | 4         | &quot;1-4-&quot; | 3     || 12 | r     | 4         | &quot;1-4-&quot; | 3     |\n于是，在给定一个节点d的时候，查找d的所有子孙节点：select * from table_name where key like &quot;${d.key}-${d.id}-%&quot;查找某个节点的所有子节点：select * from table_name where key like &quot;${d.key}-${d.id}-%&quot; and level=${d.level}+1这个设计，结构非常简单。key和level是辅助字段，维护这两个字段成本很低，即使全部重建要比MPT简单多了。\n","tags":["数据库"]},{"title":"深入理解Reactor和Proactor","url":"/2020/07/14/%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3Reactor%E5%92%8CProactor/","content":"1、标准定义两种I/O多路复用模式：Reactor和Proactor\n一般地,I/O多路复用机制都依赖于一个事件多路分离器(Event Demultiplexer)。分离器对象可将来自事件源的I/O事件分离出来，并分发到对应的read/write事件处理器(Event Handler)。开发人员预先注册需要处理的事件及其事件处理器（或回调函数）；事件分离器负责将请求事件传递给事件处理器。\n两个与事件分离器有关的模式是Reactor和Proactor。Reactor模式采用同步IO，而Proactor采用异步IO。\n在Reactor中，事件分离器负责等待文件描述符或socket为读写操作准备就绪，然后将就绪事件传递给对应的处理器，最后由处理器负责完成实际的读写工作。\n而在Proactor模式中，处理器–或者兼任处理器的事件分离器，只负责发起异步读写操作。IO操作本身由操作系统来完成。传递给操作系统的参数需要包括用户定义的数据缓冲区地址和数据大小，操作系统才能从中得到写出操作所需数据，或写入从socket读到的数据。事件分离器捕获IO操作完成事件，然后将事件传递给对应处理器。比如，在windows上，处理器发起一个异步IO操作，再由事件分离器等待IOCompletion事件。典型的异步模式实现，都建立在操作系统支持异步API的基础之上，我们将这种实现称为“系统级”异步或“真”异步，因为应用程序完全依赖操作系统执行真正的IO工作。\n举个例子，将有助于理解Reactor与Proactor二者的差异，以读操作为例（类操作类似）。\n在Reactor中实现读：\n\n注册读就绪事件和相应的事件处理器\n事件分离器等待事件\n事件到来，激活分离器，分离器调用事件对应的处理器。\n事件处理器完成实际的读操作，处理读到的数据，注册新的事件，然后返还控制权。\n\n在Proactor中实现读：\n\n处理器发起异步读操作（注意：操作系统必须支持异步IO）。在这种情况下，处理器无视IO就绪事件，它关注的是完成事件。\n事件分离器等待操作完成事件\n在分离器等待过程中，操作系统利用并行的内核线程执行实际的读操作，并将结果数据存入用户自定义缓冲区，最后通知事件分离器读操作完成。\n事件分离器呼唤处理器。\n事件处理器处理用户自定义缓冲区中的数据，然后启动一个新的异步操作，并将控制权返回事件分离器。\n\n可以看出，两个模式的相同点，都是对某个IO事件的事件通知(即告诉某个模块，这个IO操作可以进行或已经完成)。在结构上，两者也有相同点：demultiplexor负责提交IO操作(异步)、查询设备是否可操作(同步)，然后当条件满足时，就回调handler；不同点在于，异步情况下(Proactor)，当回调handler时，表示IO操作已经完成；同步情况下(Reactor)，回调handler时，表示IO设备可以进行某个操作(can read or can write)。\n2、通俗理解使用Proactor框架和Reactor框架都可以极大的简化网络应用的开发，但它们的重点却不同。\nReactor框架中用户定义的操作是在实际操作之前调用的。比如你定义了操作是要向一个SOCKET写数据，那么当该SOCKET可以接收数据的时候，你的操作就会被调用；而Proactor框架中用户定义的操作是在实际操作之后调用的。比如你定义了一个操作要显示从SOCKET中读入的数据，那么当读操作完成以后，你的操作才会被调用。\nProactor和Reactor都是并发编程中的设计模式。在我看来，他们都是用于派发/分离IO操作事件的。这里所谓的IO事件也就是诸如read/write的IO操作。”派发/分离”就是将单独的IO事件通知到上层模块。两个模式不同的地方在于，Proactor用于异步IO，而Reactor用于同步IO。\n","tags":["设计模式"]},{"title":"缓存算法","url":"/2019/12/25/%E7%BC%93%E5%AD%98%E7%AE%97%E6%B3%95/","content":"FIFO算法FIFO 算法是一种比较容易实现的算法。它的思想是先进先出（FIFO，队列），这是最简单、最公平的一种思想，即如果一个数据是最先进入的，那么可以认为在将来它被访问的可能性很小。空间满的时候，最先进入的数据会被最早置换（淘汰）掉。\nFIFO 算法的描述：设计一种缓存结构，该结构在构造时确定大小，假设大小为 K，并有两个功能：\n\nset(key,value)：将记录(key,value)插入该结构。当缓存满时，将最先进入缓存的数据置换掉。\nget(key)：返回key对应的value值。\n\n实现：维护一个FIFO队列，按照时间顺序将各数据（已分配页面）链接起来组成队列，并将置换指针指向队列的队首。再进行置换时，只需把置换指针所指的数据（页面）顺次换出，并把新加入的数据插到队尾即可。\n缺点：判断一个页面置换算法优劣的指标就是缺页率，而FIFO算法的一个显著的缺点是，在某些特定的时刻，缺页率反而会随着分配页面的增加而增加，这称为Belady现象。产生Belady现象现象的原因是，FIFO置换算法与进程访问内存的动态特征是不相容的，被置换的内存页面往往是被频繁访问的，或者没有给进程分配足够的页面，因此FIFO算法会使一些页面频繁地被替换和重新申请内存，从而导致缺页率增加。因此，现在不再使用FIFO算法。\nLRU算法LRU（The Least Recently Used，最近最久未使用算法）是一种常见的缓存算法，在很多分布式缓存系统（如Redis, Memcached）中都有广泛使用。\nLRU算法的思想是：如果一个数据在最近一段时间没有被访问到，那么可以认为在将来它被访问的可能性也很小。因此，当空间满时，最久没有访问的数据最先被置换（淘汰）。\nLRU算法的描述： 设计一种缓存结构，该结构在构造时确定大小，假设大小为 K，并有两个功能：\n\nset(key,value)：将记录(key,value)插入该结构。当缓存满时，将最久未使用的数据置换掉。\nget(key)：返回key对应的value值。\n\n实现：最朴素的思想就是用数组+时间戳的方式，不过这样做效率较低。因此，我们可以用双向链表（LinkedList）+哈希表（HashMap）实现（链表用来表示位置，哈希表用来存储和查找），在Java里有对应的数据结构LinkedHashMap。\nLinkedHashMap利用Java的LinkedHashMap用非常简单的代码来实现基于LRU算法的Cache功能\nCopyimport java.util.LinkedHashMap;import java.util.Map;&#x2F;** * 简单用LinkedHashMap来实现的LRU算法的缓存 *&#x2F;public class LRUCache&lt;K, V&gt; extends LinkedHashMap&lt;K, V&gt; &#123;    private int cacheSize;    public LRUCache(int cacheSize) &#123;        super(16, (float) 0.75, true);        this.cacheSize &#x3D; cacheSize;    &#125;    protected boolean removeEldestEntry(Map.Entry&lt;K, V&gt; eldest) &#123;        return size() &gt; cacheSize;    &#125;&#125;\n\n测试：\nCopyimport org.slf4j.Logger;import org.slf4j.LoggerFactory;public class LRUCacheTest &#123;    private static final Logger log &#x3D; LoggerFactory.getLogger(LRUCacheTest.class);    private static LRUCache&lt;String, Integer&gt; cache &#x3D; new LRUCache&lt;&gt;(10);    public static void main(String[] args) &#123;        for (int i &#x3D; 0; i &lt; 10; i++) &#123;            cache.put(&quot;k&quot; + i, i);        &#125;        log.info(&quot;all cache :&#39;&#123;&#125;&#39;&quot;,cache);        cache.get(&quot;k3&quot;);        log.info(&quot;get k3 :&#39;&#123;&#125;&#39;&quot;, cache);        cache.get(&quot;k4&quot;);        log.info(&quot;get k4 :&#39;&#123;&#125;&#39;&quot;, cache);        cache.get(&quot;k4&quot;);        log.info(&quot;get k4 :&#39;&#123;&#125;&#39;&quot;, cache);        cache.put(&quot;k&quot; + 10, 10);        log.info(&quot;After running the LRU algorithm cache :&#39;&#123;&#125;&#39;&quot;, cache);    &#125;&#125;\n\nOutput:\nCopyall cache :&#39;&#123;k0&#x3D;0, k1&#x3D;1, k2&#x3D;2, k3&#x3D;3, k4&#x3D;4, k5&#x3D;5, k6&#x3D;6, k7&#x3D;7, k8&#x3D;8, k9&#x3D;9&#125;&#39;get k3 :&#39;&#123;k0&#x3D;0, k1&#x3D;1, k2&#x3D;2, k4&#x3D;4, k5&#x3D;5, k6&#x3D;6, k7&#x3D;7, k8&#x3D;8, k9&#x3D;9, k3&#x3D;3&#125;&#39;get k4 :&#39;&#123;k0&#x3D;0, k1&#x3D;1, k2&#x3D;2, k5&#x3D;5, k6&#x3D;6, k7&#x3D;7, k8&#x3D;8, k9&#x3D;9, k3&#x3D;3, k4&#x3D;4&#125;&#39;get k4 :&#39;&#123;k0&#x3D;0, k1&#x3D;1, k2&#x3D;2, k5&#x3D;5, k6&#x3D;6, k7&#x3D;7, k8&#x3D;8, k9&#x3D;9, k3&#x3D;3, k4&#x3D;4&#125;&#39;After running the LRU algorithm cache :&#39;&#123;k1&#x3D;1, k2&#x3D;2, k5&#x3D;5, k6&#x3D;6, k7&#x3D;7, k8&#x3D;8, k9&#x3D;9, k3&#x3D;3, k4&#x3D;4, k10&#x3D;10&#125;&#39;\n\nLFU算法LFU（Least Frequently Used ，最近最少使用算法）也是一种常见的缓存算法。\n顾名思义，LFU算法的思想是：如果一个数据在最近一段时间很少被访问到，那么可以认为在将来它被访问的可能性也很小。因此，当空间满时，最小频率访问的数据最先被淘汰。\nLFU 算法的描述：\n设计一种缓存结构，该结构在构造时确定大小，假设大小为 K，并有两个功能：\n\nset(key,value)：将记录(key,value)插入该结构。当缓存满时，将访问频率最低的数据置换掉。\nget(key)：返回key对应的value值。\n\n算法实现策略：考虑到 LFU 会淘汰访问频率最小的数据，我们需要一种合适的方法按大小顺序维护数据访问的频率。LFU  算法本质上可以看做是一个 top K 问题(K =  1)，即选出频率最小的元素，因此我们很容易想到可以用二项堆来选择频率最小的元素，这样的实现比较高效。最终实现策略为小顶堆+哈希表。\n","tags":["算法相关"]},{"title":"计算机中的回车符和换行符","url":"/2020/08/14/%E8%AE%A1%E7%AE%97%E6%9C%BA%E4%B8%AD%E7%9A%84%E5%9B%9E%E8%BD%A6%E7%AC%A6%E5%92%8C%E6%8D%A2%E8%A1%8C%E7%AC%A6/","content":"概述\n\\r是回车符(carriage return，缩写CR)，使光标移至行首，十进制ASCII代码是13, 十六进制代码为0x0D\n\n\\n是换行符(line feed，缩写LF)，使光标下移一格，ASCII代码是10, 十六进制为0x0A\n\n\n不同系统中换行的表现形式Unix系统每行结尾只有“&lt;换行&gt;”，即\\n；十六进制：0A\nWindows系统里面每行结尾是“&lt;回车&gt;&lt;换行&gt;”，即\\r\\n；十六进制：0D 0A\nMac系统里每行结尾是“&lt;回车&gt;”,即\\r。十六进制：0D\n"},{"title":"设计模式之Proactor模式","url":"/2020/07/14/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8BProactor%E6%A8%A1%E5%BC%8F/","content":"Proactor模式结构Proactor主动器模式包含如下角色：\nHandle 句柄；用来标识socket连接或是打开文件；\nAsynchronous Operation Processor：异步操作处理器；负责执行异步操作，一般由操作系统内核实现；\nAsynchronous Operation：异步操作\nCompletion Event Queue：完成事件队列；异步操作完成的结果放到队列中等待后续使用\nProactor：主动器；为应用程序进程提供事件循环；从完成事件队列中取出异步操作的结果，分发调用相应的后续处理逻辑；\nCompletion Handler：完成事件接口；一般是由回调函数组成的接口；\nConcrete Completion Handler：完成事件处理逻辑；实现接口定义特定的应用处理逻辑；\nProactor模式时序图\n\n应用程序启动，调用异步操作处理器提供的异步操作接口函数，调用之后应用程序和异步操作处理就独立运行；应用程序可以调用新的异步操作，而其它操作可以并发进行。\n\n应用程序启动Proactor主动器，进行无限的事件循环，等待完成事件到来。\n\n异步操作处理器执行异步操作，完成后将结果放入到完成事件队列。\n\n主动器从完成事件队列中取出结果，分发到相应的完成事件回调函数处理逻辑中。\n\n\n","tags":["设计模式"]},{"title":"设计模式之Reactor模式","url":"/2020/07/14/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F%E4%B9%8BReactor%E6%A8%A1%E5%BC%8F/","content":"一、概念Reactor设计模式，是一种基于事件驱动的设计模式。它有一个或多个并发输入源，有一个Service Handler，和多个Request Handler，Service Handler会同步的将输入的请求（Event）多路复用的分发给相应的Request Handler。\n\n二、Reactor模式结构Reactor模式由5个角色组成。\n\nHandle：即操作系统中的句柄，是操作系统对资源的一种抽象，可以是打开的文件、一个连接(Socket)、Timer等。在网络编程中，一般指Socket Handle，文件描述符（fd）。将这个Handle注册到Synchronous Event Demultiplexer中，就可以它发生的事件，如READ、WRITE、CLOSE等事件。\nSynchronous Event Demultiplexer：同步事件多路分用器，本质上是系统调用。比如linux中的select、poll、epoll等。它会一直阻塞直在handle上，直到有事件发生时才会返回。\nInitiation Dispatcher：初始分发器，它提供了注册、删除与转发event handler的方法。当Synchronous Event Demultiplexer检测到handle上有事件发生时，便会通知initiation dispatcher调用特定的event handler的回调（handle_event()）方法。\nEvent Handler：事件处理器，定义事件处理的回调方法：handle_event()，以供InitiationDispatcher回调使用。\nConcrete Event Handler：具体的事件处理器，继承自Event Handler，在回调方法中会实现具体的业务逻辑。\n三、Reactor模式处理流程\n注册Concrete Event Handler到Initiation Dispatcher中，当Initiation Dispatcher在某种类型的事件发生时向其通知，事件与handle关联。\n\nInitiation Dispatcher调用每个Event Handler的get_handle接口获取其绑定的Handle。\n\nInitiation Dispatcher调用handle_events开始事件处理循环。在这里，Initiation Dispatcher会将步骤2获取的所有Handle都收集起来，使用Synchronous Event Demultiplexer来等待这些Handle的事件发生。\n\n当某个（或某几个）Handle的事件发生时，Synchronous Event Demultiplexer通知Initiation Dispatcher，select()根据发生事件的Handle找出对应的回调Handler。\n\nInitiation Dispatcher调用特定的Concrete Event Handler的回调方法（handel_event()）来响应其关联的handle上发生的事件。\n\n\n时序图：\n\n四、相关文章http://gee.cs.oswego.edu/dl/cpjslides/nio.pdf\nhttps://www.cnblogs.com/dafanjoy/p/11217708.html\nhttps://zhuanlan.zhihu.com/p/53191925\nhttps://cloud.tencent.com/developer/article/1513447\nhttps://blog.csdn.net/u010168160/article/details/53019039\n","tags":["设计模式"]},{"title":"Java开发规范","url":"/2019/10/24/Java%E5%BC%80%E5%8F%91%E8%A7%84%E8%8C%83/","content":"一、MyBatis不要为了多个查询条件而写1 = 1\n当遇到多个查询条件，使用where  1=1 可以很方便的解决我们的问题，但是这样很可能会造成非常大的性能损失，因为添加了 “where 1=1  ”的过滤条件之后，数据库系统就无法使用索引等查询优化策略，数据库系统将会被迫对每行数据进行扫描（即全表扫描）  以比较此行是否满足过滤条件，当表中的数据量较大时查询速度会非常慢；此外，还会存在SQL 注入的风险。\n\n反例：\n&lt;select id=\"queryBookInfo\" parameterType=\"com.tjt.platform.entity.BookInfo\" resultType=\"java.lang.Integer\"&gt;    select count(*) from t_rule_BookInfo t where 1=1    &lt;if test=\"title !=null and title !='' \"&gt;        AND title = #&#123;title&#125;    &lt;/if&gt;    &lt;if test=\"author !=null and author !='' \"&gt;        AND author = #&#123;author&#125;    &lt;/if&gt;&lt;/select&gt;\n\n正例：\n&lt;select id=\"queryBookInfo\" parameterType=\"com.tjt.platform.entity.BookInfo\" resultType=\"java.lang.Integer\"&gt;    select count(*) from t_rule_BookInfo t    &lt;where&gt;        &lt;if test=\"title !=null and title !='' \"&gt;            title = #&#123;title&#125;        &lt;/if&gt;        &lt;if test=\"author !=null and author !='' \"&gt;            AND author = #&#123;author&#125;        &lt;/if&gt;    &lt;/where&gt;&lt;/select&gt;\n\nUPDATE 操作也一样，可以用标记代替 1=1。\n二、迭代entrySet()获取Map的key和value\n当循环中只需要获取Map 的主键key时，迭代keySet() 是正确的；但是，当需要主键key 和取值value 时，迭代entrySet() 才是更高效的做法，其比先迭代keySet() 后再去通过get 取值性能更佳。\n\n反例：\n//Map 获取value 反例:HashMap&lt;String, String&gt; map = new HashMap&lt;&gt;();for (String key : map.keySet())&#123;    String value = map.get(key);&#125;\n\n正例：\n//Map 获取key &amp; value 正例:HashMap&lt;String, String&gt; map = new HashMap&lt;&gt;();for (Map.Entry&lt;String,String&gt; entry : map.entrySet())&#123;    String key = entry.getKey();    String value = entry.getValue();&#125;\n\n三、使用Collection.isEmpty()检测空\n使用Collection.size()来检测是否为空在逻辑上没有问题，但是使用Collection.isEmpty() 使得代码更易读，并且可以获得更好的性能；除此之外，任何Collection.isEmpty() 实现的时间复杂度都是O(1)  ，不需要多次循环遍历，但是某些通过Collection.size() 方法实现的时间复杂度可能是O(n)。\n\n反例：\nLinkedList&lt;Object&gt; collection = new LinkedList&lt;&gt;();if (collection.size() == 0)&#123;    System.out.println(\"collection is empty.\");&#125;\n\n正例：\nLinkedList&lt;Object&gt; collection = new LinkedList&lt;&gt;();if (collection.isEmpty())&#123;    System.out.println(\"collection is empty.\");&#125;//检测是否为null 可以使用CollectionUtils.isEmpty()if (CollectionUtils.isEmpty(collection))&#123;    System.out.println(\"collection is null.\");&#125;\n\n四、初始化集合时尽量指定其大小\n尽量在初始化时指定集合的大小，能有效减少集合的扩容次数，因为集合每次扩容的时间复杂度很可能时O(n)，耗费时间和性能。\n\n反例：\n//初始化list，往list 中添加元素反例：int[] arr = new int[]&#123;1,2,3,4&#125;;List&lt;Integer&gt; list = new ArrayList&lt;&gt;();for (int i : arr)&#123;    list.add(i);&#125;\n\n正例：\n//初始化list，往list 中添加元素正例：int[] arr = new int[]&#123;1,2,3,4&#125;;//指定集合list 的容量大小List&lt;Integer&gt; list = new ArrayList&lt;&gt;(arr.length);for (int i : arr)&#123;    list.add(i);&#125;\n\n五、使用StringBuilder拼接字符串\n一般的字符串拼接在编译期Java 会对其进行优化，但是在循环中字符串的拼接Java 编译期无法执行优化，所以需要使用StringBuilder进行替换。\n\n反例：\n//在循环中拼接字符串反例String str = \"\";for (int i = 0; i &lt; 10; i++)&#123;    //在循环中字符串拼接Java 不会对其进行优化    str += i;&#125;\n\n正例：\n//在循环中拼接字符串正例String str1 = \"Love\";String str2 = \"Courage\";String strConcat = str1 + str2;  //Java 编译器会对该普通模式的字符串拼接进行优化StringBuilder sb = new StringBuilder();for (int i = 0; i &lt; 10; i++)&#123;    //在循环中，Java 编译器无法进行优化，所以要手动使用StringBuilder    sb.append(i);&#125;\n\n六、若需频繁调用Collection.contains方法则使用Set\n在Java 集合类库中，List的contains 方法普遍时间复杂度为O(n)，若代码中需要频繁调用contains 方法查找数据则先将集合list 转换成HashSet实现，将O(n) 的时间复杂度将为O(1)。\n\n反例：\n//频繁调用Collection.contains() 反例List&lt;Object&gt; list = new ArrayList&lt;&gt;();for (int i = 0; i &lt;= Integer.MAX_VALUE; i++)&#123;    //时间复杂度为O(n)    if (list.contains(i))        System.out.println(\"list contains \"+ i);&#125;\n\n正例:\n//频繁调用Collection.contains() 正例List&lt;Object&gt; list = new ArrayList&lt;&gt;();Set&lt;Object&gt; set = new HashSet&lt;&gt;();for (int i = 0; i &lt;= Integer.MAX_VALUE; i++)&#123;    //时间复杂度为O(1)    if (set.contains(i))&#123;        System.out.println(\"list contains \"+ i);    &#125;&#125;\n\n七、使用静态代码块实现赋值静态成员变量\n对于集合类型的静态成员变量，应该使用静态代码块赋值，而不是使用集合实现来赋值。\n\n反例：\n//赋值静态成员变量反例private static Map&lt;String, Integer&gt; map = new HashMap&lt;String, Integer&gt;()&#123;    &#123;        map.put(\"Leo\",1);        map.put(\"Family-loving\",2);        map.put(\"Cold on the out side passionate on the inside\",3);    &#125;&#125;;private static List&lt;String&gt; list = new ArrayList&lt;&gt;()&#123;    &#123;        list.add(\"Sagittarius\");        list.add(\"Charming\");        list.add(\"Perfectionist\");    &#125;&#125;;\n\n正例：\n//赋值静态成员变量正例private static Map&lt;String, Integer&gt; map = new HashMap&lt;String, Integer&gt;();static &#123;    map.put(\"Leo\",1);    map.put(\"Family-loving\",2);    map.put(\"Cold on the out side passionate on the inside\",3);&#125;private static List&lt;String&gt; list = new ArrayList&lt;&gt;();static &#123;    list.add(\"Sagittarius\");    list.add(\"Charming\");    list.add(\"Perfectionist\");&#125;\n\n八、删除未使用的局部变量、方法参数、私有方法、字段和多余的括号。九、工具类中屏蔽构造函数\n工具类是一堆静态字段和函数的集合，其不应该被实例化；但是，Java 为每个没有明确定义构造函数的类添加了一个隐式公有构造函数，为了避免不必要的实例化，应该显式定义私有构造函数来屏蔽这个隐式公有构造函数。\n\n反例：\npublic class PasswordUtils &#123;    //工具类构造函数反例    private static final Logger LOG = LoggerFactory.getLogger(PasswordUtils.class);    public static final String DEFAULT_CRYPT_ALGO = \"PBEWithMD5AndDES\";    public static String encryptPassword(String aPassword) throws IOException &#123;        return new PasswordUtils(aPassword).encrypt();    &#125;\n\n正例：\npublic class PasswordUtils &#123;    //工具类构造函数正例    private static final Logger LOG = LoggerFactory.getLogger(PasswordUtils.class);    //定义私有构造函数来屏蔽这个隐式公有构造函数    private PasswordUtils()&#123;&#125;    public static final String DEFAULT_CRYPT_ALGO = \"PBEWithMD5AndDES\";    public static String encryptPassword(String aPassword) throws IOException &#123;        return new PasswordUtils(aPassword).encrypt();    &#125;\n\n十、删除多余的异常捕获并跑出\n用catch 语句捕获异常后，若什么也不进行处理，就只是让异常重新抛出，这跟不捕获异常的效果一样，可以删除这块代码或添加别的处理。\n\n反例：\n//多余异常反例private static String fileReader(String fileName)throws IOException&#123;    try (BufferedReader reader = new BufferedReader(new FileReader(fileName))) &#123;        String line;        StringBuilder builder = new StringBuilder();        while ((line = reader.readLine()) != null) &#123;            builder.append(line);        &#125;        return builder.toString();    &#125; catch (Exception e) &#123;        //仅仅是重复抛异常 未作任何处理        throw e;    &#125;&#125;\n\n正例：\n//多余异常正例private static String fileReader(String fileName)throws IOException&#123;    try (BufferedReader reader = new BufferedReader(new FileReader(fileName))) &#123;        String line;        StringBuilder builder = new StringBuilder();        while ((line = reader.readLine()) != null) &#123;            builder.append(line);        &#125;        return builder.toString();        //删除多余的抛异常，或增加其他处理：        /*catch (Exception e) &#123;            return \"fileReader exception\";        &#125;*/    &#125;&#125;\n\n十一、字符串转化使用String.valueOf(value) 代替”” + value\n把其它对象或类型转化为字符串时，使用String.valueOf(value) 比 &quot;&quot;+value 的效率更高。\n\n反例：\n//把其它对象或类型转化为字符串反例：int num = 520;// \"\" + valueString strLove = \"\" + num;\n\n正例：\n//把其它对象或类型转化为字符串正例：int num = 520;// String.valueOf() 效率更高String strLove = String.valueOf(num);\n\n十二、避免使用BigDecimal(double)\nBigDecimal(double)存在精度损失风险，在精确计算或值比较的场景中可能会导致业务逻辑异常。\n\n反例：\n// BigDecimal 反例BigDecimal bigDecimal = new BigDecimal(0.11D);\n\n正例：\n// BigDecimal 正例BigDecimal bigDecimal1 = bigDecimal.valueOf(0.11D);\n\n十三、返回空数组和集合而非 null\n若程序运行返回null，需要调用方强制检测null，否则就会抛出空指针异常；返回空数组或空集合，有效地避免了调用方因为未检测null 而抛出空指针异常的情况，还可以删除调用方检测null 的语句使代码更简洁。\n\n反例：\n//返回null 反例public static Result[] getResults() &#123;    return null;&#125;public static List&lt;Result&gt; getResultList() &#123;    return null;&#125;public static Map&lt;String, Result&gt; getResultMap() &#123;    return null;&#125;\n\n正例：\n//返回空数组和空集正例public static Result[] getResults() &#123;    return new Result[0];&#125;public static List&lt;Result&gt; getResultList() &#123;    return Collections.emptyList();&#125;public static Map&lt;String, Result&gt; getResultMap() &#123;    return Collections.emptyMap();&#125;\n\n十四、优先使用常量或确定值调用equals 方法\n对象的equals 方法容易抛空指针异常，应使用常量或确定有值的对象来调用equals 方法。\n\n反例：\n//调用 equals 方法反例private static boolean fileReader(String fileName)throws IOException&#123;    //可能抛空指针异常    return fileName.equals(\"Charming\");&#125;\n\n正例：\n//调用 equals 方法正例private static boolean fileReader(String fileName)throws IOException&#123;    //使用常量或确定有值的对象来调用 equals 方法    return \"Charming\".equals(fileName);    //或使用：java.util.Objects.equals() 方法    return Objects.equals(\"Charming\",fileName);&#125;\n\n十五、枚举的属性字段必须是私有且不可变\n枚举通常被当做常量使用，如果枚举中存在公共属性字段或设置字段方法，那么这些枚举常量的属性很容易被修改；理想情况下，枚举中的属性字段是私有的，并在私有构造函数中赋值，没有对应的Setter 方法，最好加上final 修饰符。\n\n反例：\npublic enum SwitchStatus &#123;    // 枚举的属性字段反例    DISABLED(0, \"禁用\"),    ENABLED(1, \"启用\");    public int value;    private String description;    private SwitchStatus(int value, String description) &#123;        this.value = value;        this.description = description;    &#125;    public String getDescription() &#123;        return description;    &#125;    public void setDescription(String description) &#123;        this.description = description;    &#125;&#125;\n\n正例：\npublic enum SwitchStatus &#123;    // 枚举的属性字段正例    DISABLED(0, \"禁用\"),    ENABLED(1, \"启用\");    // final 修饰    private final int value;    private final String description;    private SwitchStatus(int value, String description) &#123;        this.value = value;        this.description = description;    &#125;    // 没有Setter 方法    public int getValue() &#123;        return value;    &#125;    public String getDescription() &#123;        return description;    &#125;&#125;\n\n十六、String.split(String regex)部分关键字需要转译\n使用字符串String的split 方法时，传入的分隔字符串是正则表达式，则部分关键字（比如.[]()|等）需要转义。\n\n反例：\n// String.split(String regex) 反例String[] split = \"a.ab.abc\".split(\".\");System.out.println(Arrays.toString(split));   // 结果为[]String[] split1 = \"a|ab|abc\".split(\"|\");System.out.println(Arrays.toString(split1));  // 结果为[\"a\", \"|\", \"a\", \"b\", \"|\", \"a\", \"b\", \"c\"]\n\n正例：\n// String.split(String regex) 正例// . 需要转译String[] split2 = \"a.ab.abc\".split(\"\\\\.\");System.out.println(Arrays.toString(split2));  // 结果为[\"a\", \"ab\", \"abc\"]// | 需要转译String[] split3 = \"a|ab|abc\".split(\"\\\\|\");System.out.println(Arrays.toString(split3));  // 结果为[\"a\", \"ab\", \"abc\"]\n","tags":["Java"]},{"title":"Java网络编程介绍","url":"/2020/07/02/Java%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B%E4%BB%8B%E7%BB%8D/","content":"I/O的四种模型\n同步阻塞（Synchronous blocking I/O）\n\n同步非阻塞（Synchronous non-blocking I/0）\n\n异步阻塞（Asynchronous blocking I/0）\n\n异步非阻塞（Asynchronous non-blocking I/0）\n\n\nI/O多路复用I/O多路复用是指使用一个线程来检查多个文件描述符(Socket)的就绪状态，比如调用select和poll函数，传入多个文件描述符，如果有一个文件描述符就绪，则返回，否则阻塞直到超时。得到就绪状态后进行真正的操作可以在同一个线程里执行，也可以启动线程执行(比如使用线程池)。\n一般情况下，I/O 复用机制需要事件分发器。 事件分发器的作用，将那些读写事件源分发给各读写事件的处理者。\n涉及到事件分发器的两种模式称为：Reactor和Proactor。 Reactor模式是基于同步I/O的，而Proactor模式是和异步I/O相关的。本文主要介绍的就是 Reactor模式相关的知识。\nReactor模式Reactor模式也叫反应器模式\nIO的发展历史单线程阻塞while(true)&#123;    socket = accept();    handle(socket)&#125;\n\n这种方法的最大问题是无法并发，效率太低，如果当前的请求没有处理完，那么后面的请求只能被阻塞，服务器的吞吐量太低。\n多线程阻塞之后，想到了使用多线程，也就是很经典的connection per thread，每一个连接用一个线程处理，类似：\nimport java.io.IOException;import java.net.ServerSocket;import java.net.Socket;class BasicModel implements Runnable &#123;    public void run() &#123;        try &#123;            ServerSocket ss =                new ServerSocket(SystemConfig.SOCKET_SERVER_PORT);            while (!Thread.interrupted())                new Thread(new Handler(ss.accept())).start();            //创建新线程来handle            // or, single-threaded, or a thread pool        &#125; catch (IOException ex) &#123; /* ... */ &#125;    &#125;    static class Handler implements Runnable &#123;        final Socket socket;        Handler(Socket s) &#123; socket = s; &#125;        public void run() &#123;            try &#123;                byte[] input = new byte[SystemConfig.INPUT_SIZE];                socket.getInputStream().read(input);                byte[] output = process(input);                socket.getOutputStream().write(output);            &#125; catch (IOException ex) &#123; /* ... */ &#125;        &#125;        private byte[] process(byte[] input) &#123;            byte[] output=null;            /* ... */            return output;        &#125;    &#125;&#125;\n\n对于每一个请求都分发给一个线程，每个线程中都独自处理上面的流程。\ntomcat服务器的早期版本确实是这样实现的。\n优点定程度上极大地提高了服务器的吞吐量，因为之前的请求在read阻塞以后，不会影响到后续的请求，因为他们在不同的线程中。这也是为什么通常会讲“一个线程只能对应一个socket”的原因。\n缺点缺点在于资源要求太高，系统中创建线程是需要比较高的系统资源的，如果连接数太高，系统无法承受，而且，线程的反复创建-销毁也需要代价。\n改进采用基于事件驱动的设计，当有事件触发时，才会调用处理器进行数据处理。使用Reactor模式，对线程的数量进行控制，一个线程处理大量的事件。\n单线程NIO模型import java.io.IOException;import java.net.InetSocketAddress;import java.nio.ByteBuffer;import java.nio.channels.SelectionKey;import java.nio.channels.Selector;import java.nio.channels.ServerSocketChannel;import java.nio.channels.SocketChannel;import java.util.Iterator;class Server &#123;    public static final int SOCKET_SERVER_PORT = 8088;    public static void testServer() throws IOException &#123;        // 1、获取Selector选择器        Selector selector = Selector.open();        // 2、获取通道        ServerSocketChannel serverSocketChannel = ServerSocketChannel.open();        // 3.设置为非阻塞        serverSocketChannel.configureBlocking(false);        // 4、绑定连接        serverSocketChannel.bind(new InetSocketAddress(SOCKET_SERVER_PORT));        // 5、将通道注册到选择器上,并注册的操作为：“接收”操作        serverSocketChannel.register(selector, SelectionKey.OP_ACCEPT);        // 6、采用轮询的方式，查询获取“准备就绪”的注册过的操作        while (selector.select() &gt; 0) &#123;            // 7、获取当前选择器中所有注册的选择键（“已经准备就绪的操作”）            Iterator&lt;SelectionKey&gt; selectedKeys = selector.selectedKeys().iterator();            while (selectedKeys.hasNext()) &#123;                // 8、获取“准备就绪”的时间                SelectionKey selectedKey = selectedKeys.next();                // 9、判断key是具体的什么事件                if (selectedKey.isAcceptable()) &#123;                    // 10、若接受的事件是“接收就绪” 操作,就获取客户端连接                    SocketChannel socketChannel = serverSocketChannel.accept();                    // 11、切换为非阻塞模式                    socketChannel.configureBlocking(false);                    // 12、将该通道注册到selector选择器上                    socketChannel.register(selector, SelectionKey.OP_READ);                &#125; else if (selectedKey.isReadable()) &#123;                    // 13、获取该选择器上的“读就绪”状态的通道                    SocketChannel socketChannel = (SocketChannel) selectedKey.channel();                    // 14、读取数据                    ByteBuffer byteBuffer = ByteBuffer.allocate(1024);                    int length = 0;                    while ((length = socketChannel.read(byteBuffer)) != -1) &#123;                        byteBuffer.flip();                        System.out.println(new String(byteBuffer.array(), 0, length));                        byteBuffer.clear();                    &#125;                    socketChannel.close();                &#125;                // 15、移除选择键                selectedKeys.remove();            &#125;        &#125;        // 7、关闭连接        serverSocketChannel.close();    &#125;    public static void main(String[] args) throws IOException &#123;        testServer();    &#125;&#125;\n\n实际上的Reactor模式，是基于Java NIO的，在他的基础上，抽象出来两个组件——Reactor和Handler两个组件：\n（1）Reactor：负责响应IO事件，当检测到一个新的事件，将其发送给相应的Handler去处理；新的事件包含连接建立就绪、读就绪、写就绪等。\n（2）Handler:将自身（handler）与事件绑定，负责事件的处理，完成channel的读入，完成处理业务逻辑后，负责将结果写出channel。\n单线程Reactor参考import java.io.IOException;import java.net.InetSocketAddress;import java.nio.channels.SelectionKey;import java.nio.channels.Selector;import java.nio.channels.ServerSocketChannel;import java.nio.channels.SocketChannel;import java.util.Iterator;import java.util.Set;class Reactor implements Runnable &#123;    final Selector selector;    final ServerSocketChannel serverSocket;    Reactor(int port) throws IOException &#123; //Reactor初始化        selector = Selector.open();        serverSocket = ServerSocketChannel.open();        serverSocket.socket().bind(new InetSocketAddress(port));        //非阻塞        serverSocket.configureBlocking(false);        //分步处理,第一步,接收accept事件        SelectionKey sk = serverSocket.register(selector, SelectionKey.OP_ACCEPT);        //attach callback object, Acceptor        sk.attach(new Acceptor());    &#125;    public void run() &#123;        try &#123;            while (!Thread.interrupted()) &#123;                selector.select();                Set selected = selector.selectedKeys();                Iterator it = selected.iterator();                while (it.hasNext()) &#123;                    //Reactor负责dispatch收到的事件                    dispatch((SelectionKey) (it.next()));                &#125;                selected.clear();            &#125;        &#125; catch (IOException ex) &#123; /* ... */ &#125;    &#125;    void dispatch(SelectionKey k) &#123;        Runnable r = (Runnable) (k.attachment());        //调用之前注册的callback对象        if (r != null) &#123;            r.run();        &#125;    &#125;    // inner class    class Acceptor implements Runnable &#123;        public void run() &#123;            try &#123;                SocketChannel channel = serverSocket.accept();                if (channel != null)                    new Handler(selector, channel);            &#125; catch (IOException ex) &#123; /* ... */ &#125;        &#125;    &#125;&#125;\n\nimport java.io.IOException;import java.nio.ByteBuffer;import java.nio.channels.SelectionKey;import java.nio.channels.Selector;import java.nio.channels.SocketChannel;class Handler implements Runnable &#123;    public static final int INPUT_SIZE = 1024;    public static final int SEND_SIZE = 1024;    final SocketChannel channel;    final SelectionKey sk;    ByteBuffer input = ByteBuffer.allocate(INPUT_SIZE);    ByteBuffer output = ByteBuffer.allocate(SEND_SIZE);    static final int READING = 0, SENDING = 1;    int state = READING;    Handler(Selector selector, SocketChannel c) throws IOException &#123;        channel = c;        channel.configureBlocking(false);        // Optionally try first read now        sk = channel.register(selector, 0);        // 将Handler作为callback对象        sk.attach(this);        // 第二步,注册Read就绪事件        sk.interestOps(SelectionKey.OP_READ);        selector.wakeup();    &#125;    boolean inputIsComplete() &#123;        /* ... */        return false;    &#125;    boolean outputIsComplete() &#123;        /* ... */        return false;    &#125;    void process() &#123;        /* ... */        return;    &#125;    public void run() &#123;        try &#123;            if (state == READING) &#123;                read();            &#125; else if (state == SENDING) &#123;                send();            &#125;        &#125; catch (IOException ex) &#123; /* ... */ &#125;    &#125;    void read() throws IOException &#123;        channel.read(input);        if (inputIsComplete()) &#123;            process();            state = SENDING;            // Normally also do first write now            //第三步,接收write就绪事件            sk.interestOps(SelectionKey.OP_WRITE);        &#125;    &#125;    void send() throws IOException &#123;        channel.write(output);        //write完就结束了, 关闭select key        if (outputIsComplete()) &#123;            sk.cancel();        &#125;    &#125;&#125;\n\n1、 当其中某个 handler 阻塞时， 会导致其他所有的 client 的 handler 都得不到执行， 并且更严重的是， handler 的阻塞也会导致整个服务不能接收新的 client 请求(因为 acceptor 也被阻塞了)。 因为有这么多的缺陷， 因此单线程Reactor 模型用的比较少。这种单线程模型不能充分利用多核资源，所以实际使用的不多。\n2、因此，单线程模型仅仅适用于handler 中业务处理组件能快速完成的场景。\n多线程Reactor参考import nio.single.Handler;import java.io.IOException;import java.net.InetSocketAddress;import java.nio.channels.SelectionKey;import java.nio.channels.Selector;import java.nio.channels.ServerSocketChannel;import java.nio.channels.SocketChannel;import java.util.Iterator;import java.util.Set;class MthreadReactor implements Runnable &#123;    //subReactors集合, 一个selector代表一个subReactor    Selector[] selectors = new Selector[2];    int next = 0;    final ServerSocketChannel serverSocket;    MthreadReactor(int port) throws IOException &#123; //Reactor初始化        selectors[0] = Selector.open();        selectors[1] = Selector.open();        serverSocket = ServerSocketChannel.open();        serverSocket.socket().bind(new InetSocketAddress(port));        //非阻塞        serverSocket.configureBlocking(false);        //分步处理,第一步,接收accept事件        SelectionKey sk = serverSocket.register(selectors[0], SelectionKey.OP_ACCEPT);        //attach callback object, Acceptor        sk.attach(new Acceptor());    &#125;    public void run() &#123;        try &#123;            while (!Thread.interrupted()) &#123;                for (int i = 0; i &lt; 2; i++) &#123;                    selectors[i].select();                    Set selected = selectors[i].selectedKeys();                    Iterator it = selected.iterator();                    while (it.hasNext()) &#123;                        //Reactor负责dispatch收到的事件                        dispatch((SelectionKey) (it.next()));                    &#125;                    selected.clear();                &#125;            &#125;        &#125; catch (IOException ex) &#123; /* ... */ &#125;    &#125;    void dispatch(SelectionKey k) &#123;        Runnable r = (Runnable) (k.attachment());        //调用之前注册的callback对象        if (r != null) &#123;            r.run();        &#125;    &#125;    class Acceptor &#123; // ...        public synchronized void run() throws IOException &#123;            SocketChannel connection = serverSocket.accept(); //主selector负责accept            if (connection != null) &#123;                new Handler(selectors[next], connection); //选个subReactor去负责接收到的connection            &#125;            if (++next == selectors.length) next = 0;        &#125;    &#125;&#125;\n\nhttps://www.cnblogs.com/crazymakercircle/p/9833847.html\nhttps://www.cnblogs.com/winner-0715/p/8733787.html\nhttps://blog.csdn.net/weixin_37778801/article/details/86699341\n","tags":["Java","NIO"]},{"title":"Linux服务操作指南","url":"/2020/05/26/Linux%E6%9C%8D%E5%8A%A1%E6%93%8D%E4%BD%9C%E6%8C%87%E5%8D%97/","content":"\nhttps://www.freedesktop.org/software/systemd/man/systemd.service.html\nhttps://blog.csdn.net/yuesichiu/article/details/51485147\n\n服务路径systemd有系统和用户区分：\n\n系统：/etc/systemd/system/\n用户：/usr/lib/systemd/system/\n\n开机时，systemd只执行/etc/systemd/system/路径下的配置文件，建议在用户路径下创建，然后执行systemctl enabel mysqld，这个命令会在系统路径下创建一个链接，并且这个链接指向用户路径\n服务文件完整文件举例如下：\n[Unit]Description=MySQL ServerDocumentation=man:mysqld(8)Documentation=http://dev.mysql.com/doc/refman/en/using-systemd.htmlAfter=network.targetAfter=syslog.target[Install]WantedBy=multi-user.target[Service]User=mysqlGroup=mysqlType=forkingPIDFile=/var/run/mysql/mysqld.pidTimeoutSec=0ExecStart=/usr/local/mysql/bin/mysqld --daemonize --pid-file=/var/run/mysql/mysqld.pid $MYSQLD_OPTSEnvironmentFile=-/etc/sysconfig/mysqlLimitNOFILE = 10000Restart=on-failureRestartPreventExitStatus=1Environment=MYSQLD_PARENT_PID=1PrivateTmp=false\n\n\n所有的启动设置之前，都可以加上一个连词号（-），表示”抑制错误”，即发生错误的时候，不影响其他命令的执行。比如，EnvironmentFile=-/etc/sysconfig/mysql（注意等号后面的那个连词号），就表示即使/etc/sysconfig/mysql文件不存在，也不会抛出错误。\n\n文件分为三个部分：\n[Unit]\n启动顺序与依赖关系\n\nDescription字段给出当前服务的简单描述\nDocumentation给出文档位置\nBefore定义在哪些服务之前运行，Before=xxx.service，代表本服务在xxx.service启动之前启动。\nAfter定义在哪些服务之后运行\nRequires表示”强依赖”关系，即如果指定服务启动失败或异常退出，该服务也必须退出\nWants“弱依赖”关系，即如果指定服务启动失败或异常退出，该服务不受影响继续运行\n[Service]\n定义如何启动当前服务\n\nType定义启动类型。可以设置的值如下\n\nsimple（默认值）：ExecStart字段启动的进程为主进程\n\nforking：ExecStart字段将以fork()方式启动，此时父进程将会退出，子进程将成为主进程；对于常规的守护进程（daemon），除非你确定此启动方式无法满足需求，使用此类型启动即可。使用此启动类型应同时指定 PIDFile=，以便systemd能够跟踪服务的主进程。\n\noneshot：类似于simple，但只执行一次，Systemd 会等它执行完，才启动其他服务\n下面是一个oneshot的例子，笔记本电脑启动时，要把触摸板关掉，配置文件可以这样写。\n[Unit]Description=Switch-off Touchpad[Service]Type=oneshotExecStart=/usr/bin/touchpad-off[Install]WantedBy=multi-user.target\n\n如果关闭以后，将来某个时候还想打开，配置文件修改如下。\n[Unit]Description=Switch-off Touchpad[Service]Type=oneshotExecStart=/usr/bin/touchpad-off startExecStop=/usr/bin/touchpad-off stopRemainAfterExit=yes[Install]WantedBy=multi-user.target\n\ndbus：类似于simple，但会等待 D-Bus 信号后启动\n\nnotify：类似于simple，启动结束后会发出通知信号，然后 Systemd 再启动其他服务\n\nidle：类似于simple，但是要等到其他任务都执行完，才会启动该服务。一种使用场合是为让该服务的输出，不与其他服务的输出相混合\n\n\nPIDFilepid文件路径，一般路径都在/var/run/\nExecStart启动进程时执行的命令\nExecReload重启服务时执行的命令\nExecStop停止服务时执行的命令\nExecStartPre启动服务之前执行的命令\nExecStartPost启动服务之后执行的命令\nExecStopPost停止服务之后执行的命令\nEnvironmentFile指定当前服务的环境参数文件。该文件内部的key=value键值对，可以用$key的形式，在当前配置文件中获取。\n[Service]EnvironmentFile=/etc/sysconfig/sshdExecStart=/usr/sbin/sshd -D $OPTIONSExecReload=/bin/kill -HUP $MAINPID\n\nEnvironmentTimeoutSecLimitNOFILERestart定义了 服务退出后，Systemd 的重启方式。Restart字段可以设置的值如下。\n\nno（默认值）：退出后不会重启\non-success：只有正常退出时（退出状态码为0），才会重启\non-failure：非正常退出时（退出状态码非0），包括被信号终止和超时，才会重启\non-abnormal：只有被信号终止和超时，才会重启\non-abort：只有在收到没有捕捉到的信号终止时，才会重启\non-watchdog：超时退出，才会重启\nalways：不管是什么退出原因，总是重启\n\n对于守护进程，推荐设为on-failure。对于那些允许发生错误退出的服务，可以设为on-abnormal。\nRestartSec表示 Systemd 重启服务之前，需要等待的秒数\nRestartPreventExitStatusPrivateTmpTrue表示给服务分配独立的临时空间\nRemainAfterExit可设为”yes”或”no”(默认值)，表示当该服务的所有进程全部退出之后，是否依然将此服务视为活动(active)状态。这个选项只有在Type=oneshot时需要被配置\nKillMode定义 Systemd 如何停止 sshd 服务。\nKillMode字段可以设置的值如下。\n\ncontrol-group（默认值）：当前控制组里面的所有子进程，都会被杀掉\nprocess：只杀主进程\nmixed：主进程将收到 SIGTERM 信号，子进程收到 SIGKILL 信号\nnone：没有进程会被杀掉，只是执行服务的 stop 命令。\n\n[Unit]Description=OpenSSH server daemonDocumentation=man:sshd(8) man:sshd_config(5)After=network.target sshd-keygen.serviceWants=sshd-keygen.service[Service]EnvironmentFile=/etc/sysconfig/sshdExecStart=/usr/sbin/sshd -D $OPTIONSExecReload=/bin/kill -HUP $MAINPIDType=simpleKillMode=processRestart=on-failureRestartSec=42s\n\n上面这个例子中，将KillMode设为process，表示只停止主进程，不停止任何sshd 子进程，即子进程打开的 SSH session 仍然保持连接。这个设置不太常见，但对 sshd 很重要，否则你停止服务的时候，会连自己打开的 SSH session 一起杀掉。\n[Install]\n定义如何安装这个配置文件，即怎样做到开机启动\n\nWantBy表示该服务所在的target，target的含义是服务组，表示一组服务。WantedBy=multi-user.target指的是，当前服务所在的target是multi-user.target。这个设置非常重要，因为执行systemctl enable mysqld.service命令时，mysqld.service的一个符号链接，就会放在/etc/systemd/system目录下面的multi-user.target.wants子目录之中。\n\nsystemd 有默认的启动 target\n\n[root@zhang ~]# systemctl get-defaultmulti-user.target\n\n上面的结果表示，默认的启动target是multi-user.target。在这个组里的所有服务，都将开机启动。这就是为什么systemctl enable命令能设置开机启动的原因。\n\n查看 multi-user.target 包含的所有服务\n\nsystemctl list-dependencies multi-user.target\n\n\n切换到另一个 target\n\n# shutdown.target 就是关机状态sudo systemctl isolate shutdown.target\n\n  一般来说，常用的 Target 有两个：一个是multi-user.target，表示多用户命令行状态；另一个是graphical.target，表示图形用户状态，它依赖于multi-user.target。官方文档有一张非常清晰的 Target 依赖关系图。\n重新加载修改配置文件之后，需要重新加载配置文件\nsystemctl daemon-reload\n\n操作服务重载服务# 就会在/etc/systemd/system/multi-user.target.wants/目录下新建一个/usr/lib/systemd/system/mysql.service 文件的链接systemctl enable mysql.service# 相对应，可以用 disable 把它从 wants 目录给删除。systemctl disable mysql.servicesystemctl reload mysql.service\n\n启动停止重启systemctl start mysql.servicesystemctl stop mysql.servicesystemctl restart mysql.servicesystemctl kill mysql.service\n\n查看状态日志systemctl status mysql.servicejournalctl -f -u mysql.service\n","tags":["Linux"]},{"title":"Markdown数学公式语法","url":"/2020/03/21/Markdown%E6%95%B0%E5%AD%A6%E5%85%AC%E5%BC%8F%E8%AF%AD%E6%B3%95/","content":"行内与独行\n行内公式：将公式插入到本行内，符号：$公式内容$，如：$xyz$\n独行公式：将公式插入到新的一行内，并且居中，符号：$$公式内容$$，如：$$xyz$$\n\n上标、下标与组合\n上标符号，符号：^，如：$x^4$\n下标符号，符号：_，如：$x_1$\n组合符号，符号：{}，如：${16}{8}O{2+}{2}$\n\n汉字、字体与格式\n汉字形式，符号：\\mbox{}，如：$V_{\\mbox{初始}}$\n字体控制，符号：\\displaystyle，如：$\\displaystyle \\frac{x+y}{y+z}$\n下划线符号，符号：\\underline，如：$\\underline{x+y}$\n标签，符号\\tag{数字}，如：$\\tag{11}$\n上大括号，符号：\\overbrace{算式}，如：$\\overbrace{a+b+c+d}^{2.0}$\n下大括号，符号：\\underbrace{算式}，如：$a+\\underbrace{b+c}_{1.0}+d$\n上位符号，符号：\\stacrel{上位符号}{基位符号}，如：$\\vec{x}\\stackrel{\\mathrm{def}}{=}{x_1,\\dots,x_n}$\n\n占位符\n两个quad空格，符号：\\qquad，如：$x \\qquad y$\nquad空格，符号：\\quad，如：$x \\quad y$\n大空格，符号\\，如：$x \\ y$\n中空格，符号\\:，如：$x : y$\n小空格，符号\\,，如：$x , y$\n没有空格，符号``，如：$xy$\n紧贴，符号\\!，如：$x ! y$\n\n定界符与组合\n括号，符号：（）\\big(\\big) \\Big(\\Big) \\bigg(\\bigg) \\Bigg(\\Bigg)，如：$（）\\big(\\big) \\Big(\\Big) \\bigg(\\bigg) \\Bigg(\\Bigg)$\n中括号，符号：[]，如：$[x+y]$\n大括号，符号：\\{ \\}，如：${x+y}$\n自适应括号，符号：\\left \\right，如：$\\left(x\\right)$，$\\left(x{yz}\\right)$\n组合公式，符号：{上位公式 \\choose 下位公式}，如：${n+1 \\choose k}={n \\choose k}+{n \\choose k-1}$\n组合公式，符号：{上位公式 \\atop 下位公式}，如：$\\sum_{k_0,k_1,\\ldots&gt;0 \\atop k_0+k_1+\\cdots=n}A_{k_0}A_{k_1}\\cdots$\n\n四则运算\n加法运算，符号：+，如：$x+y=z$\n减法运算，符号：-，如：$x-y=z$\n加减运算，符号：\\pm，如：$x \\pm y=z$\n减甲运算，符号：\\mp，如：$x \\mp y=z$\n乘法运算，符号：\\times，如：$x \\times y=z$\n点乘运算，符号：\\cdot，如：$x \\cdot y=z$\n星乘运算，符号：\\ast，如：$x \\ast y=z$\n除法运算，符号：\\div，如：$x \\div y=z$\n斜法运算，符号：/，如：$x/y=z$\n分式表示，符号：\\frac{分子}{分母}，如：$\\frac{x+y}{y+z}$\n分式表示，符号：{分子} \\voer {分母}，如：${x+y} \\over {y+z}$\n绝对值表示，符号：||，如：$|x+y|$\n\n高级运算\n平均数运算，符号：\\overline{算式}，如：$\\overline{xyz}$\n开二次方运算，符号：\\sqrt，如：$\\sqrt x$\n开方运算，符号：\\sqrt[开方数]{被开方数}，如：$\\sqrt[3]{x+y}$\n对数运算，符号：\\log，如：$\\log(x)$\n极限运算，符号：\\lim，如：$\\lim^{x \\to \\infty}_{y \\to 0}{\\frac{x}{y}}$\n极限运算，符号：\\displaystyle \\lim，如：$\\displaystyle \\lim^{x \\to \\infty}_{y \\to 0}{\\frac{x}{y}}$\n求和运算，符号：\\sum，如：$\\sum^{x \\to \\infty}_{y \\to 0}{\\frac{x}{y}}$\n求和运算，符号：\\displaystyle \\sum，如：$\\displaystyle \\sum^{x \\to \\infty}_{y \\to 0}{\\frac{x}{y}}$\n积分运算，符号：\\int，如：$\\int^{\\infty}_{0}{xdx}$\n积分运算，符号：\\displaystyle \\int，如：$\\displaystyle \\int^{\\infty}_{0}{xdx}$\n微分运算，符号：\\partial，如：$\\frac{\\partial x}{\\partial y}$\n矩阵表示，符号：\\begin{matrix} \\end{matrix}，如：$\\left[ \\begin{matrix} 1 &amp;2 &amp;\\cdots &amp;4\\5 &amp;6 &amp;\\cdots &amp;8\\vdots &amp;\\vdots &amp;\\ddots &amp;\\vdots\\13 &amp;14 &amp;\\cdots &amp;16\\end{matrix} \\right]$\n\n逻辑运算\n等于运算，符号：=，如：$x+y=z$\n大于运算，符号：&gt;，如：$x+y&gt;z$\n小于运算，符号：&lt;，如：$x+y&lt;z$\n大于等于运算，符号：\\geq，如：$x+y \\geq z$\n小于等于运算，符号：\\leq，如：$x+y \\leq z$\n不等于运算，符号：\\neq，如：$x+y \\neq z$\n不大于等于运算，符号：\\ngeq，如：$x+y \\ngeq z$\n不大于等于运算，符号：\\not\\geq，如：$x+y \\not\\geq z$\n不小于等于运算，符号：\\nleq，如：$x+y \\nleq z$\n不小于等于运算，符号：\\not\\leq，如：$x+y \\not\\leq z$\n约等于运算，符号：\\approx，如：$x+y \\approx z$\n恒定等于运算，符号：\\equiv，如：$x+y \\equiv z$\n\n集合运算\n属于运算，符号：\\in，如：$x \\in y$\n不属于运算，符号：\\notin，如：$x \\notin y$\n不属于运算，符号：\\not\\in，如：$x \\not\\in y$\n子集运算，符号：\\subset，如：$x \\subset y$\n子集运算，符号：\\supset，如：$x \\supset y$\n真子集运算，符号：\\subseteq，如：$x \\subseteq y$\n非真子集运算，符号：\\subsetneq，如：$x \\subsetneq y$\n真子集运算，符号：\\supseteq，如：$x \\supseteq y$\n非真子集运算，符号：\\supsetneq，如：$x \\supsetneq y$\n非子集运算，符号：\\not\\subset，如：$x \\not\\subset y$\n非子集运算，符号：\\not\\supset，如：$x \\not\\supset y$\n并集运算，符号：\\cup，如：$x \\cup y$\n交集运算，符号：\\cap，如：$x \\cap y$\n差集运算，符号：\\setminus，如：$x \\setminus y$\n同或运算，符号：\\bigodot，如：$x \\bigodot y$\n同与运算，符号：\\bigotimes，如：$x \\bigotimes y$\n实数集合，符号：\\mathbb{R}，如：\\mathbb{R}\n自然数集合，符号：\\mathbb{Z}，如：\\mathbb{Z}\n空集，符号：\\emptyset，如：$\\emptyset$\n\n数学符号\n无穷，符号：\\infty，如：$\\infty$\n虚数，符号：\\imath，如：$\\imath$\n虚数，符号：\\jmath，如：$\\jmath$\n数学符号，符号\\hat{a}，如：$\\hat{a}$\n数学符号，符号\\check{a}，如：$\\check{a}$\n数学符号，符号\\breve{a}，如：$\\breve{a}$\n数学符号，符号\\tilde{a}，如：$\\tilde{a}$\n数学符号，符号\\bar{a}，如：$\\bar{a}$\n矢量符号，符号\\vec{a}，如：$\\vec{a}$\n数学符号，符号\\acute{a}，如：$\\acute{a}$\n数学符号，符号\\grave{a}，如：$\\grave{a}$\n数学符号，符号\\mathring{a}，如：$\\mathring{a}$\n一阶导数符号，符号\\dot{a}，如：$\\dot{a}$\n二阶导数符号，符号\\ddot{a}，如：$\\ddot{a}$\n上箭头，符号：\\uparrow，如：$\\uparrow$\n上箭头，符号：\\Uparrow，如：$\\Uparrow$\n下箭头，符号：\\downarrow，如：$\\downarrow$\n下箭头，符号：\\Downarrow，如：$\\Downarrow$\n左箭头，符号：\\leftarrow，如：$\\leftarrow$\n左箭头，符号：\\Leftarrow，如：$\\Leftarrow$\n右箭头，符号：\\rightarrow，如：$\\rightarrow$\n右箭头，符号：\\Rightarrow，如：$\\Rightarrow$\n底端对齐的省略号，符号：\\ldots，如：$1,2,\\ldots,n$\n中线对齐的省略号，符号：\\cdots，如：$x_1^2 + x_2^2 + \\cdots + x_n^2$\n竖直对齐的省略号，符号：\\vdots，如：$\\vdots$\n斜对齐的省略号，符号：\\ddots，如：$\\ddots$\n\n希腊字母\n\n\n字母\n实现\n字母\n实现\n\n\n\nA\nA\nα\n\\alhpa\n\n\nB\nB\nβ\n\\beta\n\n\nΓ\n\\Gamma\nγ\n\\gamma\n\n\nΔ\n\\Delta\nδ\n\\delta\n\n\nE\nE\nϵ\n\\epsilon\n\n\nZ\nZ\nζ\n\\zeta\n\n\nH\nH\nη\n\\eta\n\n\nΘ\n\\Theta\nθ\n\\theta\n\n\nI\nI\nι\n\\iota\n\n\nK\nK\nκ\n\\kappa\n\n\nΛ\n\\Lambda\nλ\n\\lambda\n\n\nM\nM\nμ\n\\mu\n\n\nN\nN\nν\n\\nu\n\n\nΞ\n\\Xi\nξ\n\\xi\n\n\nO\nO\nο\n\\omicron\n\n\nΠ\n\\Pi\nπ\n\\pi\n\n\nP\nP\nρ\n\\rho\n\n\nΣ\n\\Sigma\nσ\n\\sigma\n\n\nT\nT\nτ\n\\tau\n\n\nΥ\n\\Upsilon\nυ\n\\upsilon\n\n\nΦ\n\\Phi\nϕ\n\\phi\n\n\nX\nX\nχ\n\\chi\n\n\nΨ\n\\Psi\nψ\n\\psi\n\n\nΩ\n\\v\nω\n\\omega\n\n\n"},{"title":"Maven常用命令","url":"/2019/12/09/Maven%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/","content":"将jar安装到本地Maven仓库\n转自：https://blog.csdn.net/ShuSheng0007/article/details/78547264/\n\n第一种方案mvn install:install-file -Dfile=&lt;path-to-file&gt; -DgroupId=&lt;group-id&gt; -DartifactId=&lt;artifact-id&gt; -Dversion=&lt;version&gt; -Dpackaging=&lt;packaging&gt;\n\n\n&lt;path-to-file&gt;: 要安装的JAR的本地路径\n&lt;group-id&gt;：要安装的JAR的Group Id\n&lt;artifact-id&gt;: 要安装的JAR的 Artificial Id\n&lt;version&gt;: JAR 版本\n&lt;packaging&gt;: 打包类型，例如JAR\n\n\n最好在pom.xml文件所在的目录运行上述命令，个人经验不在根目录运行有时会安装不成功\n\n执行上述命令后，我们就可以在pom.xml文件中引用\n&lt;dependency&gt;    &lt;groupId&gt;com.baidu.app&lt;/groupId&gt;    &lt;artifactId&gt;bdpush&lt;/artifactId&gt;    &lt;version&gt;3.0.1&lt;/version&gt;&lt;/dependency&gt;\n\n总结：这种方法弊端较大，程序的可维护性以及移植性较低。例如当你改变本地Maven仓库时需要重新安装。如果引用此JAR的项目是多人协调工作的项目，则每个人都要将其安装在自己的本地仓库。\n解决办法可以将此JAR文件放在工程的根目录下，让其随着项目走，然后在pom.xml文件中使用maven-install-plugin在Maven初始化阶段完成安装。\n&lt;plugin&gt;    &lt;groupId&gt;org.apache.maven.plugins&lt;/groupId&gt;    &lt;artifactId&gt;maven-install-plugin&lt;/artifactId&gt;    &lt;version&gt;2.5&lt;/version&gt;    &lt;executions&gt;        &lt;execution&gt;            &lt;phase&gt;initialize&lt;/phase&gt;            &lt;goals&gt;                &lt;goal&gt;install-file&lt;/goal&gt;            &lt;/goals&gt;            &lt;configuration&gt;                &lt;groupId&gt;com.baidu.app&lt;/groupId&gt;                &lt;artifactId&gt;bdpush&lt;/artifactId&gt;                &lt;version&gt;3.0.1&lt;/version&gt;                &lt;packaging&gt;jar&lt;/packaging&gt;                &lt;file&gt;$&#123;basedir&#125;/lib/bdpush-3.0.1.ja&lt;/file&gt;            &lt;/configuration&gt;        &lt;/execution&gt;    &lt;/executions&gt;&lt;/plugin&gt;\n\n${basedir}表示pom.xml文件所在的目录\n第二种方案第二种方法比较粗暴简单，具体为将依赖设置为系统域，通过完全路径引用。例如要引用的JAR文件在 &lt;PROJECT_ROOT_FOLDER&gt;/lib下，那么使用如下方法添加依赖\n&lt;dependency&gt;    &lt;groupId&gt;com.baidu.app&lt;/groupId&gt;    &lt;artifactId&gt;bdpush&lt;/artifactId&gt;    &lt;version&gt;3.0.1&lt;/version&gt;    &lt;scope&gt;system&lt;/scope&gt;    &lt;systemPath&gt;$&#123;basedir&#125;/lib/bdpush-3.0.1.ja&lt;/systemPath&gt;&lt;/dependency&gt;\n\n${basedir}表示pom.xml文件所在的目录，例如你的JAR文件在D盘下的jarLibs里面，就将${basedir}替换为D:/jarLibs即可。\n\n这种方法我自己在SpringBoot项目中打包成war文件时，没有成功打包到里面\n\n第三种方案第三种方案与第一种差不多，不同的是JAR文件被安装在一个单独的仓库里。这个本地仓库建在你项目的根目录下，随着项目走。例如\n1：我们在${basedir}（pom.xml文件所在路径）目录下建立一个叫maven-repository的本地仓库。\n2：使用如下命令安装我们要引用的JAR到此仓库中\nmvn deploy:deploy-file -Dfile=&lt;path-to-file&gt; -DgroupId=&lt;group-id&gt; -DartifactId=&lt;artifact-id&gt; -Dversion=&lt;version&gt; -Dpackaging=jar -Durl=file:./maven-repository/ -DrepositoryId=maven-repository -DupdateReleaseInfo=true\n\n3：在pom.xml中如下使用\n\n申明仓库\n\n&lt;repositories&gt;    &lt;repository&gt;        &lt;id&gt;maven-repository&lt;/id&gt;        &lt;url&gt;file:///$&#123;project.basedir&#125;/maven-repository&lt;/url&gt;    &lt;/repository&gt;&lt;/repositories&gt;\n\n\n然后添加引用\n\n&lt;dependency&gt;    &lt;groupId&gt;com.baidu.app&lt;/groupId&gt;    &lt;artifactId&gt;bdpush&lt;/artifactId&gt;    &lt;version&gt;3.0.1&lt;/version&gt;&lt;/dependency&gt;\n\nMaven常用命令[root@zhang ~]# mvn --helpusage: mvn [options] [&lt;goal(s)&gt;] [&lt;phase(s)&gt;]Options: -am,--also-make                        If project list is specified, also                                        build projects required by the                                        list -amd,--also-make-dependents            If project list is specified, also                                        build projects that depend on                                        projects on the list -B,--batch-mode                        Run in non-interactive (batch)                                        mode (disables output color) -b,--builder &lt;arg&gt;                     The id of the build strategy to                                        use -C,--strict-checksums                  Fail the build if checksums don't                                        match -c,--lax-checksums                     Warn if checksums don't match -cpu,--check-plugin-updates            Ineffective, only kept for                                        backward compatibility -D,--define &lt;arg&gt;                      Define a system property -e,--errors                            Produce execution error messages -emp,--encrypt-master-password &lt;arg&gt;   Encrypt master security password -ep,--encrypt-password &lt;arg&gt;           Encrypt server password -f,--file &lt;arg&gt;                        Force the use of an alternate POM                                        file (or directory with pom.xml) -fae,--fail-at-end                     Only fail the build afterwards;                                        allow all non-impacted builds to                                        continue -ff,--fail-fast                        Stop at first failure in                                        reactorized builds -fn,--fail-never                       NEVER fail the build, regardless                                        of project result -gs,--global-settings &lt;arg&gt;            Alternate path for the global                                        settings file -gt,--global-toolchains &lt;arg&gt;          Alternate path for the global                                        toolchains file -h,--help                              Display help information -l,--log-file &lt;arg&gt;                    Log file where all build output                                        will go (disables output color) -llr,--legacy-local-repository         Use Maven 2 Legacy Local                                        Repository behaviour, ie no use of                                        _remote.repositories. Can also be                                        activated by using                                        -Dmaven.legacyLocalRepo=true -N,--non-recursive                     Do not recurse into sub-projects -npr,--no-plugin-registry              Ineffective, only kept for                                        backward compatibility -npu,--no-plugin-updates               Ineffective, only kept for                                        backward compatibility -nsu,--no-snapshot-updates             Suppress SNAPSHOT updates -ntp,--no-transfer-progress            Do not display transfer progress                                        when downloading or uploading -o,--offline                           Work offline -P,--activate-profiles &lt;arg&gt;           Comma-delimited list of profiles                                        to activate -pl,--projects &lt;arg&gt;                   Comma-delimited list of specified                                        reactor projects to build instead                                        of all projects. A project can be                                        specified by [groupId]:artifactId                                        or by its relative path -q,--quiet                             Quiet output - only show errors -rf,--resume-from &lt;arg&gt;                Resume reactor from specified                                        project -s,--settings &lt;arg&gt;                    Alternate path for the user                                        settings file -t,--toolchains &lt;arg&gt;                  Alternate path for the user                                        toolchains file -T,--threads &lt;arg&gt;                     Thread count, for instance 2.0C                                        where C is core multiplied -U,--update-snapshots                  Forces a check for missing                                        releases and updated snapshots on                                        remote repositories -up,--update-plugins                   Ineffective, only kept for                                        backward compatibility -v,--version                           Display version information -V,--show-version                      Display version information                                        WITHOUT stopping build -X,--debug                             Produce execution debug output\n\nmvn package \\\t-Dmaven.repo.local&#x3D;C:\\Users\\lenovo\\.m2\\Repository4 \\\t-Dmaven.test.skip&#x3D;true \\\t-f pom.xml\n\n\n-Dmaven.repo.local 强制使用本地源\n-Dmaven.test.skip 跳过单测\n-f 指定配置文件\n\n","tags":["Maven"]},{"title":"MySQL5.7基于GTID及多线程主从复制","url":"/2020/04/17/MySQL57%E5%9F%BA%E4%BA%8EGTID%E5%8F%8A%E5%A4%9A%E7%BA%BF%E7%A8%8B%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6/","content":"\n转自：https://www.sundayle.com/mysql-gtid-relication/\n\nMySQL主从同步原理\n参考文档\n\nMySQL主从同步是在MySQL主从复制(Master-Slave Replication)基础上实现的，通过设置在Master MySQL上的binlog(使其处于打开状态)，Slave MySQL上通过一个I/O线程从Master MySQL上读取binlog，然后传输到Slave MySQL的中继日志中，然后Slave MySQL的SQL线程从中继日志中读取中继日志，然后应用到Slave MySQL的数据库中。这样实现了主从数据同步功能。\nMySQL中主从复制的优点\n横向扩展解决方案在多个从库之间扩展负载以提高性能。在这种环境中，所有写入和更新在主库上进行。但是，读取可能发生在一个或多个从库上。该模型可以提高写入的性能（由于主库专用于更新），同时在多个从库上读取，可以大大提高读取速度。\n数据安全性由于主库数据被复制到从库，从库可以暂停复制过程，可以在从库上运行备份服务，而不会破坏对应的主库数据。\n分析可以在主库上创建实时数据，而信息分析可以在从库上进行，而不会影响主服务器的性能。\n\nGTID概念从 MySQL 5.6.5 开始新增了一种基于 GTID 的复制方式。通过 GTID保证了每个在主库上提交的事务在集群中有一个唯一的ID。这种方式强化了数据库的主备一致性，故障恢复以及容错能力。在原来基于二进制日志的复制中，从库需要告知主库要从哪个偏移量进行增量同步，如果指定错误会造成数据的遗漏，从而造成数据的不一致。借助GTID，在发生主备切换的情况下，MySQL的其它从库可以自动在新主库上找到正确的复制位置，这大大简化了复杂复制拓扑下集群的维护，也减少了人为设置复制位置发生误操作的风险。另外，基于GTID的复制可以忽略已经执行过的事务，减少了数据发生不一致的风险。\n什么是GTIDGTID (Global Transaction ID) 是对于一个已提交事务的编号，并且是一个全局唯一的编号。 GTID 实际上是由UUID+TID 组成的。其中 UUID 是一个 MySQL 实例的唯一标识。TID代表了该实例上已经提交的事务数量，并且随着事务提交单调递增。下面是一个GTID的具体形式：\n3E11FA47-71CA-11E1-9E33-C80AA9429562:23，冒号分割前边为uuid，后边为TID。\nGTID 集合可以包含来自多个 MySQL 实例的事务，它们之间用逗号分隔。如果来自同一MySQL实例的事务序号有多个范围区间，各组范围之间用冒号分隔。\n例如：\ne6954592-8dba-11e6-af0e-fa163e1cf111:1-5:11-18,\ne6954592-8dba-11e6-af0e-fa163e1cf3f2:1-27\n可以使用show master status实时查看当前事务执行数。\nGTID的作用GTID采用了新的复制协议，旧协议是，首先从服务器上在一个特定的偏移量位置连接到主服务器上一个给定的二进制日志文件，然后主服务器再从给定的连接点开始发送所有的事件。新协议有所不同，支持以全局统一事务ID (GTID)为基础的复制。当在主库上提交事务或者被从库应用时，可以定位和追踪每一个事务。GTID复制是全部以事务为基础，使得检查主从一致性变得非常简单。如果所有主库上提交的事务也同样提交到从库上，一致性就得到了保证。\nGTID的工作原理①当一个事务在主库端执行并提交时，产生GTID，一同记录到binlog日志中。②binlog传输到slave,并存储到slave的relaylog后，读取这个GTID的这个值设置gtid_next变量，即告诉Slave，下一个要执行的GTID值。③sql线程从relay log中获取GTID，然后对比slave端的binlog是否有该GTID。④如果有记录，说明该GTID的事务已经执行，slave会忽略。⑤如果没有记录，slave就会执行该GTID事务，并记录该GTID到自身的binlog，在读取执行事务前会先检查其他session持有该GTID，确保不被重复执行。⑥在解析过程中会判断是否有主键，如果没有就用二级索引，如果没有就用全部扫描。\n操作环境系统：CentOS 7数据库：MySQL 5.7主库：192.168.11.31从库：192.168.11.32\n主库配置[mysqld]datadir&#x3D;&#x2F;data&#x2F;mysql&#x2F;3306socket&#x3D;&#x2F;tmp&#x2F;mysql.socksymbolic-links&#x3D;0#服务器IDserver-id&#x3D;169#二进制日志文件名log-bin&#x3D;master-bin#强烈建议，其他格式可能造成数据不一致binlog_format &#x3D; row#是否记录从服务器同步数据动作log-slave-updates &#x3D; 1#启用gitd功能gtid-mode &#x3D; on#开启强制GTID一致性enforce-gtid-consistency &#x3D; 1#记录IO线程读取已经读取到的master binlog位置，用于slave宕机后IO线程根据文件中的POS点重新拉取binlog日志master-info-repository &#x3D; TABLE#记录SQL线程读取Master binlog的位置，用于slave宕机后根据文件中记录的pos点恢复Sql线程relay-log-info-repository &#x3D; TABLE#启用确保无信息丢失；任何一个事务提交后, 将二进制日志的文件名及事件位置记录到文件中sync-master-info &#x3D; 1#设定从服务器的复制线程数；0表示关闭多线程复制功能slave-parallel-workers &#x3D; 2#设置binlog校验算法（循环冗余校验码）binlog-checksum &#x3D; CRC32#设置主服务器是否校验master-verify-checksum &#x3D; 1#设置从服务器是否校验slave-sql-verify-checksum &#x3D; 1#用于在二进制日志记录事件相关的信息，可降低故障排除的复杂度binlog-rows-query-log_events &#x3D; 1#保证master crash safe，该参数必须设置为1sync_binlog &#x3D; 1#保证master crash safe，该参数必须设置为1innodb_flush_log_at_trx_commit &#x3D; 1\n\n从库配置[mysqld]server_id &#x3D; 32log-bin&#x3D;mysql-binbinlog_format &#x3D; rowgtid-mode &#x3D; onenforce-gtid-consistency &#x3D; 1master-info-repository &#x3D; TABLErelay-log-info-repository &#x3D; TABLEsync-master-info &#x3D; 1slave-parallel-workers &#x3D; 4binlog-checksum &#x3D; CRC32master-verify-checksum &#x3D; 1slave-sql-verify-checksum &#x3D; 1binlog-rows-query-log_events &#x3D; 1#sync_binlog &#x3D; 1#innodb_flush_log_at_trx_commit &#x3D; 1log-slave-updates &#x3D; 0 \t\t\t\t# crash safe slave 5.6版本需要开启relay_log_recovery &#x3D; 1  \t\t\t# crash safe slaveread_only&#x3D;on        \t\t\t\t#设置一般用户为只读模式super_read_only&#x3D;on      \t\t\t#设置super（root）用户为只读模式#tx_read_only&#x3D;on     \t\t\t\t#设置事务为只读模式\n\n主库权限设置mysql &gt; grant replication slave on *.* to slave@&#39;192.168.11.32&#39; identified by &#39;slave123&#39;;mysql &gt; flush privileges;\n\n自动同步连接主库(方法一)适用于master也是新建不久的情况。\n\n如果你的master所有的binlog还在。可以安装slave，slave直接change master to到master端。\n原理是直接获取master所有的GTID并执行。\n优点：简单方便。\n缺点：如果binlog太多，数据完全同步需要时间较长，并且master一开始就启用了GTUD。\n\nchange master tomaster_host&#x3D;&#39;192.168.11.31&#39;,master_user&#x3D;&#39;slave&#39;,master_password&#x3D;&#39;slave123&#39;,master_port&#x3D;3306,master_auto_position&#x3D;1#master_auto_position&#x3D;1 从库自动找同步点\n\n备份导入连接主库(方法二)\nXtrabackup_binlog_info文件中，包含global.gtid_purged=&#39;XXXXXX:XXXX&#39;的信息。\n然后到slave去手工的 SET @@GLOBAL.GTID_PURGED=&#39;XXXXXX:XXXX&#39;。\n恢复备份，开启change master to 命令。\n\n备份导入连接主库(方法三)适用于拥有较大数据的情况。（推荐）\n\n通过master或者其他slave的备份搭建新的slave。\n原理：获取master的数据和这些数据对应的GTID范围，然后通过slave设置master_auto_position=1,自动同步，跳过备份包含的gtid。\n缺点：相对来说有点复杂。\n\n将主库设为只读模式注：生产环境会影响不能写入数据\nmysql&gt; flush tables with read lock;Query OK, 0 rows affected (0.00 sec)mysql&gt; set global read_only&#x3D;on;Query OK, 0 rows affected (0.00 sec)\n\n主库使用mysqldump导出可以同时导出多个数据库，如music、record\nmysqldump --databases &lt;数据库名&gt;  --single-transaction --order-by-primary -r &lt;备份文件名&gt; --routines -h&lt;服务器地址&gt;  -P&lt;端口号&gt; -u&lt;用户名&gt; -p&lt;密码&gt;mysqldump --default-character-set&#x3D;utf8mb4 --single-transaction --triggers --routines --events --hex-blob --databases muisc record &gt; music_record.sql\n\n记录GTID_PURGED\ngrep -r &quot;GLOBAL.GTID_PURGED&quot; music_record.sqlSET @@GLOBAL.GTID_PURGED&#x3D;&#39;3cdb9ce6-0d7e-11e8-abe4-001517b5a5f0:1-698887&#39;;\n\n注意：mysql服务器内置的库包括mysql库和test库不需要导出。\n\n将主库设为可读写模式数据库导出完成后将主库重新设为可读写模式。\nmysql&gt; set global read_only&#x3D;off;mysql&gt; unlock tables;\n\n从库数据导入#mysql&gt; create database &#96;music&#96;;#mysql -u root -p muisc &lt; &#x2F;root&#x2F;music.sqlmysql -u root -p &lt; &#x2F;root&#x2F;music_record.sqlmysql&gt; reset slave all;mysql&gt; reset master;mysql&gt; SET @@GLOBAL.GTID_PURGED&#x3D;&#39;3cdb9ce6-0d7e-11e8-abe4-001517b5a5f0:1-698887&#39;;\n\n从库连接主库change master tomaster_host&#x3D;&#39;192.168.11.31&#39;,master_user&#x3D;&#39;slave&#39;,master_password&#x3D;&#39;slave123&#39;,master_port&#x3D;3306,master_auto_position&#x3D;1;\n\n从库启动复制线程mysql&gt; start slave;\n\n从库查看复制状态mysql&gt; show slave status\\G;*************************** 1. row ***************************               Slave_IO_State: Waiting for master to send event                  Master_Host: 192.168.11.31                  Master_User: slave                  Master_Port: 3306                Connect_Retry: 60              Master_Log_File: master-bin.000002          Read_Master_Log_Pos: 149375983               Relay_Log_File: db2-relay-bin.000002                Relay_Log_Pos: 321        Relay_Master_Log_File: master-bin.000002             Slave_IO_Running: Yes            Slave_SQL_Running: Yes              Replicate_Do_DB:          Replicate_Ignore_DB:           Replicate_Do_Table:       Replicate_Ignore_Table:      Replicate_Wild_Do_Table:  Replicate_Wild_Ignore_Table:                   Last_Errno: 0                   Last_Error:                 Skip_Counter: 0          Exec_Master_Log_Pos: 149375983              Relay_Log_Space: 526              Until_Condition: None               Until_Log_File:                Until_Log_Pos: 0           Master_SSL_Allowed: No           Master_SSL_CA_File:           Master_SSL_CA_Path:              Master_SSL_Cert:            Master_SSL_Cipher:               Master_SSL_Key:        Seconds_Behind_Master: 0Master_SSL_Verify_Server_Cert: No                Last_IO_Errno: 0                Last_IO_Error:               Last_SQL_Errno: 0               Last_SQL_Error:  Replicate_Ignore_Server_Ids:             Master_Server_Id: 31                  Master_UUID: 834449ff-4487-11e8-8b27-000c294b06ca             Master_Info_File: mysql.slave_master_info                    SQL_Delay: 0          SQL_Remaining_Delay: NULL      Slave_SQL_Running_State: Slave has read all relay log; waiting for more updates           Master_Retry_Count: 86400                  Master_Bind:      Last_IO_Error_Timestamp:     Last_SQL_Error_Timestamp:               Master_SSL_Crl:           Master_SSL_Crlpath:           Retrieved_Gtid_Set:            Executed_Gtid_Set:                Auto_Position: 0         Replicate_Rewrite_DB:                 Channel_Name:           Master_TLS_Version:1 row in set (0.00 sec)ERROR:No query specified\n\n检查主从复制通信状态\nSlave_IO_State #从站的当前状态Slave_IO_Running： Yes #读取主程序二进制日志的I/O线程是否正在运行Slave_SQL_Running： Yes #执行读取主服务器中二进制日志事件的SQL线程是否正在运行。与I/O线程一样Seconds_Behind_Master #是否为0，0就是已经同步了\n如果再次查询状态仍然 发现Slave_IO_Running 或者Slave_SQL_Running 不同时为YES,尝试执行\nmysql&gt; stop slave;mysql&gt; reset slave;mysql&gt; start slave;\n\n主库查看状态mysql&gt; show master status;+-------------------+-----------+--------------+------------------+--------------------------------------------+| File              | Position  | Binlog_Do_DB | Binlog_Ignore_DB | Executed_Gtid_Set                          |+-------------------+-----------+--------------+------------------+--------------------------------------------+| master-bin.000002 | 149375983 |              |                  | 834449ff-4487-11e8-8b27-000c294b06ca:1-254 |+-------------------+-----------+--------------+------------------+--------------------------------------------+1 row in set (0.00 sec)mysql&gt; show slave hosts;+-----------+------+------+-----------+--------------------------------------+| Server_id | Host | Port | Master_id | Slave_UUID                           |+-----------+------+------+-----------+--------------------------------------+|        32 |      | 3306 |        31 | 68303133-4489-11e8-84e9-000c293eaee6 |+-----------+------+------+-----------+--------------------------------------+1 row in set (0.00 sec)mysql&gt; show global variables like &#39;%gtid%&#39;;+----------------------------------+--------------------------------------------+| Variable_name                    | Value                                      |+----------------------------------+--------------------------------------------+| binlog_gtid_simple_recovery      | ON                                         || enforce_gtid_consistency         | ON                                         || gtid_executed                    | 834449ff-4487-11e8-8b27-000c294b06ca:1-255 || gtid_executed_compression_period | 1000                                       || gtid_mode                        | ON                                         || gtid_owned                       |                                            || gtid_purged                      |                                            || session_track_gtids              | OFF                                        |+----------------------------------+--------------------------------------------+8 rows in set (0.00 sec)\n\n其他命令mysql&gt; show binlog events;mysql&gt; show binlog events in &#39;master-bin.000001&#39;;mysql&gt; show master logs;mysql&gt; show processlistmysql&gt; show full processlist;\n\nGTID与crash safe slave查看错误\nmysql&gt; select * from performance_schema.replication_applier_status_by_worker where LAST_ERROR_NUMBER&#x3D;1007\\G;\n\nhttps://docs.azure.cn/zh-cn/mysql/mysql-database-data-replicationGTID原理和一些问题解答MySQL 5.7 Replication 相关新功能说明\n","tags":["MySQL","数据库"]},{"title":"MySQL各种JOIN介绍","url":"/2020/06/16/MySQL%E5%90%84%E7%A7%8DJOIN%E4%BB%8B%E7%BB%8D/","content":"前言在各种问答社区里谈及 SQL 里的各种 JOIN 之间的区别时，最被广为引用的是 CodeProject 上 C.L. Moffatt 的文章 Visual Representation of SQL Joins，他确实讲得简单明了，使用文氏图来帮助理解，效果明显。本文将沿用他的讲解方式，稍有演绎，可以视为该文较为粗糙的中译版。\n约定下文将使用两个数据库表 Table_A 和 Table_B 来进行示例讲解，其结构与数据分别如下：\nmysql&gt; SELECT * FROM Table_A ORDER BY PK ASC;+----+---------+| PK | Value   |+----+---------+|  1 | both ab ||  2 | only a  |+----+---------+2 rows in set (0.00 sec)mysql&gt; SELECT * from Table_B ORDER BY PK ASC;+----+---------+| PK | Value   |+----+---------+|  1 | both ab ||  3 | only b  |+----+---------+2 rows in set (0.00 sec)\n\n其中 PK 为 1 的记录在 Table_A 和 Table_B 中都有，2 为 Table_A 特有，3 为 Table_B 特有。\n常用的 JOININNER JOININNER JOIN 一般被译作内连接。内连接查询能将左表（表 A）和右表（表 B）中能关联起来的数据连接后返回。\n文氏图：\n示例查询：\nSELECT A.PK AS A_PK, B.PK AS B_PK,       A.Value AS A_Value, B.Value AS B_ValueFROM Table_A AINNER JOIN Table_B BON A.PK &#x3D; B.PK;\n\n查询结果：\n+------+------+---------+---------+| A_PK | B_PK | A_Value | B_Value |+------+------+---------+---------+|    1 |    1 | both ab | both ab |+------+------+---------+---------+1 row in set (0.00 sec)\n\n注：其中 A 为 Table_A 的别名，B 为 Table_B 的别名，下同。\nLEFT JOINLEFT JOIN 一般被译作左连接，也写作 LEFT OUTER JOIN。左连接查询会返回左表（表 A）中所有记录，不管右表（表 B）中有没有关联的数据。在右表中找到的关联数据列也会被一起返回。\n文氏图：\n示例查询：\nSELECT A.PK AS A_PK, B.PK AS B_PK,       A.Value AS A_Value, B.Value AS B_ValueFROM Table_A ALEFT JOIN Table_B BON A.PK &#x3D; B.PK;\n\n查询结果：\n+------+------+---------+---------+| A_PK | B_PK | A_Value | B_Value |+------+------+---------+---------+|    1 |    1 | both ab | both ba ||    2 | NULL | only a  | NULL    |+------+------+---------+---------+2 rows in set (0.00 sec)\n\nRIGHT JOINRIGHT JOIN 一般被译作右连接，也写作 RIGHT OUTER JOIN。右连接查询会返回右表（表 B）中所有记录，不管左表（表 A）中有没有关联的数据。在左表中找到的关联数据列也会被一起返回。\n文氏图：\n示例查询：\nSELECT A.PK AS A_PK, B.PK AS B_PK,       A.Value AS A_Value, B.Value AS B_ValueFROM Table_A ARIGHT JOIN Table_B BON A.PK &#x3D; B.PK;\n\n查询结果：\n+------+------+---------+---------+| A_PK | B_PK | A_Value | B_Value |+------+------+---------+---------+|    1 |    1 | both ab | both ba || NULL |    3 | NULL    | only b  |+------+------+---------+---------+2 rows in set (0.00 sec)\n\nFULL OUTER JOINFULL OUTER JOIN 一般被译作外连接、全连接，实际查询语句中可以写作 FULL OUTER JOIN 或 FULL JOIN。外连接查询能返回左右表里的所有记录，其中左右表里能关联起来的记录被连接后返回。\n文氏图：\n示例查询：\nSELECT A.PK AS A_PK, B.PK AS B_PK,       A.Value AS A_Value, B.Value AS B_ValueFROM Table_A AFULL OUTER JOIN Table_B BON A.PK &#x3D; B.PK;\n\n查询结果：\nERROR 1064 (42000): You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near &#39;FULL OUTER JOIN Table_B BON A.PK &#x3D; B.PK&#39; at line 4\n\n注：我当前示例使用的 MySQL 不支持 FULL OUTER JOIN。\n应当返回的结果（使用 UNION 模拟）：\nmysql&gt; SELECT *    -&gt; FROM Table_A    -&gt; LEFT JOIN Table_B    -&gt; ON Table_A.PK &#x3D; Table_B.PK    -&gt; UNION ALL    -&gt; SELECT *    -&gt; FROM Table_A    -&gt; RIGHT JOIN Table_B    -&gt; ON Table_A.PK &#x3D; Table_B.PK    -&gt; WHERE Table_A.PK IS NULL;+------+---------+------+---------+| PK   | Value   | PK   | Value   |+------+---------+------+---------+|    1 | both ab |    1 | both ba ||    2 | only a  | NULL | NULL    || NULL | NULL    |    3 | only b  |+------+---------+------+---------+3 rows in set (0.00 sec)\n\n小结以上四种，就是 SQL 里常见 JOIN 的种类和概念了，看一下它们的合影：\n有没有感觉少了些什么，学数学集合时完全不止这几种情况？确实如此，继续看。\n延伸用法LEFT JOIN EXCLUDING INNER JOIN返回左表有但右表没有关联数据的记录集。\n文氏图：\n示例查询：\nSELECT A.PK AS A_PK, B.PK AS B_PK,       A.Value AS A_Value, B.Value AS B_ValueFROM Table_A ALEFT JOIN Table_B BON A.PK &#x3D; B.PKWHERE B.PK IS NULL;\n\n查询结果：\n+------+------+---------+---------+| A_PK | B_PK | A_Value | B_Value |+------+------+---------+---------+|    2 | NULL | only a  | NULL    |+------+------+---------+---------+1 row in set (0.01 sec)\n\nRIGHT JOIN EXCLUDING INNER JOIN返回右表有但左表没有关联数据的记录集。\n文氏图：\n示例查询：\nSELECT A.PK AS A_PK, B.PK AS B_PK,       A.Value AS A_Value, B.Value AS B_ValueFROM Table_A ARIGHT JOIN Table_B BON A.PK &#x3D; B.PKWHERE A.PK IS NULL;\n\n查询结果：\n+------+------+---------+---------+| A_PK | B_PK | A_Value | B_Value |+------+------+---------+---------+| NULL |    3 | NULL    | only b  |+------+------+---------+---------+1 row in set (0.00 sec)\n\nFULL OUTER JOIN EXCLUDING INNER JOIN返回左表和右表里没有相互关联的记录集。\n文氏图：\n示例查询：\nSELECT A.PK AS A_PK, B.PK AS B_PK,       A.Value AS A_Value, B.Value AS B_ValueFROM Table_A AFULL OUTER JOIN Table_B BON A.PK &#x3D; B.PKWHERE A.PK IS NULLOR B.PK IS NULL;\n\n因为使用到了 FULL OUTER JOIN，MySQL 在执行该查询时再次报错。\nERROR 1064 (42000): You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near &#39;FULL OUTER JOIN Table_B BON A.PK &#x3D; B.PKWHERE A.PK IS NULLOR B.PK IS NULL&#39; at line 4\n\n应当返回的结果（用 UNION 模拟）：\nmysql&gt; SELECT *    -&gt; FROM Table_A    -&gt; LEFT JOIN Table_B    -&gt; ON Table_A.PK &#x3D; Table_B.PK    -&gt; WHERE Table_B.PK IS NULL    -&gt; UNION ALL    -&gt; SELECT *    -&gt; FROM Table_A    -&gt; RIGHT JOIN Table_B    -&gt; ON Table_A.PK &#x3D; Table_B.PK    -&gt; WHERE Table_A.PK IS NULL;+------+--------+------+--------+| PK   | Value  | PK   | Value  |+------+--------+------+--------+|    2 | only a | NULL | NULL   || NULL | NULL   |    3 | only b |+------+--------+------+--------+2 rows in set (0.00 sec)\n\n总结以上七种用法基本上可以覆盖各种 JOIN 查询了。七种用法的全家福：\n看着它们，我仿佛回到了当年学数学，求交集并集的时代……\n顺带张贴一下 C.L. Moffatt 带 SQL 语句的图片，配合学习，风味更佳：\n\n更新：更多的 JOIN除以上几种外，还有更多的 JOIN 用法，比如 CROSS JOIN（迪卡尔集）、SELF JOIN，可以参考 SQL JOINS Slide Presentation 学习。\nCROSS JOIN返回左表与右表之间符合条件的记录的迪卡尔集。\n图示：\n示例查询：\nSELECT A.PK AS A_PK, B.PK AS B_PK,       A.Value AS A_Value, B.Value AS B_ValueFROM Table_A ACROSS JOIN Table_B B;\n\n查询结果：\n+------+------+---------+---------+| A_PK | B_PK | A_Value | B_Value |+------+------+---------+---------+|    1 |    1 | both ab | both ba ||    2 |    1 | only a  | both ba ||    1 |    3 | both ab | only b  ||    2 |    3 | only a  | only b  |+------+------+---------+---------+4 rows in set (0.00 sec)\n\n上面讲过的几种 JOIN 查询的结果都可以用 CROSS JOIN 加条件模拟出来，比如 INNER JOIN 对应 CROSS JOIN ... WHERE A.PK = B.PK。\nSELF JOIN返回表与自己连接后符合条件的记录，一般用在表里有一个字段是用主键作为外键的情况。\n比如 Table_C 的结构与数据如下：\n+--------+----------+-------------+| EMP_ID | EMP_NAME | EMP_SUPV_ID |+--------+----------+-------------+|   1001 | Ma       |        NULL ||   1002 | Zhuang   |        1001 |+--------+----------+-------------+2 rows in set (0.00 sec)\n\nEMP_ID 字段表示员工 ID，EMP_NAME 字段表示员工姓名，EMP_SUPV_ID 表示主管 ID。\n示例查询：\n现在我们想查询所有有主管的员工及其对应的主管 ID 和姓名，就可以用 SELF JOIN 来实现。\nSELECT A.EMP_ID AS EMP_ID, A.EMP_NAME AS EMP_NAME,    B.EMP_ID AS EMP_SUPV_ID, B.EMP_NAME AS EMP_SUPV_NAMEFROM Table_C A, Table_C BWHERE A.EMP_SUPV_ID &#x3D; B.EMP_ID;\n\n查询结果：\n+--------+----------+-------------+---------------+| EMP_ID | EMP_NAME | EMP_SUPV_ID | EMP_SUPV_NAME |+--------+----------+-------------+---------------+|   1002 | Zhuang   |        1001 | Ma            |+--------+----------+-------------+---------------+1 row in set (0.00 sec)\n","tags":["MySQL","数据库"]},{"title":"MySQL安装部署","url":"/2019/10/22/MySQL%E5%AE%89%E8%A3%85%E9%83%A8%E7%BD%B2/","content":"Windows环境\n下载地址\n官方部署文档\n\nD:\\Develop\\mysql-8.0.18-winx64&gt;bin\\mysqld.exe --defaults-file=D:\\Develop\\mysql-8.0.18-winx64\\my.ini --initialize --console\n\n2019-10-24T08:47:21.549556Z 0 [System] [MY-013169] [Server] D:\\Develop\\mysql-8.0.18-winx64\\bin\\mysqld.exe (mysqld 8.0.18) initializing of server in progress asprocess 76122019-10-24T08:47:34.895556Z 5 [Note] [MY-010454] [Server] A temporary password is generated for root@localhost: 6#gL3pJ#qyh.\n\n# 安装服务D:\\Develop\\mysql-8.0.18-winx64&gt;bin\\mysqld.exe install\n\nnet start mysql\n\nLinux环境Yum安装\n 下载链接  参考文档\n\n下载mysql80-community-release-el7-3.noarch.rpm\n# 安装rpm源sudo rpm -Uvh mysql80-community-release-el7-3.noarch.rpm# 编辑，找到Enable to use MySQL 5.7，改为enabled=1，其他版本设置成enabled=0，# 同理这个方法可以按照别的版本vim /etc/yum.repos.d/mysql-community.repo# 检查只有MySQL 5.7启动yum repolist enabled | grep mysql# 安装MySQLsudo yum install mysql-community-server# 启动MySQL服务器sudo service mysqld start# MySQL服务器的状态sudo service mysqld status# 查看超级用户的密码sudo grep 'temporary password' /var/log/mysqld.log# 登录mysqlmysql -uroot -p# 修改密码ALTER USER 'root'@'localhost' IDENTIFIED BY 'MyNewPass4!';# 默认mysql的root用户不支持远程访问，开启访问权限GRANT ALL ON *.* TO root@'%' IDENTIFIED BY '123456' WITH GRANT OPTION;flush privileges;# 修改密码设置级别set global validate_password_policy=0;set global validate_password_length=1;# 开启3306端口firewall-cmd --add-port=3306/tcp# (a)数据库目录/var/lib/mysql/# (b)配置文件/usr/share /mysql（mysql.server命令及配置文件）/etc/my.cnf# (c)相关命令/usr/bin（mysqladmin mysqldump等命令）# (d)启动脚本/etc/rc.d/init.d/（启动脚本文件mysql的目录）\n\n二进制安装\n下载地址 参考文档\n\n下载文件： mysql-5.7.28-linux-glibc2.12-x86_64.tar\n# 查看包中内容tar -tvf mysql-5.7.28-linux-glibc2.12-x86_64.tar# mysql-5.7.28-linux-glibc2.12-x86_64.tar.gz# mysql-test-5.7.28-linux-glibc2.12-x86_64.tar.gz\n\n\n\n\nDirectory\nContents of Directory\n\n\n\nbin\nmysqld server, client and utility programs\n\n\ndocs\nMySQL manual in Info format\n\n\nman\nUnix manual pages\n\n\ninclude\nInclude (header) files\n\n\nlib\nLibraries\n\n\nshare\nError messages, dictionary, and SQL for database installation\n\n\nsupport-files\nMiscellaneous support files\n\n\n创建用户、用户组groupadd mysqluseradd -r -g mysql -s /bin/false mysql\n\n解压发行版文件cd /usr/local#tar zxvf /path/to/mysql-VERSION-OS.tar.gz 如果是.gz结尾tar xvf /path/to/mysql-VERSION-OS.tar\n\n创建软链接# 链接，这里建议使用全路径ln -s full-path-to-mysql-VERSION-OS mysql# 解压创建软链接，并且修改所属用户和组chown -R mysql:mysql mysql\n\n创建并授权cd mysqlmkdir mysql-fileschown mysql:mysql mysql-fileschmod 750 mysql-files\n\n创建配置文件cd /etctouch my.cnfchown root:root my.cnfchmod 644 my.cnf\n\n[mysqld]datadir=/usr/local/mysql/datasocket=/tmp/mysql.sockport=3306log-error=/usr/local/mysql/data/localhost.localdomain.erruser=mysqlsecure_file_priv=/usr/local/mysql/mysql-fileslocal_infile=OFF\n\n初始化数据目录cd /usr/local/mysqlmkdir datachmod 750 datachown mysql:mysql data\n\n初始化  参数： –initialize 会生成一个随机密码\nbin/mysqld --initialize --user=mysql\n\n显示下面则初始化成功：\n[root@bogon mysql]# bin/mysqld --initialize --user=mysql2019-10-23T07:41:12.611481Z 0 [Warning] TIMESTAMP with implicit DEFAULT value is deprecated. Please use --explicit_defaults_for_timestamp server option (see documentation for more details).2019-10-23T07:43:00.499738Z 0 [Warning] InnoDB: New log files created, LSN=457902019-10-23T07:43:00.819667Z 0 [Warning] InnoDB: Creating foreign key constraint system tables.2019-10-23T07:43:00.919776Z 0 [Warning] No existing UUID has been found, so we assume that this is the first time that this server has been started. Generating a new UUID: bd1531fb-f568-11e9-bc4b-46afd4d32e02.2019-10-23T07:43:00.958124Z 0 [Warning] Gtid table is not ready to be used. Table 'mysql.gtid_executed' cannot be opened.2019-10-23T07:43:02.482380Z 0 [Warning] CA certificate ca.pem is self signed.2019-10-23T07:43:02.643686Z 1 [Note] A temporary password is generated for root@localhost: Wsi!(otie8de\n\n命令添加到环境变量中vim /etc/profile# 添加PATH=$PATH:/usr/local/mysql/bin# 使生效source /etc/profile\n\n启动bin/mysqld_safe --user=mysql &amp;\n\nmkdir /var/log/mysql/touch /var/log/mysql/mysql.log# 如果日志没内容，授权chown -R mysql:mysql /var/log/mysql/mysql.log\n\n配置systemd\n参考文档 通用二进制包安装指南\n\n\n创建文件\n\n这两个路径任意一个都可以\ntouch /etc/systemd/system/mysqld.service# 建议创建到这个路径下面touch /usr/lib/systemd/system/mysqld.service\n\n这里注意pid的路径，写入下面内容\n[Unit]Description=MySQL ServerDocumentation=man:mysqld(8)Documentation=http://dev.mysql.com/doc/refman/en/using-systemd.htmlAfter=network.targetAfter=syslog.target[Install]WantedBy=multi-user.target[Service]User=mysqlGroup=mysql# Have mysqld write its state to the systemd notify socketType=forkingPIDFile=/var/run/mysql/mysqld.pid# Disable service start and stop timeout logic of systemd for mysqld service.TimeoutSec=0# Start main serviceExecStart=/usr/local/mysql/bin/mysqld --daemonize --pid-file=/var/run/mysql/mysqld.pid $MYSQLD_OPTS# Use this to switch malloc implementationEnvironmentFile=-/etc/sysconfig/mysql# Sets open_files_limitLimitNOFILE = 10000Restart=on-failureRestartPreventExitStatus=1# Set environment variable MYSQLD_PARENT_PID. This is required for restart.Environment=MYSQLD_PARENT_PID=1PrivateTmp=false\n\n\n重启\n\nsystemctl daemon-reload\n\n\n操作\n\nsystemctl &#123;start|stop|restart|status&#125; mysqld\n\n设置开机启动\n参考文档\n\ncp /usr/local/mysql/support-files/mysql.server /etc/init.d/mysqlchmod +x /etc/init.d/mysqlchkconfig --add mysql# 某些系统可能用下面命令chkconfig --level 345 mysql on\n\n相关问题\nERROR 2002 (HY000): Can&#39;t connect to local MySQL server through socket &#39;&#x2F;tmp&#x2F;mysql.sock&#39; (2)\n\n解决办法： ln -s /var/lib/mysql/mysql.sock mysql.sock\n\n重启无法创建PID\nmkdir /var/run/mysqlchown mysql:mysql -R /var/run/mysql\n\n\n相关命令# 关闭防火墙systemctl stop firewalld# 永久关闭防火墙systemctl disable firewalld# 加入开机启动systemctl enable redis.service# 查看开机是否启动成功systemctl is-enabled redis.service\n\n相关文档\n忘记初始密码怎么办\n\n创建文件mysql-init.txt，写入以下内容\nALTER USER &#39;root&#39;@&#39;localhost&#39; IDENTIFIED BY &#39;MyNewPass&#39;;\n执行\nmysqld --init-file&#x3D;C:\\\\mysql-init.txt\n\n\nMySQL同步\n\n","tags":["MySQL","数据库","部署文档"]},{"title":"Redis安装部署","url":"/2020/05/25/Redis%E5%AE%89%E8%A3%85%E9%83%A8%E7%BD%B2/","content":"\n相关文章：\nhttps://www.cnblogs.com/shook/p/12883742.html\nhttps://redis.io/documentation\n\nWindow\n下载地址\n\n启动\nredis-server.exe redis.windows.conf\n\nLinux\n测试环境：Linux version 3.10.0-1062.7.1.el7.x86_64 (mockbuild@kbuilder.bsys.centos.org) (gcc version 4.8.5 20150623 (Red Hat 4.8.5-39) (GCC) ) #1 SMP Mon Dec 2 17:33:29 UTC 2019\n下载地址\n\n准备环境yum install -y gccyum install -y gcc-c++yum install -y tcl\n\n下载安装\n注意：这里选择redis-5.0.8这个版本可以编译成功，如果编译高版本失败则可能需要升级gcc版本重新编译\n\nwget http://download.redis.io/releases/redis-5.0.8.tar.gztar xzf redis-5.0.8.tar.gzcd redis-5.0.8make\n\n编译成功make[2]: 离开目录“/opt/redis-5.0.8/deps”    CC adlist.o    CC quicklist.o    CC ae.o    CC anet.o    CC dict.o    CC server.o    CC sds.o    CC zmalloc.o    CC lzf_c.o    CC lzf_d.o    CC pqsort.o    CC zipmap.o    CC sha1.o    CC ziplist.o    CC release.o    CC networking.o    CC util.o    CC object.o    CC db.o    CC replication.o    CC rdb.o    CC t_string.o    CC t_list.o    CC t_set.o    CC t_zset.o    CC t_hash.o    CC config.o    CC aof.o    CC pubsub.o    CC multi.o    CC debug.o    CC sort.o    CC intset.o    CC syncio.o    CC cluster.o    CC crc16.o    CC endianconv.o    CC slowlog.o    CC scripting.o    CC bio.o    CC rio.o    CC rand.o    CC memtest.o    CC crc64.o    CC bitops.o    CC sentinel.o    CC notify.o    CC setproctitle.o    CC blocked.o    CC hyperloglog.o    CC latency.o    CC sparkline.o    CC redis-check-rdb.o    CC redis-check-aof.o    CC geo.o    CC lazyfree.o    CC module.o    CC evict.o    CC expire.o    CC geohash.o    CC geohash_helper.o    CC childinfo.o    CC defrag.o    CC siphash.o    CC rax.o    CC t_stream.o    CC listpack.o    CC localtime.o    CC lolwut.o    CC lolwut5.o    LINK redis-server    INSTALL redis-sentinel    CC redis-cli.o    LINK redis-cli    CC redis-benchmark.o    LINK redis-benchmark    INSTALL redis-check-rdb    INSTALL redis-check-aofHint: It's a good idea to run 'make test' ;)make[1]: 离开目录“/opt/redis-5.0.8/src”\n\n编译错误erver.c:5152:44: 错误：‘struct redisServer’没有名为‘tlsfd_count’的成员         if (server.ipfd_count &gt; 0 || server.tlsfd_count &gt; 0)                                            ^server.c:5154:19: 错误：‘struct redisServer’没有名为‘sofd’的成员         if (server.sofd &gt; 0)                   ^server.c:5155:94: 错误：‘struct redisServer’没有名为‘unixsocket’的成员             serverLog(LL_NOTICE,\"The server is now ready to accept connections at %s\", server.unixsocket);                                                                                              ^server.c:5156:19: 错误：‘struct redisServer’没有名为‘supervised_mode’的成员         if (server.supervised_mode == SUPERVISED_SYSTEMD) &#123;                   ^server.c:5157:24: 错误：‘struct redisServer’没有名为‘masterhost’的成员             if (!server.masterhost) &#123;                        ^server.c:5170:15: 错误：‘struct redisServer’没有名为‘maxmemory’的成员     if (server.maxmemory &gt; 0 &amp;&amp; server.maxmemory &lt; 1024*1024) &#123;               ^server.c:5170:39: 错误：‘struct redisServer’没有名为‘maxmemory’的成员     if (server.maxmemory &gt; 0 &amp;&amp; server.maxmemory &lt; 1024*1024) &#123;                                       ^server.c:5171:176: 错误：‘struct redisServer’没有名为‘maxmemory’的成员         serverLog(LL_WARNING,\"WARNING: You specified a maxmemory value that is less than 1MB (current value is %llu bytes). Are you sure this is what you really want?\", server.maxmemory);                                                                                                                                                                                ^server.c:5174:31: 错误：‘struct redisServer’没有名为‘server_cpulist’的成员     redisSetCpuAffinity(server.server_cpulist);                               ^server.c: 在函数‘hasActiveChildProcess’中:server.c:1476:1: 警告：在有返回值的函数中，控制流程到达函数尾 [-Wreturn-type] &#125; ^server.c: 在函数‘allPersistenceDisabled’中:server.c:1482:1: 警告：在有返回值的函数中，控制流程到达函数尾 [-Wreturn-type] &#125; ^server.c: 在函数‘writeCommandsDeniedByDiskError’中:server.c:3789:1: 警告：在有返回值的函数中，控制流程到达函数尾 [-Wreturn-type] &#125; ^server.c: 在函数‘iAmMaster’中:server.c:4966:1: 警告：在有返回值的函数中，控制流程到达函数尾 [-Wreturn-type] &#125; ^make[1]: *** [server.o] 错误 1make[1]: 离开目录“/opt/redis-6.0.3/src”make: *** [all] 错误 2\n\n升级gcc版本# 查看gcc版本gcc -v# 升级到9.1版本yum -y install centos-release-scl# 临时启用yum -y install devtoolset-9-gcc devtoolset-9-gcc-c++ devtoolset-9-binutilsscl enable devtoolset-9 bash# 如果要长期使用gcc 9.1的话：echo \"source /opt/rh/devtoolset-9/enable\" &gt;&gt;/etc/profile\n\n运行测试make test\n\n正常显示如下：\nExecution time of different units:  0 seconds - unit/printver  0 seconds - unit/type/incr  1 seconds - unit/auth  1 seconds - unit/keyspace  1 seconds - unit/protocol  1 seconds - unit/quit  3 seconds - unit/multi  4 seconds - unit/type/stream-cgroups  12 seconds - unit/type/hash  13 seconds - unit/other  15 seconds - unit/expire  15 seconds - unit/type/list  17 seconds - unit/type/string  19 seconds - unit/scan  20 seconds - unit/type/set  3 seconds - integration/rdb  3 seconds - integration/convert-zipmap-hash-on-load  1 seconds - integration/logging  7 seconds - integration/aof  1 seconds - unit/pubsub  26 seconds - unit/sort  3 seconds - unit/slowlog  29 seconds - unit/type/zset  1 seconds - unit/introspection  28 seconds - integration/block-repl  1 seconds - unit/limits  11 seconds - unit/scripting  7 seconds - unit/introspection-2  41 seconds - unit/type/list-2  4 seconds - unit/bitfield  33 seconds - integration/replication-2  25 seconds - integration/psync2-reg  13 seconds - unit/bitops  2 seconds - unit/lazyfree  55 seconds - unit/dump  32 seconds - integration/psync2  57 seconds - unit/type/stream  8 seconds - unit/wait  45 seconds - integration/replication-4  11 seconds - unit/pendingquerybuf  23 seconds - unit/geo  71 seconds - integration/replication-3  99 seconds - unit/aofrw  82 seconds - unit/maxmemory  71 seconds - unit/memefficiency  118 seconds - unit/type/list-3  107 seconds - integration/replication-psync  79 seconds - unit/hyperloglog  156 seconds - integration/replication  385 seconds - unit/obuf-limits\\o/ All tests passed without errors!\n\n启动src/redis-server [redis.conf]\n\n成功启动显示：\n26876:C 26 May 2020 09:56:57.357 # oO0OoO0OoO0Oo Redis is starting oO0OoO0OoO0Oo26876:C 26 May 2020 09:56:57.357 # Redis version=5.0.8, bits=64, commit=00000000, modified=0, pid=26876, just started26876:C 26 May 2020 09:56:57.357 # Warning: no config file specified, using the default config. In order to specify a config file use src/redis-server /path/to/redis.conf26876:M 26 May 2020 09:56:57.358 * Increased maximum number of open files to 10032 (it was originally set to 1024).                _._           _.-``__ ''-._      _.-``    `.  `_.  ''-._           Redis 5.0.8 (00000000/0) 64 bit  .-`` .-```.  ```\\/    _.,_ ''-._ (    '      ,       .-`  | `,    )     Running in standalone mode |`-._`-...-` __...-.``-._|'` _.-'|     Port: 6379 |    `-._   `._    /     _.-'    |     PID: 26876  `-._    `-._  `-./  _.-'    _.-' |`-._`-._    `-.__.-'    _.-'_.-'| |    `-._`-._        _.-'_.-'    |           http://redis.io  `-._    `-._`-.__.-'_.-'    _.-' |`-._`-._    `-.__.-'    _.-'_.-'| |    `-._`-._        _.-'_.-'    |  `-._    `-._`-.__.-'_.-'    _.-'      `-._    `-.__.-'    _.-'          `-._        _.-'              `-.__.-'26876:M 26 May 2020 09:56:57.362 # WARNING: The TCP backlog setting of 511 cannot be enforced because /proc/sys/net/core/somaxconn is set to the lower value of 128.26876:M 26 May 2020 09:56:57.362 # Server initialized26876:M 26 May 2020 09:56:57.362 # WARNING overcommit_memory is set to 0! Background save may fail under low memory condition. To fix this issue add 'vm.overcommit_memory = 1' to /etc/sysctl.conf and then reboot or run the command 'sysctl vm.overcommit_memory=1' for this to take effect.26876:M 26 May 2020 09:56:57.362 # WARNING you have Transparent Huge Pages (THP) support enabled in your kernel. This will create latency and memory usage issues with Redis. To fix this issue run the command 'echo never &gt; /sys/kernel/mm/transparent_hugepage/enabled' as root, and add it to your /etc/rc.local in order to retain the setting after a reboot. Redis must be restarted after THP is disabled.26876:M 26 May 2020 09:56:57.363 * Ready to accept connections\n\n后台启动vim redis.confdaemonize no# 改成daemonize yes\n\n启动：\n[root@zhang redis-5.0.8]# src/redis-server redis.conf29472:C 26 May 2020 10:01:41.246 # oO0OoO0OoO0Oo Redis is starting oO0OoO0OoO0Oo29472:C 26 May 2020 10:01:41.246 # Redis version=5.0.8, bits=64, commit=00000000, modified=0, pid=29472, just started29472:C 26 May 2020 10:01:41.246 # Configuration loaded\n\n停止：\nps axu|grep rediskill-9 29472\n\n创建服务vim /usr/lib/systemd/system/redis.service\n\n[Unit]Description=The redis-server Process ManagerAfter=syslog.target network.target[Service]Type=forkingPIDFile=/var/run/redis_6379.pidExecStart=/opt/redis-5.0.8/src/redis-server /opt/redis-5.0.8/redis.conf[Install]WantedBy=multi-user.target\n\nsystemctl enable redis.servicesystemctl start redis.service\n\nDocker待完善\n常见问题如何远程访问修改配置文件\nbind 127.0.0.1\n","tags":["Redis"]},{"title":"Spring源码详解","url":"/2020/05/25/Spring%E6%BA%90%E7%A0%81%E8%AF%A6%E8%A7%A3/","content":"Spring源码详解AOP\n相关文章：https://blog.csdn.net/wyl6019/article/details/80136000\n\nXML注册\n@Aspect注册\n\ncontextInitialized:103, ContextLoaderListener\ninitWebApplicationContext:291, ContextLoader\nconfigureAndRefreshWebApplicationContext:400, ContextLoader\nrefresh:549, AbstractApplicationContext\nfinishBeanFactoryInitialization:877, AbstractApplicationContext\npreInstantiateSingletons:830, DefaultListableBeanFactory\ngetBean:199, AbstractBeanFactory\ndoGetBean:318, AbstractBeanFactory\ngetSingleton:222, DefaultSingletonBeanRegistry\ngetObject:-1, 889007824\nlambda$doGetBean$0:320, AbstractBeanFactory\ncreateBean:515, AbstractAutowireCapableBeanFactory\ndoCreateBean:593, AbstractAutowireCapableBeanFactory\ninitializeBean:1766, AbstractAutowireCapableBeanFactory\napplyBeanPostProcessorsAfterInitialization:429, AbstractAutowireCapableBeanFactory\npostProcessAfterInitialization:296, AbstractAutoProxyCreator\nwrapIfNecessary:335, AbstractAutoProxyCreator\ncreateProxy:471, AbstractAutoProxyCreator\ncreateProxy:471, AbstractAutoProxyCreator\ngetProxy:160, CglibAopProxy\n\npublic Object getProxy(@Nullable ClassLoader classLoader) &#123;    if (logger.isTraceEnabled()) &#123;        logger.trace(\"Creating CGLIB proxy: \" + this.advised.getTargetSource());    &#125;    try &#123;        Class&lt;?&gt; rootClass = this.advised.getTargetClass();        Assert.state(rootClass != null, \"Target class must be available for creating a CGLIB proxy\");        Class&lt;?&gt; proxySuperClass = rootClass;        if (ClassUtils.isCglibProxyClass(rootClass)) &#123;            proxySuperClass = rootClass.getSuperclass();            Class&lt;?&gt;[] additionalInterfaces = rootClass.getInterfaces();            for (Class&lt;?&gt; additionalInterface : additionalInterfaces) &#123;                this.advised.addInterface(additionalInterface);            &#125;        &#125;        // Validate the class, writing log messages as necessary.        validateClassIfNecessary(proxySuperClass, classLoader);        // Configure CGLIB Enhancer...        Enhancer enhancer = createEnhancer();        if (classLoader != null) &#123;            enhancer.setClassLoader(classLoader);            if (classLoader instanceof SmartClassLoader &amp;&amp;                    ((SmartClassLoader) classLoader).isClassReloadable(proxySuperClass)) &#123;                enhancer.setUseCache(false);            &#125;        &#125;        enhancer.setSuperclass(proxySuperClass);        enhancer.setInterfaces(AopProxyUtils.completeProxiedInterfaces(this.advised));        enhancer.setNamingPolicy(SpringNamingPolicy.INSTANCE);        enhancer.setStrategy(new ClassLoaderAwareUndeclaredThrowableStrategy(classLoader));        // 获取Callback派生类，包含@After、@Before等        Callback[] callbacks = getCallbacks(rootClass);        Class&lt;?&gt;[] types = new Class&lt;?&gt;[callbacks.length];        for (int x = 0; x &lt; types.length; x++) &#123;            types[x] = callbacks[x].getClass();        &#125;        // fixedInterceptorMap only populated at this point, after getCallbacks call above        enhancer.setCallbackFilter(new ProxyCallbackFilter(                this.advised.getConfigurationOnlyCopy(), this.fixedInterceptorMap, this.fixedInterceptorOffset));        enhancer.setCallbackTypes(types);        // Generate the proxy class and create a proxy instance.        return createProxyClassAndInstance(enhancer, callbacks);    &#125;    catch (CodeGenerationException | IllegalArgumentException ex) &#123;        throw new AopConfigException(\"Could not generate CGLIB subclass of \" + this.advised.getTargetClass() +                \": Common causes of this problem include using a final class or a non-visible class\",                ex);    &#125;    catch (Throwable ex) &#123;        // TargetSource.getTarget() failed        throw new AopConfigException(\"Unexpected AOP exception\", ex);    &#125;&#125;\n\n// Create proxy if we have advice.Object[] specificInterceptors = getAdvicesAndAdvisorsForBean(bean.getClass(), beanName, null);if (specificInterceptors != DO_NOT_PROXY) &#123;    this.advisedBeans.put(cacheKey, Boolean.TRUE);    Object proxy = createProxy(            bean.getClass(), beanName, specificInterceptors, new SingletonTargetSource(bean));    this.proxyTypes.put(cacheKey, proxy.getClass());    return proxy;&#125;\n\n执行\nintercept:688, CglibAopProxy$DynamicAdvisedInterceptor\nproceed:162, ReflectiveMethodInvocation\n\npublic Object proceed() throws Throwable &#123;    //\tWe start with an index of -1 and increment early.    if (this.currentInterceptorIndex == this.interceptorsAndDynamicMethodMatchers.size() - 1) &#123;        return invokeJoinpoint();    &#125;    Object interceptorOrInterceptionAdvice =            this.interceptorsAndDynamicMethodMatchers.get(++this.currentInterceptorIndex);    if (interceptorOrInterceptionAdvice instanceof InterceptorAndDynamicMethodMatcher) &#123;        // Evaluate dynamic method matcher here: static part will already have        // been evaluated and found to match.        InterceptorAndDynamicMethodMatcher dm =                (InterceptorAndDynamicMethodMatcher) interceptorOrInterceptionAdvice;        Class&lt;?&gt; targetClass = (this.targetClass != null ? this.targetClass : this.method.getDeclaringClass());        if (dm.methodMatcher.matches(this.method, targetClass, this.arguments)) &#123;            return dm.interceptor.invoke(this);        &#125;        else &#123;            // Dynamic matching failed.            // Skip this interceptor and invoke the next in the chain.            return proceed();        &#125;    &#125;    else &#123;        // It's an interceptor, so we just invoke it: The pointcut will have        // been evaluated statically before this object was constructed.        // 调用机制相当于实现了一个chain，把this传给下一个Callback，注意获取的时候++this.currentInterceptorIndex        return ((MethodInterceptor) interceptorOrInterceptionAdvice).invoke(this);    &#125;&#125;\n\n处理请求注册\nrefresh:549, AbstractApplicationContext\nfinishBeanFactoryInitialization:877, AbstractApplicationContext\npreInstantiateSingletons:849, DefaultListableBeanFactory\ngetBean:199, AbstractBeanFactory\ndoGetBean:318, AbstractBeanFactory\ngetSingleton:222, DefaultSingletonBeanRegistry\ngetObject:-1, 911637678\nlambda$doGetBean$0:320, AbstractBeanFactory\ncreateBean:515, AbstractAutowireCapableBeanFactory\ndoCreateBean:593, AbstractAutowireCapableBeanFactory\ninitializeBean:1758, AbstractAutowireCapableBeanFactory\ninvokeInitMethods:1821, AbstractAutowireCapableBeanFactory\nafterPropertiesSet:164, RequestMappingHandlerMapping\nafterPropertiesSet:199, AbstractHandlerMethodMapping\ninitHandlerMethods:211, AbstractHandlerMethodMapping\n\n\ngetCandidateBeanNames()获取到需要初始化的bean,processCandidateBean(beanName)方法对这些bean进行过滤\n\nprotected void initHandlerMethods() &#123;    for (String beanName : getCandidateBeanNames()) &#123;        if (!beanName.startsWith(SCOPED_TARGET_NAME_PREFIX)) &#123;            processCandidateBean(beanName);        &#125;    &#125;    handlerMethodsInitialized(getHandlerMethods());&#125;\n\nprocessCandidateBean:250, AbstractHandlerMethodMapping\nisHandler(beanType)主要过滤条件,detectHandlerMethods(beanName);注册\n\nprotected void processCandidateBean(String beanName) &#123;    Class&lt;?&gt; beanType = null;    try &#123;        beanType = obtainApplicationContext().getType(beanName);    &#125;    catch (Throwable ex) &#123;        // An unresolvable bean type, probably from a lazy bean - let's ignore it.        if (logger.isTraceEnabled()) &#123;            logger.trace(\"Could not resolve type for bean '\" + beanName + \"'\", ex);        &#125;    &#125;    if (beanType != null &amp;&amp; isHandler(beanType)) &#123;        detectHandlerMethods(beanName);    &#125;&#125;\n\n符合@Controller或者@RequestMapping\n\nprotected boolean isHandler(Class&lt;?&gt; beanType) &#123;    return (AnnotatedElementUtils.hasAnnotation(beanType, Controller.class) ||            AnnotatedElementUtils.hasAnnotation(beanType, RequestMapping.class));&#125;\n\n\n\n请求\norg.springframework.web.servlet.DispatcherServlet\nservice:882, FrameworkServlet\nservice:742, HttpServlet\nservice:635, HttpServlet\n这个方法具体判断是什么请求类型\n\nprotected void service(HttpServletRequest req, HttpServletResponse resp)        throws ServletException, IOException&#123;    String method = req.getMethod();    if (method.equals(METHOD_GET)) &#123;        long lastModified = getLastModified(req);        if (lastModified == -1) &#123;            // servlet doesn't support if-modified-since, no reason            // to go through further expensive logic            doGet(req, resp);        &#125; else &#123;            long ifModifiedSince = req.getDateHeader(HEADER_IFMODSINCE);            if (ifModifiedSince &lt; lastModified) &#123;                // If the servlet mod time is later, call doGet()                // Round down to the nearest second for a proper compare                // A ifModifiedSince of -1 will always be less                maybeSetLastModified(resp, lastModified);                doGet(req, resp);            &#125; else &#123;                resp.setStatus(HttpServletResponse.SC_NOT_MODIFIED);            &#125;        &#125;    &#125; else if (method.equals(METHOD_HEAD)) &#123;        long lastModified = getLastModified(req);        maybeSetLastModified(resp, lastModified);        doHead(req, resp);    &#125; else if (method.equals(METHOD_POST)) &#123;        doPost(req, resp);    &#125; else if (method.equals(METHOD_PUT)) &#123;        doPut(req, resp);    &#125; else if (method.equals(METHOD_DELETE)) &#123;        doDelete(req, resp);    &#125; else if (method.equals(METHOD_OPTIONS)) &#123;        doOptions(req,resp);    &#125; else if (method.equals(METHOD_TRACE)) &#123;        doTrace(req,resp);    &#125; else &#123;        //        // Note that this means NO servlet supports whatever        // method was requested, anywhere on this server.        //        String errMsg = lStrings.getString(\"http.method_not_implemented\");        Object[] errArgs = new Object[1];        errArgs[0] = method;        errMsg = MessageFormat.format(errMsg, errArgs);        resp.sendError(HttpServletResponse.SC_NOT_IMPLEMENTED, errMsg);    &#125;&#125;\ndoGet:897, FrameworkServlet\nprocessRequest:1005, FrameworkServlet\ndoService:942, DispatcherServlet\ndoDispatch:1014, DispatcherServlet\ngetHandler:1231, DispatcherServlet\ngetHandler:401, AbstractHandlerMapping\ngetHandlerInternal:365, AbstractHandlerMethodMapping\nAbstractHandlerMethodMapping内部使用了读写锁\nlookupHandlerMethod(lookupPath, request); 从注册好的集合中查找返回HandlerMethod调用\nmappingRegistry.urlLookup这个map保存了url和对应的方法\n\nprotected HandlerMethod getHandlerInternal(HttpServletRequest request) throws Exception &#123;    String lookupPath = getUrlPathHelper().getLookupPathForRequest(request);    this.mappingRegistry.acquireReadLock();    try &#123;        HandlerMethod handlerMethod = lookupHandlerMethod(lookupPath, request);        return (handlerMethod != null ? handlerMethod.createWithResolvedBean() : null);    &#125;    finally &#123;        this.mappingRegistry.releaseReadLock();    &#125;&#125;\n\n\n\n事务\nSpring并不直接管理事务，而是提供了事务管理接口是PlatformTransactionManager，通过这个 接口，Spring 为各个平台如JDBC、Hibernate等都提供了对应的事务管理器，但是具体的实现就是各个平台自己的 事情了。\n\n\n\n\n平台\n实现类\n\n\n\nJDBC\nDataSourceTransactionManager\n\n\nJTA\nJtaTransactionManager\n\n\nHibernate\nHibernateTransactionManager\n\n\n注册执行","tags":["Java","Spring"]},{"title":"二叉树详细介绍","url":"/2020/02/04/%E4%BA%8C%E5%8F%89%E6%A0%91%E8%AF%A6%E7%BB%86%E4%BB%8B%E7%BB%8D/","content":"基本概念二叉树是一种树形结构，它的特点是每个结点至多只有两棵子树（即二叉树中不存在度大于2的结点），并且二叉树的子树有左右之分，其次序不能任意颠倒。\n度：结点拥有的子树数称为结点的度。\n终端结点：度为0的结点称为叶子或者终端结点。\n深度：树中结点的最大层次称为树的深度或高度。\n完全二叉树：可以对满二叉树的结点进行连续编号，约定编号从根结点起，自上而下，从左到右。深度为$k$的，有$n$个结点的二叉树，当且仅当其每一个结点都与深度为$k$的满二叉树编号从$1$至$n$一一对应时，称之为完全二叉树。\n性质\n在二叉树的第$i$层上至多有$2^{i-1}$个结点($i \\geq 1$)。\n深度为$k$的二叉树至多有$2^k-1$个结点($k \\geq 1$)。如果是$2^k-1$则为满二叉树。\n对于任何一颗二叉树$T$，如果其终端结点树为$n_0$，度为2的结点树为$n_2$，则$n_0 = n_2 +1$\n具有$n$个结点的完全二叉树，其深度k满足$ \\log_{2}n&lt; k \\leq \\log_2n+1$，$k$的值其实就是$\\log_2n+1$向下取整\n如果对一颗有$n$个结点的完全二叉树的结点按层序编号，则对任一结点$i$($1\\leq i \\leq n$)，有\n如果$i = 1$，则结点是二叉树的根，无双亲；如果$i &gt; 1$，则其双亲结点$i/2$取整。\n如果$2i &gt; n$，则结点$i$无左孩子（结点$i$为叶子结点）；否则其左孩子是结点$2i$。\n如果$2i+1 &gt; n$，则结点无右孩子；否则其右孩子结点$2i+1$\n\n\n\n存储结构\n顺序存储结构\n链式存储结构\n\n遍历二叉树\n学习网站： https://www.cs.usfca.edu/~galles/visualization/Algorithms.html\n\n假如以L、D、R分别表示遍历左子树、访问根结点、遍历右子树，则可有DLR、LDR、LRD、DRL、RDL、RLD这6种遍历方式。若限定先左后右，则只有三种情况，分别称之为先（根）序遍历、中（根）序遍历、后（根）序遍历。基于二叉树的递归定义，可得下述遍历二叉树的递归算法定义。\n\n先序遍历二叉树的操作定义为：\n若二叉树为空，则空操作；否则\n\n\n\n访问根结点；\n先序遍历左子树；\n先序遍历右子树。\n\n\n中序遍历二叉树的操作定义为：\n若二叉树为空，则空操作；否则\n\n\n\n中序遍历左子树；\n访问根结点；\n中序遍历右子树。\n\n\n后序遍历二叉树的操作定义为：\n若二叉树为空，则空操作；否则\n\n\n\n后序遍历左子树；\n后序遍历右子树；\n访问根结点。\n\n定义二叉树public class TreeNode &#123;    int val;    TreeNode left;    TreeNode right;    TreeNode(int x) &#123;        val = x;    &#125;    public static TreeNode create(Integer[] nums, int index) &#123;        TreeNode top = null;        if (index &lt; nums.length) &#123;            Integer value = nums[index];            if (value == null) &#123;                return null;            &#125;            top = new TreeNode(value);            top.left = create(nums, index * 2 + 1);            top.right = create(nums, index * 2 + 2);            return top;        &#125;        return top;    &#125;&#125;\n\n深度优先搜索（DFS）/**  * 前序遍历 中--左--右(DLR)  * @param root  */public static void preorderTraversal(TreeNode root) &#123;    if (root != null) &#123;        System.out.println(root.getData() + \"-&gt;\");        preorderTraversal(root.getLeftNode());        preorderTraversal(root.getRightNode());    &#125;&#125;/**  * 中序遍历 左--中--右(LDR)  * @param root  */public static void inorderTraversal(TreeNode root) &#123;    if (root != null) &#123;        inorderTraversal(root.getLeftNode());        System.out.println(root.getData() + \"-&gt;\");        inorderTraversal(root.getRightNode());    &#125;&#125;/**  * 后序遍历 左--右--中(LRD)  * @param root  */public static void postorderTraversal(TreeNode root) &#123;    if (root != null) &#123;        postorderTraversal(root.getLeftNode());        postorderTraversal(root.getRightNode());        System.out.println(root.getData() + \"-&gt;\");    &#125;&#125;\n\n宽度优先搜索（BFS）\n相关：https://leetcode-cn.com/problems/binary-tree-level-order-traversal/solution/er-cha-shu-de-ceng-ci-bian-li-by-leetcode/\n\nclass Solution &#123;    List&lt;List&lt;Integer&gt;&gt; levels = new ArrayList&lt;List&lt;Integer&gt;&gt;();    public void helper(TreeNode node, int level) &#123;        // start the current level        if (levels.size() == level)            levels.add(new ArrayList&lt;Integer&gt;());        // fulfil the current level        levels.get(level).add(node.val);        // process child nodes for the next level        if (node.left != null)            helper(node.left, level + 1);        if (node.right != null)            helper(node.right, level + 1);    &#125;    public List&lt;List&lt;Integer&gt;&gt; levelOrder(TreeNode root) &#123;        if (root == null) return levels;        helper(root, 0);        return levels;    &#125;&#125;\n\nclass Solution &#123;    public List&lt;List&lt;Integer&gt;&gt; levelOrder(TreeNode root) &#123;        List&lt;List&lt;Integer&gt;&gt; levels = new ArrayList&lt;List&lt;Integer&gt;&gt;();        if (root == null) return levels;        Queue&lt;TreeNode&gt; queue = new LinkedList&lt;TreeNode&gt;();        queue.add(root);        int level = 0;        while ( !queue.isEmpty() ) &#123;            // start the current level            levels.add(new ArrayList&lt;Integer&gt;());            // number of elements in the current level            int level_length = queue.size();            for(int i = 0; i &lt; level_length; ++i) &#123;                TreeNode node = queue.remove();                // fulfill the current level                levels.get(level).add(node.val);                // add child nodes of the current level                // in the queue for the next level                if (node.left != null) queue.add(node.left);                if (node.right != null) queue.add(node.right);            &#125;            // go to next level            level++;        &#125;        return levels;    &#125;&#125;\n\n遍历图解\n\n旋转什么是旋转\n\n\n左旋：是以节点的”右分支”为轴，进行逆时针旋转。我们将左旋操作定义为 left_rotate.\n右旋：是以节点的“左分支”为轴，进行顺时针旋转。我们将右旋操作定义为 right_rotate.\n\n为什么要旋转在解释这个道理之前，我们先看看执行旋转后，二叉树中节点的深度有什么变化。在上图中，二叉树执行左旋后，a 分支所有节点的深度比以前多 1，b 分支保持不变，c 分支所有节点比以前少 1.\n这就意味着，通过合适的左旋和右旋操作，我们可以调整二叉树的深度。另一方面，通过合适的左旋和右旋，我们可以把二叉树变换成任意的形状！\n\n\n如上图，如何把二叉树通过若干次左旋和右旋操作变换成链，答案：\nleft_rotate(4);right_rotate(10);right_rotate(8);right_rotate(5);right_rotate(4);right_rotate(2);\n\n旋转算法\n定义二叉树结构\n\npublic class TreeNode &#123;    int val;    TreeNode left;    TreeNode right;    TreeNode parent;&#125;\n\n\n旋转\n\npackage example;public class TreeUtil &#123;    public static TreeNode leftRotate(TreeNode node) &#123;        TreeNode root = node.parent;        TreeNode x = node;        TreeNode y = node.right;        TreeNode b = node.right.left;        if (root.left == node) &#123;            root.left = y;        &#125; else &#123;            root.right = y;        &#125;        y.parent = root;        x.right = b;        b.parent = x;        y.left = x;        x.parent = y;        return y;    &#125;    public static TreeNode rightRotate(TreeNode node) &#123;        TreeNode root = node.parent;        TreeNode y = node;        TreeNode x = node.left;        TreeNode b = node.left.right;        if (root.left == node) &#123;            root.left = x;        &#125; else &#123;            root.right = x;        &#125;        x.parent = root;        y.left = b;        b.parent = y;        x.right = y;        y.parent = x;        return x;    &#125;    public static void main(String[] args) &#123;        TreeNode xx = new TreeNode(\"xx\");        TreeNode x = new TreeNode(\"x\");        TreeNode y = new TreeNode(\"y\");        TreeNode a = new TreeNode(\"a\");        TreeNode b = new TreeNode(\"b\");        TreeNode c = new TreeNode(\"c\");        xx.left = x;        x.parent = xx;        x.left = a;        a.parent = x;        x.right = y;        y.parent = x;        y.left = b;        b.parent = y;        y.right = c;        c.parent = y;        x = TreeUtil.leftRotate(x);        x = TreeUtil.rightRotate(x);        System.out.println(\"end\");    &#125;&#125;\n","tags":["算法相关"]},{"title":"二进制基础","url":"/2019/11/14/%E4%BA%8C%E8%BF%9B%E5%88%B6%E5%9F%BA%E7%A1%80/","content":"一. 机器数和真值在学习原码, 反码和补码之前, 需要先了解机器数和真值的概念.\n1、机器数一个数在计算机中的二进制表示形式,  叫做这个数的机器数。机器数是带符号的，在计算机用一个数的最高位存放符号, 正数为0, 负数为1.\n比如，十进制中的数 +3 ，计算机字长为8位，转换成二进制就是00000011。如果是 -3 ，就是 10000011 。\n那么，这里的 00000011 和 10000011 就是机器数。\n2、真值\n因为第一位是符号位，所以机器数的形式值就不等于真正的数值。例如上面的有符号数 10000011，其最高位1代表负，其真正数值是 -3 而不是形式值131（10000011转换成十进制等于131）。所以，为区别起见，将带符号位的机器数对应的真正数值称为机器数的真值。\n\n例：0000 0001的真值 = +000 0001 = +1，1000 0001的真值 = –000 0001 = –1\n二. 原码, 反码, 补码的基础概念和计算方法在探求为何机器要使用补码之前, 让我们先了解原码, 反码和补码的概念.对于一个数, 计算机要使用一定的编码方式进行存储. 原码, 反码, 补码是机器存储一个具体数字的编码方式.\n1. 原码原码就是符号位加上真值的绝对值, 即用第一位表示符号, 其余位表示值. 比如如果是8位二进制:\n\n[+1]原 = 0000 0001\n[-1]原 = 1000 0001\n\n第一位是符号位. 因为第一位是符号位, 所以8位二进制数的取值范围就是:\n\n[1111 1111 , 0111 1111]\n\n即\n\n[-127 , 127]\n\n原码是人脑最容易理解和计算的表示方式.\n2. 反码反码的表示方法是:\n正数的反码是其本身\n负数的反码是在其原码的基础上, 符号位不变，其余各个位取反.\n\n[+1] = [00000001]原 = [00000001]反\n[-1] = [10000001]原 = [11111110]反\n\n可见如果一个反码表示的是负数, 人脑无法直观的看出来它的数值. 通常要将其转换成原码再计算.\n3. 补码补码的表示方法是:\n正数的补码就是其本身\n负数的补码是在其原码的基础上, 符号位不变, 其余各位取反, 最后+1. (即在反码的基础上+1)\n\n[+1] = [00000001]原 = [00000001]反 = [00000001]补\n[-1] = [10000001]原 = [11111110]反 = [11111111]补\n\n对于负数, 补码表示方式也是人脑无法直观看出其数值的. 通常也需要转换成原码在计算其数值.\n4. 理解一个字节8位* 譬如一个10进制数 27* 转成二进制 00011011-27 的二进制* 先计算原码： 00011011* 反码：      11100100* 补码：      11100101\n\n三. 为何要使用原码, 反码和补码在开始深入学习前, 我的学习建议是先”死记硬背”上面的原码, 反码和补码的表示方式以及计算方法.\n现在我们知道了计算机可以有三种编码方式表示一个数. 对于正数因为三种编码方式的结果都相同:\n\n[+1] = [00000001]原 = [00000001]反 = [00000001]补\n\n所以不需要过多解释. 但是对于负数:\n\n[-1] = [10000001]原 = [11111110]反 = [11111111]补\n\n可见原码, 反码和补码是完全不同的. 既然原码才是被人脑直接识别并用于计算表示方式, 为何还会有反码和补码呢?\n首先, 因为人脑可以知道第一位是符号位, 在计算的时候我们会根据符号位, 选择对真值区域的加减. (真值的概念在本文最开头). 但是对于计算机, 加减乘数已经是最基础的运算, 要设计的尽量简单. 计算机辨别”符号位”显然会让计算机的基础电路设计变得十分复杂! 于是人们想出了将符号位也参与运算的方法. 我们知道, 根据运算法则减去一个正数等于加上一个负数, 即: 1-1 = 1 + (-1) = 0 , 所以机器可以只有加法而没有减法, 这样计算机运算的设计就更简单了.\n于是人们开始探索 将符号位参与运算, 并且只保留加法的方法. 首先来看原码:\n计算十进制的表达式: 1-1=0\n\n1 - 1 = 1 + (-1) = [00000001]原 + [10000001]原 = [10000010]原 = -2\n\n如果用原码表示, 让符号位也参与计算, 显然对于减法来说, 结果是不正确的.这也就是为何计算机内部不使用原码表示一个数.\n为了解决原码做减法的问题, 出现了反码:\n计算十进制的表达式: 1-1=0\n\n1 - 1 = 1 + (-1) = [0000 0001]原 + [1000 0001]原= [0000 0001]反 + [1111 1110]反 = [1111 1111]反 = [1000 0000]原 = -0\n\n发现用反码计算减法, 结果的真值部分是正确的. 而唯一的问题其实就出现在”0”这个特殊的数值上. 虽然人们理解上+0和-0是一样的, 但是0带符号是没有任何意义的. 而且会有[0000 0000]原和[1000 0000]原两个编码表示0.\n于是补码的出现, 解决了0的符号以及两个编码的问题:\n\n1-1 = 1 + (-1) = [0000 0001]原 + [1000 0001]原 = [0000 0001]补 + [1111 1111]补 = [0000 0000]补=[0000 0000]原\n\n这样0用[0000 0000]表示, 而以前出现问题的-0则不存在了.而且可以用[1000 0000]表示-128:\n\n(-1) + (-127) = [1000 0001]原 + [1111 1111]原 = [1111 1111]补 + [1000 0001]补 = [1000 0000]补\n\n-1-127的结果应该是-128, 在用补码运算的结果中, [1000 0000]补 就是-128. 但是注意因为实际上是使用以前的-0的补码来表示-128, 所以-128并没有原码和反码表示.(对-128的补码表示[1000 0000]补算出来的原码是[0000 0000]原, 这是不正确的)\n使用补码, 不仅仅修复了0的符号以及存在两个编码的问题, 而且还能够多表示一个最低数. 这就是为什么8位二进制, 使用原码或反码表示的范围为[-127, +127], 而使用补码表示的范围为[-128, 127].\n因为机器使用补码, 所以对于编程中常用到的32位int类型, 可以表示范围是: [-231, 231-1] 因为第一位表示的是符号位.而使用补码表示时又可以多保存一个最小值.\n四. 原码, 反码, 补码 再深入计算机巧妙地把符号位参与运算, 并且将减法变成了加法, 背后蕴含了怎样的数学原理呢?\n将钟表想象成是一个1位的12进制数. 如果当前时间是6点, 我希望将时间设置成4点, 需要怎么做呢?我们可以:\n\n\n往回拨2个小时: 6 - 2 = 4\n\n往前拨10个小时: (6 + 10) mod 12 = 4\n\n往前拨10+12=22个小时: (6+22) mod 12 =4\n\n\n\n2,3方法中的mod是指取模操作, 16 mod 12 =4 即用16除以12后的余数是4.\n所以钟表往回拨(减法)的结果可以用往前拨(加法)替代!\n现在的焦点就落在了如何用一个正数, 来替代一个负数. 上面的例子我们能感觉出来一些端倪, 发现一些规律. 但是数学是严谨的. 不能靠感觉.\n首先介绍一个数学中相关的概念: 同余\n同余的概念两个整数a，b，若它们除以整数m所得的余数相等，则称a，b对于模m同余\n记作 a ≡ b (mod m)\n读作 a 与 b 关于模 m 同余。\n举例说明:\n\n4 mod 12 = 4\n16 mod 12 = 4\n28 mod 12 = 4\n\n所以4, 16, 28关于模 12 同余.\n负数取模正数进行mod运算是很简单的. 但是负数呢?\n下面是关于mod运算的数学定义:\n\n上面是截图, “取下界”符号找不到如何输入(word中粘贴过来后乱码). 下面是使用”L”和”J”替换上图的”取下界”符号:\n\nx mod y = x - y L x / y J\n\n上面公式的意思是:\nx mod y等于 x 减去 y 乘上 x与y的商的下界.\n以 -3 mod 2 举例:\n\n-3 mod 2\n= -3 - 2xL -3/2 J\n= -3 - 2xL-1.5J\n= -3 - 2x(-2)\n= -3 + 4 = 1\n\n所以:\n\n(-2) mod 12 = 12-2=10\n(-4) mod 12 = 12-4 = 8\n(-5) mod 12 = 12 - 5 = 7\n\n开始证明再回到时钟的问题上:\n\n回拨2小时 = 前拨10小时\n回拨4小时 = 前拨8小时\n回拨5小时= 前拨7小时\n\n注意, 这里发现的规律!\n结合上面学到的同余的概念.实际上:\n\n(-2) mod 12 = 10\n10 mod 12 = 10\n\n-2与10是同余的.\n\n(-4) mod 12 = 8\n8 mod 12 = 8\n\n-4与8是同余的.\n距离成功越来越近了. 要实现用正数替代负数, 只需要运用同余数的两个定理:\n反身性:\n\na ≡ a (mod m)\n\n这个定理是很显而易见的.\n线性运算定理:\n\n如果a ≡ b (mod m)，c ≡ d (mod m) 那么:\n(1)a ± c ≡ b ± d (mod m)\n(2)a * c ≡ b * d (mod m)\n\n如果想看这个定理的证明, 请看:http://baike.baidu.com/view/79282.htm\n所以:\n\n7 ≡ 7 (mod 12)\n(-2) ≡ 10 (mod 12)\n7 -2 ≡ 7 + 10 (mod 12)\n\n现在我们为一个负数, 找到了它的正数同余数. 但是并不是7-2 = 7+10, 而是 7 -2 ≡ 7 + 10 (mod 12) , 即计算结果的余数相等.\n接下来回到二进制的问题上, 看一下: 2-1=1的问题.\n\n2-1=2+(-1) = [0000 0010]原 + [1000 0001]原= [0000 0010]反 + [1111 1110]反\n\n先到这一步, -1的反码表示是1111 1110. 如果这里将[1111 1110]认为是原码, 则[1111 1110]原 = -126, 这里将符号位除去, 即认为是126.\n发现有如下规律:\n\n(-1) mod 127 = 126\n126 mod 127 = 126\n\n即:\n\n(-1) ≡ 126 (mod 127)\n2-1 ≡ 2+126 (mod 127)\n\n2-1 与 2+126的余数结果是相同的! 而这个余数, 正式我们的期望的计算结果: 2-1=1\n所以说一个数的反码, 实际上是这个数对于一个膜的同余数. 而这个膜并不是我们的二进制, 而是所能表示的最大值! 这就和钟表一样, 转了一圈后总能找到在可表示范围内的一个正确的数值!\n而2+126很显然相当于钟表转过了一轮, 而因为符号位是参与计算的, 正好和溢出的最高位形成正确的运算结果.\n既然反码可以将减法变成加法, 那么现在计算机使用的补码呢? 为什么在反码的基础上加1, 还能得到正确的结果?\n\n2-1=2+(-1) = [0000 0010]原 + [1000 0001]原 = [0000 0010]补 + [1111 1111]补\n\n如果把[1111 1111]当成原码, 去除符号位, 则:\n\n[0111 1111]原 = 127\n\n其实, 在反码的基础上+1, 只是相当于增加了膜的值:\n\n(-1) mod 128 = 127\n127 mod 128 = 127\n2-1 ≡ 2+127 (mod 128)\n\n此时, 表盘相当于每128个刻度转一轮. 所以用补码表示的运算结果最小值和最大值应该是[-128, 128].\n但是由于0的特殊情况, 没有办法表示128, 所以补码的取值范围是[-128, 127]\n"},{"title":"数据结构与算法具体实现","url":"/2020/06/03/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E4%B8%8E%E7%AE%97%E6%B3%95/","content":"\n\n\n\nC\nC++\nJava\n\n\n\n线性结构\n1. 数组、单链表和双链表2. Linux内核中双向链表的经典实现\n数组、单链表和双链表\n数组、单链表和双链表\n\n\n\n栈\n栈\n栈\n\n\n\n队列\n队列\n队列\n\n\n树形结构\n二叉查找树\n二叉查找树\n二叉查找树 \n\n\n\nAVL树\nAVL树\nAVL树\n\n\n\n1. 红黑树(一)之原理和算法详细介绍2. 红黑树(二)之C语言的实现3. 红黑树(三)之Linux内核中红黑树的经典实现4. 红黑树(六)之 参考资料\n1. 红黑树(一)之原理和算法详细介绍2. 红黑树(四)之C++的实现 3. 红黑树(六)之参考资料\n1. 红黑树(一)之原理和算法详细介绍2. 红黑树(五)之Java的实现3. 红黑树(六)之参考资料\n\n\n\n哈夫曼树\n哈夫曼树\n哈夫曼树\n\n\n堆\n二叉堆\n二叉堆\n二叉堆\n\n\n\n左倾堆\n左倾堆\n左倾堆\n\n\n\n斜堆\n斜堆\n斜堆\n\n\n\n二项堆\n二项堆\n二项堆\n\n\n\n斐波那契堆\n斐波那契堆\n斐波那契堆\n\n\n图\n图的理论基础\n图的理论基础\n图的理论基础\n\n\n\n1. 邻接矩阵无向图2. 邻接表无向图3. 邻接矩阵有向图4. 邻接表有向图\n1. 邻接矩阵无向图2. 邻接表无向图3. 邻接矩阵有向图4. 邻接表有向图\n1. 邻接矩阵无向图2. 邻接表无向图3. 邻接矩阵有向图4. 邻接表有向图\n\n\n\n深度优先搜索和广度优先搜索\n深度优先搜索和广度优先搜索\n深度优先搜索和广度优先搜索\n\n\n\n拓扑排序\n拓扑排序\n拓扑排序\n\n\n\nKruskal算法\nKruskal算法\nKruskal算法\n\n\n\nPrim算法\nPrim算法\nPrim算法\n\n\n\nDijkstra算法\n\n\n\n\n排序算法\n冒泡排序\n冒泡排序\n冒泡排序\n\n\n\n快速排序\n快速排序\n快速排序\n\n\n\n直接插入排序\n直接插入排序\n直接插入排序\n\n\n\n希尔排序\n希尔排序\n希尔排序\n\n\n\n选择排序\n选择排序\n选择排序\n\n\n\n堆排序\n堆排序\n堆排序\n\n\n\n归并排序\n归并排序\n归并排序\n\n\n\n桶排序\n桶排序\n桶排序\n\n\n\n基数排序\n基数排序\n基数排序\n\n\n"},{"title":"零拷贝","url":"/2020/05/19/%E9%9B%B6%E6%8B%B7%E8%B4%9D/","content":"引言传统的Linux操作系统的标准I/O接口是基于数据拷贝操作的，即I/O操作会导致数据在操作系统内核地址空间的缓冲区和应用程序地址空间定义的缓冲区之间进行传输。这样做最大的好处是可以减少磁盘I/O的操作，因为如果所请求的数据已经存放在操作系统的高速缓冲存储器中，那么就不需要再进行实际的物理磁盘I/O操作。但是数据传输过程中的数据拷贝操作却导致了极大的CPU开销，限制了操作系统有效进行数据传输操作的能力。\n零拷贝（zero-copy）这种技术可以有效地改善数据传输的性能，在内核驱动程序（比如网络堆栈或者磁盘存储驱动程序）处理I/O数据的时候，零拷贝技术可以在某种程度上减少甚至完全避免不必要CPU数据拷贝操作。现代的CPU和存储体系结构提供了很多特征可以有效地实现零拷贝技术，但是因为存储体系结构非常复杂，而且网络协议栈有时需要对数据进行必要的处理，所以零拷贝技术有可能会产生很多负面的影响，甚至会导致零拷贝技术自身的优点完全丧失。\n为什么需要零拷贝技术如今，很多网络服务器都是基于客户端-服务器这一模型的。在这种模型中，客户端向服务器端请求数据或者服务；服务器端则需要响应客户端发出的请求，并为客户端提供它所需要的数据。随着网络服务的逐渐普及，video这类应用程序发展迅速。当今的计算机系统已经具备足够的能力去处理video这类应用程序对客户端所造成的重负荷，但是对于服务器端来说，它应付由video这类应用程序引起的网络通信量就显得捉襟见肘了。而且，客户端的数量增长迅速，那么服务器端就更容易成为性能瓶颈。而对于负荷很重的服务器来说，操作系统通常都是引起性能瓶颈的罪魁祸首。举个例子来说，当数据“写”操作或者数据“发送”操作的系统调用发出时，操作系统通常都会将数据从应用程序地址空间的缓冲区拷贝到操作系统内核的缓冲区中去。操作系统这样做的好处是接口简单，但是却在很大程度上损失了系统性能，因为这种数据拷贝操作不单需要占用CPU时间片，同时也需要占用额外的内存带宽。\n一般来说，客户端通过网络接口卡向服务器端发送请求，操作系统将这些客户端的请求传递给服务器端应用程序，服务器端应用程序会处理这些请求，请求处理完成以后，操作系统还需要将处理得到的结果通过网络适配器传递回去。\n下边这一小节会跟读者简单介绍一下传统的服务器是如何进行数据传输的，以及这种数据传输的处理过程存在哪些问题有可能会造成服务器的性能损失。\nLinux中传统服务器进行数据传输的流程Linux中传统的I/O操作是一种缓冲I/O，I/O过程中产生的数据传输通常需要在缓冲区中进行多次的拷贝操作。一般来说，在传输数据的时候，用户应用程序需要分配一块大小合适的缓冲区用来存放需要传输的数据。应用程序从文件中读取一块数据，然后把这块数据通过网络发送到接收端去。用户应用程序只是需要调用两个系统调用read()和write()就可以完成这个数据传输操作，应用程序并不知晓在这个数据传输的过程中操作系统所做的数据拷贝操作。对于Linux操作系统来说，基于数据排序或者校验等各方面因素的考虑，操作系统内核会在处理数据传输的过程中进行多次拷贝操作。在某些情况下，这些数据拷贝操作会极大地降低数据传输的性能。\n当应用程序需要访问某块数据的时候，操作系统内核会先检查这块数据是不是因为前一次对相同文件的访问而已经被存放在操作系统内核地址空间的缓冲区内，如果在内核缓冲区中找不到这块数据，Linux操作系统内核会先将这块数据从磁盘读出来放到操作系统内核的缓冲区里去。如果这个数据读取操作是由DMA完成的，那么在DMA进行数据读取的这一过程中，CPU只是需要进行缓冲区管理，以及创建和处理DMA，除此之外，CPU不需要再做更多的事情，DMA执行完数据读取操作之后，会通知操作系统做进一步的处理。Linux操作系统会根据read()系统调用指定的应用程序地址空间的地址，把这块数据存放到请求这块数据的应用程序的地址空间中去，在接下来的处理过程中，操作系统需要将数据再一次从用户应用程序地址空间的缓冲区拷贝到与网络堆栈相关的内核缓冲区中去，这个过程也是需要占用CPU的。数据拷贝操作结束以后，数据会被打包，然后发送到网络接口卡上去。在数据传输的过程中，应用程序可以先返回进而执行其他的操作。之后，在调用write()系统调用的时候，用户应用程序缓冲区中的数据内容可以被安全的丢弃或者更改，因为操作系统已经在内核缓冲区中保留了一份数据拷贝，当数据被成功传送到硬件上之后，这份数据拷贝就可以被丢弃。\n从上面的描述可以看出，在这种传统的数据传输过程中，数据至少发生了四次拷贝操作，即便是使用了DMA来进行与硬件的通讯，CPU仍然需要访问数据两次。在read()读数据的过程中，数据并不是直接来自于硬盘，而是必须先经过操作系统的文件系统层。在write()写数据的过程中，为了和要传输的数据包的大小相吻合，数据必须要先被分割成块，而且还要预先考虑包头，并且要进行数据校验和操作。\n\n图1.传统使用read和write系统调用的数据传输\n\n\n零拷贝（zero-copy）技术概述什么是零拷贝？简单一点来说，零拷贝就是一种避免CPU将数据从一块存储拷贝到另外一块存储的技术。针对操作系统中的设备驱动程序、文件系统以及网络协议堆栈而出现的各种零拷贝技术极大地提升了特定应用程序的性能，并且使得这些应用程序可以更加有效地利用系统资源。这种性能的提升就是通过在数据拷贝进行的同时，允许CPU执行其他的任务来实现的。零拷贝技术可以减少数据拷贝和共享总线操作的次数，消除传输数据在存储器之间不必要的中间拷贝次数，从而有效地提高数据传输效率。而且，零拷贝技术减少了用户应用程序地址空间和操作系统内核地址空间之间因为上下文切换而带来的开销。进行大量的数据拷贝操作其实是一件简单的任务，从操作系统的角度来说，如果CPU一直被占用着去执行这项简单的任务，那么这将会是很浪费资源的；如果有其他比较简单的系统部件可以代劳这件事情，从而使得CPU解脱出来可以做别的事情，那么系统资源的利用则会更加有效。综上所述，零拷贝技术的目标可以概括如下：\n避免数据拷贝\n\n避免操作系统内核缓冲区之间进行数据拷贝操作。\n避免操作系统内核和用户应用程序地址空间这两者之间进行数据拷贝操作。\n用户应用程序可以避开操作系统直接访问硬件存储。\n数据传输尽量让DMA来做。\n\n将多种操作结合在一起\n\n避免不必要的系统调用和上下文切换。\n需要拷贝的数据可以先被缓存起来。\n对数据进行处理尽量让硬件来做。\n\n前文提到过，对于高速网络来说，零拷贝技术是非常重要的。这是因为高速网络的网络链接能力与CPU的处理能力接近，甚至会超过CPU的处理能力。如果是这样的话，那么CPU就有可能需要花费几乎所有的时间去拷贝要传输的数据，而没有能力再去做别的事情，这就产生了性能瓶颈，限制了通讯速率，从而降低了网络链接的能力。一般来说，一个CPU时钟周期可以处理一位的数据。举例来说，一个1GHz的处理器可以对1Gbit/s的网络链接进行传统的数据拷贝操作，但是如果是10Gbit/s的网络，那么对于相同的处理器来说，零拷贝技术就变得非常重要了。对于超过1Gbit/s的网络链接来说，零拷贝技术在超级计算机集群以及大型的商业数据中心中都有所应用。然而，随着信息技术的发展，1Gbit/s，10Gbit/s以及100Gbit/s的网络会越来越普及，那么零拷贝技术也会变得越来越普及，这是因为网络链接的处理能力比CPU的处理能力的增长要快得多。传统的数据拷贝受限于传统的操作系统或者通信协议，这就限制了数据传输性能。零拷贝技术通过减少数据拷贝次数，简化协议处理的层次，在应用程序和网络之间提供更快的数据传输方法，从而可以有效地降低通信延迟，提高网络吞吐率。零拷贝技术是实现主机或者路由器等设备高速网络接口的主要技术之一。\n现代的CPU和存储体系结构提供了很多相关的功能来减少或避免I/O操作过程中产生的不必要的CPU数据拷贝操作，但是，CPU和存储体系结构的这种优势经常被过高估计。存储体系结构的复杂性以及网络协议中必需的数据传输可能会产生问题，有时甚至会导致零拷贝这种技术的优点完全丧失。在下一章中，我们会介绍几种Linux操作系统中出现的零拷贝技术，简单描述一下它们的实现方法，并对它们的弱点进行分析。\n零拷贝技术分类零拷贝技术的发展很多样化，现有的零拷贝技术种类也非常多，而当前并没有一个适合于所有场景的零拷贝技术的出现。对于Linux来说，现存的零拷贝技术也比较多，这些零拷贝技术大部分存在于不同的Linux内核版本，有些旧的技术在不同的Linux内核版本间得到了很大的发展或者已经渐渐被新的技术所代替。本文针对这些零拷贝技术所适用的不同场景对它们进行了划分。概括起来，Linux中的零拷贝技术主要有下面这几种：\n\n直接I/O：对于这种数据传输方式来说，应用程序可以直接访问硬件存储，操作系统内核只是辅助数据传输：这类零拷贝技术针对的是操作系统内核并不需要对数据进行直接处理的情况，数据可以在应用程序地址空间的缓冲区和磁盘之间直接进行传输，完全不需要Linux操作系统内核提供的页缓存的支持。\n在数据传输的过程中，避免数据在操作系统内核地址空间的缓冲区和用户应用程序地址空间的缓冲区之间进行拷贝。有的时候，应用程序在数据进行传输的过程中不需要对数据进行访问，那么，将数据从Linux的页缓存拷贝到用户进程的缓冲区中就可以完全避免，传输的数据在页缓存中就可以得到处理。在某些特殊的情况下，这种零拷贝技术可以获得较好的性能。Linux中提供类似的系统调用主要有mmap()，sendfile()以及splice()。\n对数据在Linux的页缓存和用户进程的缓冲区之间的传输过程进行优化。该零拷贝技术侧重于灵活地处理数据在用户进程的缓冲区和操作系统的页缓存之间的拷贝操作。这种方法延续了传统的通信方式，但是更加灵活。在Linux中，该方法主要利用了写时复制技术。\n\n前两类方法的目的主要是为了避免应用程序地址空间和操作系统内核地址空间这两者之间的缓冲区拷贝操作。这两类零拷贝技术通常适用在某些特殊的情况下，比如要传送的数据不需要经过操作系统内核的处理或者不需要经过应用程序的处理。第三类方法则继承了传统的应用程序地址空间和操作系统内核地址空间之间数据传输的概念，进而针对数据传输本身进行优化。我们知道，硬件和软件之间的数据传输可以通过使用DMA来进行，DMA进行数据传输的过程中几乎不需要CPU参与，这样就可以把CPU解放出来去做更多其他的事情，但是当数据需要在用户地址空间的缓冲区和Linux操作系统内核的页缓存之间进行传输的时候，并没有类似DMA这种工具可以使用，CPU需要全程参与到这种数据拷贝操作中，所以这第三类方法的目的是可以有效地改善数据在用户地址空间和操作系统内核地址空间之间传递的效率。\nJava通过零拷贝实现高效的数据传输在 Linux 和 Unix 系统中 Java 类库通过java.nio.channels.FileChannel 的transgerTo方法支持零拷贝。\n"},{"title":"JavaScript组件化开发","url":"/2020/03/21/JavaScript%E7%BB%84%E4%BB%B6%E5%8C%96%E5%BC%80%E5%8F%91/","content":"文章出自：https://blog.csdn.net/Prince_fmx/article/details/77926189\n下面我们来谈谈，在现有的知识体系下，如何很好的写组件。\n比如我们要实现这样一个组件，就是一个输入框里面字数的计数。这个应该是个很简单的需求。\n\n我们来看看，下面的各种写法。\n\n为了更清楚的演示，下面全部使用jQuery作为基础语言库。\n\n最简陋的写法嗯 所谓的入门级写法呢，就是完完全全的全局函数全局变量的写法。（就我所知，现在好多外包还是这种写法）\n代码如下：\n&lt;!DOCTYPE html&gt;&lt;html&gt;  &lt;head&gt;    &lt;meta charset=\"utf-8\"&gt;    &lt;title&gt;test&lt;/title&gt;    &lt;script src=\"http://code.jquery.com/jquery-1.9.1.min.js\"&gt;&lt;/script&gt;    &lt;script&gt;      $(function() &#123;        var input = $('#J_input');        //用来获取字数        function getNum()&#123;          return input.val().length;        &#125;        //渲染元素        function render()&#123;          var num = getNum();          //没有字数的容器就新建一个          if ($('#J_input_count').length == 0) &#123;            input.after('&lt;span id=\"J_input_count\"&gt;&lt;/span&gt;');          &#125;;          $('#J_input_count').html(num+'个字');        &#125;        //监听事件        input.on('keyup',function()&#123;          render();        &#125;);        //初始化，第一次渲染        render();      &#125;)    &lt;/script&gt;  &lt;/head&gt;  &lt;body&gt;    &lt;input type=\"text\" id=\"J_input\"/&gt;  &lt;/body&gt;&lt;/html&gt;\n\n这段代码跑也是可以跑的，但是呢，各种变量混乱，没有很好的隔离作用域,当页面变的复杂的时候,会很难去维护。目前这种代码基本是用不了的。当然少数的活动页面可以简单用用。\n作用域隔离让我们对上面的代码作些改动，使用单个变量模拟命名空间。\nvar textCount = &#123;  input:null,  init:function(config)&#123;    this.input = $(config.id);    this.bind();    //这边范围对应的对象，可以实现链式调用    return this;  &#125;,  bind:function()&#123;    var self = this;    this.input.on('keyup',function()&#123;      self.render();    &#125;);  &#125;,  getNum:function()&#123;    return this.input.val().length;  &#125;,  //渲染元素  render:function()&#123;    var num = this.getNum();    if ($('#J_input_count').length == 0) &#123;      this.input.after('&lt;span id=\"J_input_count\"&gt;&lt;/span&gt;');    &#125;;    $('#J_input_count').html(num+'个字');  &#125;&#125;$(function() &#123;  //在domready后调用  textCount.init(&#123;id:'#J_input'&#125;).render();&#125;)\n\n这样一改造，立马变的清晰了很多，所有的功能都在一个变量下面。代码更清晰，并且有统一的入口调用方法。\n但是还是有些瑕疵，这种写法没有私有的概念，比如上面的getNum,bind应该都是私有的方法。但是其他代码可以很随意的改动这些。当代码量特别特别多的时候，很容易出现变量重复，或被修改的问题。\n于是又出现了一种函数闭包的写法：\nvar TextCount = (function()&#123;  //私有方法，外面将访问不到  var _bind = function(that)&#123;    that.input.on('keyup',function()&#123;      that.render();    &#125;);  &#125;  var _getNum = function(that)&#123;    return that.input.val().length;  &#125;  var TextCountFun = function(config)&#123;  &#125;  TextCountFun.prototype.init = function(config) &#123;    this.input = $(config.id);    _bind(this);    return this;  &#125;;  TextCountFun.prototype.render = function() &#123;    var num = _getNum(this);    if ($('#J_input_count').length == 0) &#123;      this.input.after('&lt;span id=\"J_input_count\"&gt;&lt;/span&gt;');    &#125;;    $('#J_input_count').html(num+'个字');  &#125;;  //返回构造函数  return TextCountFun;&#125;)();$(function() &#123;  new TextCount().init(&#123;id:'#J_input'&#125;).render();&#125;)\n\n这种写法，把所有的东西都包在了一个自动执行的闭包里面，所以不会受到外面的影响，并且只对外公开了TextCountFun构造函数，生成的对象只能访问到init,render方法。这种写法已经满足绝大多数的需求了。事实上大部分的jQuery插件都是这种写法。\n面向对象上面的写法已经可以满足绝大多数需求了。\n但是呢，当一个页面特别复杂，当我们需要的组件越来越多，当我们需要做一套组件。仅仅用这个就不行了。首先的问题就是，这种写法太灵活了，写单个组件还可以。如果我们需要做一套风格相近的组件，而且是多个人同时在写。那真的是噩梦。\n在编程的圈子里，面向对象一直是被认为最佳的编写代码方式。比如java，就是因为把面向对象发挥到了极致，所以多个人写出来的代码都很接近，维护也很方便。但是很不幸的是，javascript不支持class类的定义。但是我们可以模拟。\n下面我们先实现个简单的javascript类：\nvar Class = (function() &#123;  var _mix = function(r, s) &#123;    for (var p in s) &#123;      if (s.hasOwnProperty(p)) &#123;        r[p] = s[p]      &#125;    &#125;  &#125;  var _extend = function() &#123;    //开关 用来使生成原型时,不调用真正的构成流程init    this.initPrototype = true    var prototype = new this()    this.initPrototype = false    var items = Array.prototype.slice.call(arguments) || []    var item    //支持混入多个属性，并且支持&#123;&#125;也支持 Function    while (item = items.shift()) &#123;      _mix(prototype, item.prototype || item)    &#125;    // 这边是返回的类，其实就是我们返回的子类    function SubClass() &#123;      if (!SubClass.initPrototype &amp;&amp; this.init)        this.init.apply(this, arguments)//调用init真正的构造函数    &#125;    // 赋值原型链，完成继承    SubClass.prototype = prototype    // 改变constructor引用    SubClass.prototype.constructor = SubClass    // 为子类也添加extend方法    SubClass.extend = _extend    return SubClass  &#125;  //超级父类  var Class = function() &#123;&#125;  //为超级父类添加extend方法  Class.extend = _extend  return Class&#125;)()\n\n这是拿John Resig的class简单修改了下。\n\n这边只是很简陋的实现了类的继承机制。如果对类的实现有兴趣可以参考我另一篇文章javascript oo实现\n\n我们看下使用方法：\n//继承超级父类，生成个子类Animal，并且混入一些方法。这些方法会到Animal的原型上。//另外这边不仅支持混入&#123;&#125;，还支持混入Functionvar Animal = Class.extend(&#123;  init:function(opts)&#123;    this.msg = opts.msg    this.type = \"animal\"  &#125;,  say:function()&#123;    alert(this.msg+\":i am a \"+this.type)  &#125;&#125;)//继承Animal，并且混入一些方法var Dog = Animal.extend(&#123;  init:function(opts)&#123;    //并未实现super方法，直接简单使用父类原型调用即可    Animal.prototype.init.call(this,opts)    //修改了type类型    this.type = \"dog\"  &#125;&#125;)//new Animal(&#123;msg:'hello'&#125;).say()new Dog(&#123;msg:'hi'&#125;).say()\n\n使用很简单，超级父类具有extend方法，可以继承出一个子类。子类也具有extend方法。\n这边要强调的是，继承的父类都是一个也就是单继承。但是可以通过extend实现多重混入。详见下面用法。\n有了这个类的扩展，我们可以这么编写代码了：\nvar TextCount = Class.extend(&#123;  init:function(config)&#123;    this.input = $(config.id);    this._bind();    this.render();  &#125;,  render:function() &#123;    var num = this._getNum();    if ($('#J_input_count').length == 0) &#123;      this.input.after('&lt;span id=\"J_input_count\"&gt;&lt;/span&gt;');    &#125;;    $('#J_input_count').html(num+'个字');  &#125;,  _getNum:function()&#123;    return this.input.val().length;  &#125;,  _bind:function()&#123;    var self = this;    self.input.on('keyup',function()&#123;      self.render();    &#125;);  &#125;&#125;)$(function() &#123;  new TextCount(&#123;    id:\"#J_input\"  &#125;);&#125;)\n\n这边可能还没看见class的真正好处，不急我们继续往下。\n抽象出base可以看到，我们的组件有些方法，是大部分组件都会有的。\n\n比如init用来初始化属性。\n比如render用来处理渲染的逻辑。\n比如bind用来处理事件的绑定。\n\n当然这也是一种约定俗成的规范了。如果大家全部按照这种风格来写代码，开发大规模组件库就变得更加规范，相互之间配合也更容易。\n这个时候面向对象的好处就来了，我们抽象出一个Base类。其他组件编写时都继承它。\nvar Base = Class.extend(&#123;  init:function(config)&#123;    //自动保存配置项    this.__config = config    this.bind()    this.render()  &#125;,  //可以使用get来获取配置项  get:function(key)&#123;    return this.__config[key]  &#125;,  //可以使用set来设置配置项  set:function(key,value)&#123;    this.__config[key] = value  &#125;,  bind:function()&#123;  &#125;,  render:function() &#123;  &#125;,  //定义销毁的方法，一些收尾工作都应该在这里  destroy:function()&#123;  &#125;&#125;)\n\nbase类主要把组件的一般性内容都提取了出来，这样我们编写组件时可以直接继承base类，覆盖里面的bind和render方法。\n于是我们可以这么写代码：\nvar TextCount = Base.extend(&#123;  _getNum:function()&#123;    return this.get('input').val().length;  &#125;,  bind:function()&#123;    var self = this;    self.get('input').on('keyup',function()&#123;      self.render();    &#125;);  &#125;,  render:function() &#123;    var num = this._getNum();    if ($('#J_input_count').length == 0) &#123;      this.get('input').after('&lt;span id=\"J_input_count\"&gt;&lt;/span&gt;');    &#125;;    $('#J_input_count').html(num+'个字');  &#125;&#125;)$(function() &#123;  new TextCount(&#123;    //这边直接传input的节点了，因为属性的赋值都是自动的。    input:$(\"#J_input\")  &#125;);&#125;)\n\n可以看到我们直接实现一些固定的方法，bind，render就行了。其他的base会自动处理（这里只是简单处理了配置属性的赋值）。\n事实上，这边的init，bind，render就已经有了点生命周期的影子，但凡是组件都会具有这几个阶段，初始化，绑定事件，以及渲染。当然这边还可以加一个destroy销毁的方法，用来清理现场。\n此外为了方便，这边直接变成了传递input的节点。因为属性赋值自动化了，一般来说这种情况下都是使用getter，setter来处理。这边就不详细展开了。\n引入事件机制（观察者模式）有了base应该说我们编写组件更加的规范化，体系化了。下面我们继续深挖。\n还是上面的那个例子，如果我们希望输入字的时候超过5个字就弹出警告。该怎么办呢。\n小白可能会说，那简单啊直接改下bind方法：\nvar TextCount = Base.extend(&#123;  ...  bind:function()&#123;    var self = this;    self.get('input').on('keyup',function()&#123;      if(self._getNum() &gt; 5)&#123;        alert('超过了5个字了。。。')      &#125;      self.render();    &#125;);  &#125;,  ...&#125;)\n\n的确也是一种方法，但是太low了，代码严重耦合。当这种需求特别特别多，代码会越来越乱。\n这个时候就要引入事件机制，也就是经常说的观察者模式。\n\n注意这边的事件机制跟平时的浏览器那些事件不是一回事，要分开来看。\n\n什么是观察者模式呢，官方的解释就不说了，直接拿这个例子来说。\n想象一下base是个机器人会说话，他会一直监听输入的字数并且汇报出去（通知）。而你可以把耳朵凑上去，听着他的汇报（监听）。发现字数超过5个字了，你就做些操作。\n所以这分为两个部分，一个是通知，一个是监听。\n假设通知是 fire方法，监听是on。于是我们可以这么写代码：\nvar TextCount = Base.extend(&#123;  ...  bind:function()&#123;    var self = this;    self.get('input').on('keyup',function()&#123;      //通知,每当有输入的时候，就报告出去。      self.fire('Text.input',self._getNum())      self.render();    &#125;);  &#125;,  ...&#125;)  $(function() &#123;  var t = new TextCount(&#123;    input:$(\"#J_input\")  &#125;);  //监听这个输入事件  t.on('Text.input',function(num)&#123;    //可以获取到传递过来的值    if(num&gt;5)&#123;      alert('超过了5个字了。。。')    &#125;  &#125;)&#125;)\n\nfire用来触发一个事件，可以传递数据。而on用来添加一个监听。这样组件里面只负责把一些关键的事件抛出来，至于具体的业务逻辑都可以添加监听来实现。没有事件的组件是不完整的。\n下面我们看看怎么实现这套事件机制。\n我们首先抛开base，想想怎么实现一个具有这套机制的类。\n//辅组函数，获取数组里某个元素的索引 indexvar _indexOf = function(array,key)&#123;  if (array === null) return -1  var i = 0, length = array.length  for (; i &lt; length; i++) if (array[i] === item) return i  return -1&#125;var Event = Class.extend(&#123;  //添加监听  on:function(key,listener)&#123;    //this.__events存储所有的处理函数    if (!this.__events) &#123;      this.__events = &#123;&#125;    &#125;    if (!this.__events[key]) &#123;      this.__events[key] = []    &#125;    if (_indexOf(this.__events,listener) === -1 &amp;&amp; typeof listener === 'function') &#123;      this.__events[key].push(listener)    &#125;    return this  &#125;,  //触发一个事件，也就是通知  fire:function(key)&#123;    if (!this.__events || !this.__events[key]) return    var args = Array.prototype.slice.call(arguments, 1) || []    var listeners = this.__events[key]    var i = 0    var l = listeners.length    for (i; i &lt; l; i++) &#123;      listeners[i].apply(this,args)    &#125;    return this  &#125;,  //取消监听  off:function(key,listener)&#123;    if (!key &amp;&amp; !listener) &#123;      this.__events = &#123;&#125;    &#125;    //不传监听函数，就去掉当前key下面的所有的监听函数    if (key &amp;&amp; !listener) &#123;      delete this.__events[key]    &#125;    if (key &amp;&amp; listener) &#123;      var listeners = this.__events[key]      var index = _indexOf(listeners, listener)      (index &gt; -1) &amp;&amp; listeners.splice(index, 1)      &#125;    return this;  &#125;&#125;)var a = new Event()//添加监听 test事件a.on('test',function(msg)&#123;  alert(msg)&#125;)//触发 test事件a.fire('test','我是第一次触发')a.fire('test','我又触发了')a.off('test')a.fire('test','你应该看不到我了')\n\n实现起来并不复杂，只要使用this.__events存下所有的监听函数。在fire的时候去找到并且执行就行了。\n这个时候面向对象的好处就来了，如果我们希望base拥有事件机制。只需要这么写:\nvar Base = Class.extend(Event,&#123;  ...  destroy:function()&#123;    //去掉所有的事件监听    this.off()  &#125;&#125;)//于是可以//var a  = new Base()// a.on(xxx,fn)//// a.fire()\n\n是的只要extend的时候多混入一个Event，这样Base或者它的子类生成的对象都会自动具有事件机制。\n有了事件机制我们可以把组件内部很多状态暴露出来，比如我们可以在set方法中抛出一个事件，这样每次属性变更的时候我们都可以监听到。\n到这里为止，我们的base类已经像模像样了，具有了init，bind，render，destroy方法来表示组件的各个关键过程，并且具有了事件机制。基本上已经可以很好的来开发组件了。\n更进一步，richbase我们还可以继续深挖。看看我们的base，还差些什么。首先浏览器的事件监听还很落后，需要用户自己在bind里面绑定，再然后现在的TextCount里面还存在dom操作，也没有自己的模板机制。这都是需要扩展的，于是我们在base的基础上再继承出一个richbase用来实现更完备的组件基类。\n主要实现这些功能：\n\n事件代理：不需要用户自己去找dom元素绑定监听，也不需要用户去关心什么时候销毁。\n模板渲染：用户不需要覆盖render方法，而是覆盖实现setUp方法。可以通过在setUp里面调用render来达到渲染对应html的目的。\n单向绑定：通过setChuckdata方法，更新数据，同时会更新html内容，不再需要dom操作。\n\n我们看下我们实现richbase后怎么写组件：\nvar TextCount = RichBase.extend(&#123;  //事件直接在这里注册，会代理到parentNode节点，parentNode节点在下面指定  EVENTS:&#123;    //选择器字符串，支持所有jQuery风格的选择器    'input':&#123;      //注册keyup事件      keyup:function(self,e)&#123;        //单向绑定，修改数据直接更新对应模板        self.setChuckdata('count',self._getNum())      &#125;    &#125;  &#125;,  //指定当前组件的模板  template:'&lt;span id=\"J_input_count\"&gt;&lt;%= count %&gt;个字&lt;/span&gt;',  //私有方法  _getNum:function()&#123;    return this.get('input').val().length || 0  &#125;,  //覆盖实现setUp方法，所有逻辑写在这里。最后可以使用render来决定需不需要渲染模板  //模板渲染后会append到parentNode节点下面，如果未指定，会append到document.body  setUp:function()&#123;    var self = this;    var input = this.get('parentNode').find('#J_input')    self.set('input',input)    var num = this._getNum()    //赋值数据，渲染模板，选用。有的组件没有对应的模板就可以不调用这步。    self.render(&#123;      count:num    &#125;)  &#125;&#125;)$(function() &#123;  //传入parentNode节点，组件会挂载到这个节点上。所有事件都会代理到这个上面。  new TextCount(&#123;    parentNode:$(\"#J_test_container\")  &#125;);&#125;)/**对应的html,做了些修改，主要为了加上parentNode，这边就是J_test_container&lt;div id=\"J_test_container\"&gt;  &lt;input type=\"text\" id=\"J_input\"/&gt;&lt;/div&gt;*/\n\n看下上面的用法，可以看到变得更简单清晰了：\n\n事件不需要自己绑定，直接注册在EVENTS属性上。程序会自动将事件代理到parentNode上。\n引入了模板机制，使用template规定组件的模板，然后在setUp里面使用render(data)的方式渲染模板，程序会自动帮你append到parentNode下面。\n单向绑定，无需操作dom，后面要改动内容，不需要操作dom，只需要调用setChuckdata(key,新的值)，选择性的更新某个数据，相应的html会自动重新渲染。\n\n下面我们看下richebase的实现：\nvar RichBase = Base.extend(&#123;  EVENTS:&#123;&#125;,  template:'',  init:function(config)&#123;    //存储配置项    this.__config = config    //解析代理事件    this._delegateEvent()    this.setUp()  &#125;,  //循环遍历EVENTS，使用jQuery的delegate代理到parentNode  _delegateEvent:function()&#123;    var self = this    var events = this.EVENTS || &#123;&#125;    var eventObjs,fn,select,type    var parentNode = this.get('parentNode') || $(document.body)    for (select in events) &#123;      eventObjs = events[select]      for (type in eventObjs) &#123;        fn = eventObjs[type]        parentNode.delegate(select,type,function(e)&#123;          fn.call(null,self,e)        &#125;)      &#125;    &#125;  &#125;,  //支持underscore的极简模板语法  //用来渲染模板，这边是抄的underscore的。非常简单的模板引擎，支持原生的js语法  _parseTemplate:function(str,data)&#123;    /**       * http://ejohn.org/blog/javascript-micro-templating/       * https://github.com/jashkenas/underscore/blob/0.1.0/underscore.js#L399       */    var fn = new Function('obj',                          'var p=[],print=function()&#123;p.push.apply(p,arguments);&#125;;' +                          'with(obj)&#123;p.push(\\'' + str                          .replace(/[\\r\\t\\n]/g, \" \")                          .split(\"&lt;%\").join(\"\\t\")                          .replace(/((^|%&gt;)[^\\t]*)'/g, \"$1\\r\")                          .replace(/\\t=(.*?)%&gt;/g, \"',$1,'\")                          .split(\"\\t\").join(\"');\")                          .split(\"%&gt;\").join(\"p.push('\")                          .split(\"\\r\").join(\"\\\\'\") +                          \"');&#125;return p.join('');\")    return data ? fn(data) : fn  &#125;,  //提供给子类覆盖实现  setUp:function()&#123;    this.render()  &#125;,  //用来实现刷新，只需要传入之前render时的数据里的key还有更新值，就可以自动刷新模板  setChuckdata:function(key,value)&#123;    var self = this    var data = self.get('__renderData')    //更新对应的值    data[key] = value    if (!this.template) return;    //重新渲染    var newHtmlNode = $(self._parseTemplate(this.template,data))    //拿到存储的渲染后的节点    var currentNode = self.get('__currentNode')    if (!currentNode) return;    //替换内容    currentNode.replaceWith(newHtmlNode)    self.set('__currentNode',newHtmlNode)  &#125;,  //使用data来渲染模板并且append到parentNode下面  render:function(data)&#123;    var self = this    //先存储起来渲染的data,方便后面setChuckdata获取使用    self.set('__renderData',data)    if (!this.template) return;    //使用_parseTemplate解析渲染模板生成html    //子类可以覆盖这个方法使用其他的模板引擎解析    var html = self._parseTemplate(this.template,data)    var parentNode = this.get('parentNode') || $(document.body)    var currentNode = $(html)    //保存下来留待后面的区域刷新    //存储起来，方便后面setChuckdata获取使用    self.set('__currentNode',currentNode)    parentNode.append(currentNode)  &#125;,  destroy:function()&#123;    var self = this    //去掉自身的事件监听    self.off()    //删除渲染好的dom节点    self.get('__currentNode').remove()    //去掉绑定的代理事件    var events = self.EVENTS || &#123;&#125;    var eventObjs,fn,select,type    var parentNode = self.get('parentNode')    for (select in events) &#123;      eventObjs = events[select]      for (type in eventObjs) &#123;        fn = eventObjs[type]        parentNode.undelegate(select,type,fn)      &#125;    &#125;  &#125;&#125;)\n\n主要做了两件事，一个就是事件的解析跟代理，全部代理到parentNode上面。另外就是把render抽出来，用户只需要实现setUp方法。如果需要模板支持就在setUp里面调用render来渲染模板，并且可以通过setChuckdata来刷新模板，实现单向绑定。\n结语有了richbase，基本上组件开发就没啥问题了。但是我们还是可以继续深挖下去。\n比如组件自动化加载渲染，局部刷新，比如父子组件的嵌套，再比如双向绑定，再比如实现ng-click这种风格的事件机制。\n当然这些东西已经不属于组件里面的内容了。再进一步其实已经是一个框架了。实际上最近比较流行的react，ploymer还有我们的brix等等都是实现了这套东西。受限于篇幅，这个以后有空再写篇文章详细分析下。\n","tags":["JavaScript","前端开发"]},{"title":"Java中Unsafe详细介绍","url":"/2020/06/03/Java%E4%B8%ADUnsafe%E8%AF%A6%E7%BB%86%E4%BB%8B%E7%BB%8D/","content":"前言Unsafe是位于sun.misc包下的一个类，主要提供一些用于执行低级别、不安全操作的方法，如直接访问系统内存资源、自主管理内存资源等，这些方法在提升Java运行效率、增强Java语言底层资源操作能力方面起到了很大的作用。但由于Unsafe类使Java语言拥有了类似C语言指针一样操作内存空间的能力，这无疑也增加了程序发生相关指针问题的风险。在程序中过度、不正确使用Unsafe类会使得程序出错的概率变大，使得Java这种安全的语言变得不再“安全”，因此对Unsafe的使用一定要慎重。\n注：本文对sun.misc.Unsafe公共API功能及相关应用场景进行介绍。\n基本介绍如下Unsafe源码所示，Unsafe类为一单例实现，提供静态方法getUnsafe获取Unsafe实例，当且仅当调用getUnsafe方法的类为引导类加载器所加载时才合法，否则抛出SecurityException异常。\npublic final class Unsafe &#123;  // 单例对象  private static final Unsafe theUnsafe;  private Unsafe() &#123;  &#125;  @CallerSensitive  public static Unsafe getUnsafe() &#123;    Class var0 = Reflection.getCallerClass();    // 仅在引导类加载器`BootstrapClassLoader`加载时才合法    if(!VM.isSystemDomainLoader(var0.getClassLoader())) &#123;      throw new SecurityException(\"Unsafe\");    &#125; else &#123;      return theUnsafe;    &#125;  &#125;&#125;\n\n那如若想使用这个类，该如何获取其实例？有如下两个可行方案。\n其一，从getUnsafe方法的使用限制条件出发，通过Java命令行命令-Xbootclasspath/a把调用Unsafe相关方法的类A所在jar包路径追加到默认的bootstrap路径中，使得A被引导类加载器加载，从而通过Unsafe.getUnsafe方法安全的获取Unsafe实例。\njava -Xbootclasspath/a: $&#123;path&#125;   // 其中path为调用Unsafe相关方法的类所在jar包路径\n\n其二，通过反射获取单例对象theUnsafe。\nprivate static Unsafe reflectGetUnsafe() &#123;    try &#123;      Field field = Unsafe.class.getDeclaredField(\"theUnsafe\");      field.setAccessible(true);      return (Unsafe) field.get(null);    &#125; catch (Exception e) &#123;      log.error(e.getMessage(), e);      return null;    &#125;&#125;\n\n功能介绍\n如上图所示，Unsafe提供的API大致可分为内存操作、CAS、Class相关、对象操作、线程调度、系统信息获取、内存屏障、数组操作等几类，下面将对其相关方法和应用场景进行详细介绍。\n内存操作这部分主要包含堆外内存的分配、拷贝、释放、给定地址值操作等方法。\n//分配内存, 相当于C++的malloc函数public native long allocateMemory(long bytes);//扩充内存public native long reallocateMemory(long address, long bytes);//释放内存public native void freeMemory(long address);//在给定的内存块中设置值public native void setMemory(Object o, long offset, long bytes, byte value);//内存拷贝public native void copyMemory(Object srcBase, long srcOffset, Object destBase, long destOffset, long bytes);//获取给定地址值，忽略修饰限定符的访问限制。与此类似操作还有: getInt，getDouble，getLong，getChar等public native Object getObject(Object o, long offset);//为给定地址设置值，忽略修饰限定符的访问限制，与此类似操作还有: putInt,putDouble，putLong，putChar等public native void putObject(Object o, long offset, Object x);//获取给定地址的byte类型的值（当且仅当该内存地址为allocateMemory分配时，此方法结果为确定的）public native byte getByte(long address);//为给定地址设置byte类型的值（当且仅当该内存地址为allocateMemory分配时，此方法结果才是确定的）public native void putByte(long address, byte x);\n\n通常，我们在Java中创建的对象都处于堆内内存（heap）中，堆内内存是由JVM所管控的Java进程内存，并且它们遵循JVM的内存管理机制，JVM会采用垃圾回收机制统一管理堆内存。与之相对的是堆外内存，存在于JVM管控之外的内存区域，Java中对堆外内存的操作，依赖于Unsafe提供的操作堆外内存的native方法。\n使用堆外内存的原因\n对垃圾回收停顿的改善。由于堆外内存是直接受操作系统管理而不是JVM，所以当我们使用堆外内存时，即可保持较小的堆内内存规模。从而在GC时减少回收停顿对于应用的影响。\n提升程序I/O操作的性能。通常在I/O通信过程中，会存在堆内内存到堆外内存的数据拷贝操作，对于需要频繁进行内存间数据拷贝且生命周期较短的暂存数据，都建议存储到堆外内存。\n\n典型应用DirectByteBuffer是Java用于实现堆外内存的一个重要类，通常用在通信过程中做缓冲池，如在Netty、MINA等NIO框架中应用广泛。DirectByteBuffer对于堆外内存的创建、使用、销毁等逻辑均由Unsafe提供的堆外内存API来实现。\n下图为DirectByteBuffer构造函数，创建DirectByteBuffer的时候，通过Unsafe.allocateMemory分配内存、Unsafe.setMemory进行内存初始化，而后构建Cleaner对象用于跟踪DirectByteBuffer对象的垃圾回收，以实现当DirectByteBuffer被垃圾回收时，分配的堆外内存一起被释放。\n\n那么如何通过构建垃圾回收追踪对象Cleaner实现堆外内存释放呢？\nCleaner继承自Java四大引用类型之一的虚引用PhantomReference（众所周知，无法通过虚引用获取与之关联的对象实例，且当对象仅被虚引用引用时，在任何发生GC的时候，其均可被回收），通常PhantomReference与引用队列ReferenceQueue结合使用，可以实现虚引用关联对象被垃圾回收时能够进行系统通知、资源清理等功能。如下图所示，当某个被Cleaner引用的对象将被回收时，JVM垃圾收集器会将此对象的引用放入到对象引用中的pending链表中，等待Reference-Handler进行相关处理。其中，Reference-Handler为一个拥有最高优先级的守护线程，会循环不断的处理pending链表中的对象引用，执行Cleaner的clean方法进行相关清理工作。\n\n所以当DirectByteBuffer仅被Cleaner引用（即为虚引用）时，其可以在任意GC时段被回收。当DirectByteBuffer实例对象被回收时，在Reference-Handler线程操作中，会调用Cleaner的clean方法根据创建Cleaner时传入的Deallocator来进行堆外内存的释放。\n\nCAS相关如下源代码释义所示，这部分主要为CAS相关操作的方法。\n/**\t*  CAS  * @param o         包含要修改field的对象  * @param offset    对象中某field的偏移量  * @param expected  期望值  * @param update    更新值  * @return          true | false  */public final native boolean compareAndSwapObject(Object o, long offset,  Object expected, Object update);public final native boolean compareAndSwapInt(Object o, long offset, int expected,int update);public final native boolean compareAndSwapLong(Object o, long offset, long expected, long update);\n\n什么是CAS? 即比较并替换，实现并发算法时常用到的一种技术。CAS操作包含三个操作数——内存位置、预期原值及新值。执行CAS操作的时候，将内存位置的值与预期原值比较，如果相匹配，那么处理器会自动将该位置值更新为新值，否则，处理器不做任何操作。我们都知道，CAS是一条CPU的原子指令（cmpxchg指令），不会造成所谓的数据不一致问题，Unsafe提供的CAS方法（如compareAndSwapXXX）底层实现即为CPU指令cmpxchg。\n典型应用CAS在java.util.concurrent.atomic相关类、Java AQS、CurrentHashMap等实现上有非常广泛的应用。如下图所示，AtomicInteger的实现中，静态字段valueOffset即为字段value的内存偏移地址，valueOffset的值在AtomicInteger初始化时，在静态代码块中通过Unsafe的objectFieldOffset方法获取。在AtomicInteger中提供的线程安全方法中，通过字段valueOffset的值可以定位到AtomicInteger对象中value的内存地址，从而可以根据CAS实现对value字段的原子操作。\n\n下图为某个AtomicInteger对象自增操作前后的内存示意图，对象的基地址baseAddress=“0x110000”，通过baseAddress+valueOffset得到value的内存地址valueAddress=“0x11000c”；然后通过CAS进行原子性的更新操作，成功则返回，否则继续重试，直到更新成功为止。\n\n线程调度这部分，包括线程挂起、恢复、锁机制等方法。\n//取消阻塞线程public native void unpark(Object thread);//阻塞线程public native void park(boolean isAbsolute, long time);//获得对象锁（可重入锁）@Deprecatedpublic native void monitorEnter(Object o);//释放对象锁@Deprecatedpublic native void monitorExit(Object o);//尝试获取对象锁@Deprecatedpublic native boolean tryMonitorEnter(Object o);\n\n如上源码说明中，方法park、unpark即可实现线程的挂起与恢复，将一个线程进行挂起是通过park方法实现的，调用park方法后，线程将一直阻塞直到超时或者中断等条件出现；unpark可以终止一个挂起的线程，使其恢复正常。\n典型应用Java锁和同步器框架的核心类AbstractQueuedSynchronizer，就是通过调用LockSupport.park()和LockSupport.unpark()实现线程的阻塞和唤醒的，而LockSupport的park、unpark方法实际是调用Unsafe的park、unpark方式来实现。\nClass相关此部分主要提供Class和它的静态字段的操作相关方法，包含静态字段内存定位、定义类、定义匿名类、检验&amp;确保初始化等。\n//获取给定静态字段的内存地址偏移量，这个值对于给定的字段是唯一且固定不变的public native long staticFieldOffset(Field f);//获取一个静态类中给定字段的对象指针public native Object staticFieldBase(Field f);//判断是否需要初始化一个类，通常在获取一个类的静态属性的时候（因为一个类如果没初始化，它的静态属性也不会初始化）使用。 当且仅当ensureClassInitialized方法不生效时返回false。public native boolean shouldBeInitialized(Class&lt;?&gt; c);//检测给定的类是否已经初始化。通常在获取一个类的静态属性的时候（因为一个类如果没初始化，它的静态属性也不会初始化）使用。public native void ensureClassInitialized(Class&lt;?&gt; c);//定义一个类，此方法会跳过JVM的所有安全检查，默认情况下，ClassLoader（类加载器）和ProtectionDomain（保护域）实例来源于调用者public native Class&lt;?&gt; defineClass(String name, byte[] b, int off, int len, ClassLoader loader, ProtectionDomain protectionDomain);//定义一个匿名类public native Class&lt;?&gt; defineAnonymousClass(Class&lt;?&gt; hostClass, byte[] data, Object[] cpPatches);\n\n典型应用从Java 8开始，JDK使用invokedynamic及VM Anonymous Class结合来实现Java语言层面上的Lambda表达式。\n\ninvokedynamic： invokedynamic是Java 7为了实现在JVM上运行动态语言而引入的一条新的虚拟机指令，它可以实现在运行期动态解析出调用点限定符所引用的方法，然后再执行该方法，invokedynamic指令的分派逻辑是由用户设定的引导方法决定。\nVM Anonymous Class：可以看做是一种模板机制，针对于程序动态生成很多结构相同、仅若干常量不同的类时，可以先创建包含常量占位符的模板类，而后通过Unsafe.defineAnonymousClass方法定义具体类时填充模板的占位符生成具体的匿名类。生成的匿名类不显式挂在任何ClassLoader下面，只要当该类没有存在的实例对象、且没有强引用来引用该类的Class对象时，该类就会被GC回收。故而VM Anonymous Class相比于Java语言层面的匿名内部类无需通过ClassClassLoader进行类加载且更易回收。\n\n在Lambda表达式实现中，通过invokedynamic指令调用引导方法生成调用点，在此过程中，会通过ASM动态生成字节码，而后利用Unsafe的defineAnonymousClass方法定义实现相应的函数式接口的匿名类，然后再实例化此匿名类，并返回与此匿名类中函数式方法的方法句柄关联的调用点；而后可以通过此调用点实现调用相应Lambda表达式定义逻辑的功能。下面以如下图所示的Test类来举例说明。\n\nTest类编译后的class文件反编译后的结果如下图一所示（删除了对本文说明无意义的部分），我们可以从中看到main方法的指令实现、invokedynamic指令调用的引导方法BootstrapMethods、及静态方法lambda$main$0（实现了Lambda表达式中字符串打印逻辑）等。在引导方法执行过程中，会通过Unsafe.defineAnonymousClass生成如下图二所示的实现Consumer接口的匿名类。其中，accept方法通过调用Test类中的静态方法lambda$main$0来实现Lambda表达式中定义的逻辑。而后执行语句consumer.accept（&quot;lambda&quot;）其实就是调用下图二所示的匿名类的accept方法。\n\n对象操作此部分主要包含对象成员属性相关操作及非常规的对象实例化方式等相关方法。\n//返回对象成员属性在内存地址相对于此对象的内存地址的偏移量public native long objectFieldOffset(Field f);//获得给定对象的指定地址偏移量的值，与此类似操作还有：getInt，getDouble，getLong，getChar等public native Object getObject(Object o, long offset);//给定对象的指定地址偏移量设值，与此类似操作还有：putInt，putDouble，putLong，putChar等public native void putObject(Object o, long offset, Object x);//从对象的指定偏移量处获取变量的引用，使用volatile的加载语义public native Object getObjectVolatile(Object o, long offset);//存储变量的引用到对象的指定的偏移量处，使用volatile的存储语义public native void putObjectVolatile(Object o, long offset, Object x);//有序、延迟版本的putObjectVolatile方法，不保证值的改变被其他线程立即看到。只有在field被volatile修饰符修饰时有效public native void putOrderedObject(Object o, long offset, Object x);//绕过构造方法、初始化代码来创建对象public native Object allocateInstance(Class&lt;?&gt; cls) throws InstantiationException;\n\n典型应用\n常规对象实例化方式：我们通常所用到的创建对象的方式，从本质上来讲，都是通过new机制来实现对象的创建。但是，new机制有个特点就是当类只提供有参的构造函数且无显示声明无参构造函数时，则必须使用有参构造函数进行对象构造，而使用有参构造函数时，必须传递相应个数的参数才能完成对象实例化。\n非常规的实例化方式：而Unsafe中提供allocateInstance方法，仅通过Class对象就可以创建此类的实例对象，而且不需要调用其构造函数、初始化代码、JVM安全检查等。它抑制修饰符检测，也就是即使构造器是private修饰的也能通过此方法实例化，只需提类对象即可创建相应的对象。由于这种特性，allocateInstance在java.lang.invoke、Objenesis（提供绕过类构造器的对象生成方式）、Gson（反序列化时用到）中都有相应的应用。\n\n如下图所示，在Gson反序列化时，如果类有默认构造函数，则通过反射调用默认构造函数创建实例，否则通过UnsafeAllocator来实现对象实例的构造，UnsafeAllocator通过调用Unsafe的allocateInstance实现对象的实例化，保证在目标类无默认构造函数时，反序列化不够影响。\n\n数组相关这部分主要介绍与数据操作相关的arrayBaseOffset与arrayIndexScale这两个方法，两者配合起来使用，即可定位数组中每个元素在内存中的位置。\n//返回数组中第一个元素的偏移地址public native int arrayBaseOffset(Class&lt;?&gt; arrayClass);//返回数组中一个元素占用的大小public native int arrayIndexScale(Class&lt;?&gt; arrayClass);\n\n典型应用这两个与数据操作相关的方法，在java.util.concurrent.atomic 包下的AtomicIntegerArray（可以实现对Integer数组中每个元素的原子性操作）中有典型的应用，如下图AtomicIntegerArray源码所示，通过Unsafe的arrayBaseOffset、arrayIndexScale分别获取数组首元素的偏移地址base及单个元素大小因子scale。后续相关原子性操作，均依赖于这两个值进行数组中元素的定位，如下图二所示的getAndAdd方法即通过checkedByteOffset方法获取某数组元素的偏移地址，而后通过CAS实现原子性操作。\n\n内存屏障在Java 8中引入，用于定义内存屏障（也称内存栅栏，内存栅障，屏障指令等，是一类同步屏障指令，是CPU或编译器在对内存随机访问的操作中的一个同步点，使得此点之前的所有读写操作都执行后才可以开始执行此点之后的操作），避免代码重排序。\n//内存屏障，禁止load操作重排序。屏障前的load操作不能被重排序到屏障后，屏障后的load操作不能被重排序到屏障前public native void loadFence();//内存屏障，禁止store操作重排序。屏障前的store操作不能被重排序到屏障后，屏障后的store操作不能被重排序到屏障前public native void storeFence();//内存屏障，禁止load、store操作重排序public native void fullFence();\n\n典型应用在Java 8中引入了一种锁的新机制——StampedLock，它可以看成是读写锁的一个改进版本。StampedLock提供了一种乐观读锁的实现，这种乐观读锁类似于无锁的操作，完全不会阻塞写线程获取写锁，从而缓解读多写少时写线程“饥饿”现象。由于StampedLock提供的乐观读锁不阻塞写线程获取读锁，当线程共享变量从主内存load到线程工作内存时，会存在数据不一致问题，所以当使用StampedLock的乐观读锁时，需要遵从如下图用例中使用的模式来确保数据的一致性。\n\n如上图用例所示计算坐标点Point对象，包含点移动方法move及计算此点到原点的距离的方法distanceFromOrigin。在方法distanceFromOrigin中，首先，通过tryOptimisticRead方法获取乐观读标记；然后从主内存中加载点的坐标值 (x,y)；而后通过StampedLock的validate方法校验锁状态，判断坐标点(x,y)从主内存加载到线程工作内存过程中，主内存的值是否已被其他线程通过move方法修改，如果validate返回值为true，证明(x, y)的值未被修改，可参与后续计算；否则，需加悲观读锁，再次从主内存加载(x,y)的最新值，然后再进行距离计算。其中，校验锁状态这步操作至关重要，需要判断锁状态是否发生改变，从而判断之前copy到线程工作内存中的值是否与主内存的值存在不一致。\n下图为StampedLock.validate方法的源码实现，通过锁标记与相关常量进行位运算、比较来校验锁状态，在校验逻辑之前，会通过Unsafe的loadFence方法加入一个load内存屏障，目的是避免上图用例中步骤②和StampedLock.validate中锁状态校验运算发生重排序导致锁状态校验不准确的问题。\n\n系统相关这部分包含两个获取系统相关信息的方法。\n//返回系统指针的大小。返回值为4（32位系统）或 8（64位系统）。public native int addressSize();//内存页的大小，此值为2的幂次方。public native int pageSize();\n\n典型应用如下图所示的代码片段，为java.nio下的工具类Bits中计算待申请内存所需内存页数量的静态方法，其依赖于Unsafe中pageSize方法获取系统内存页大小实现后续计算逻辑。\n\n结语本文对Java中的sun.misc.Unsafe的用法及应用场景进行了基本介绍，我们可以看到Unsafe提供了很多便捷、有趣的API方法。即便如此，由于Unsafe中包含大量自主操作内存的方法，如若使用不当，会对程序带来许多不可控的灾难。因此对它的使用我们需要慎之又慎。\n","tags":["Java"]},{"title":"Java命名规范参考","url":"/2020/03/23/Java%E5%91%BD%E5%90%8D%E8%A7%84%E8%8C%83%E5%8F%82%E8%80%83/","content":"\n转自：https://mp.weixin.qq.com/s/O7U4XU-4QysmvL6cRfVfvw\n\n一，Java中的命名规范好的命名能体现出代码的特征，含义或者是用途，让阅读者可以根据名称的含义快速厘清程序的脉络。不同语言中采用的命名形式大相径庭，Java中常用到的命名形式共有三种，既首字母大写的UpperCamelCase，首字母小写的lowerCamelCase以及全部大写的并用下划线分割单词的UPPERCAMELUNSER_SCORE。通常约定，类一般采用大驼峰命名，方法和局部变量使用小驼峰命名，而大写下划线命名通常是常量和枚举中使用。\n\n\n\n类型(名)\n约束\n例\n\n\n\n项目\n全部小写 多个单词用中划线分隔‘-’\nspring-cloud\n\n\n包\n全部小写\ncom.alibaba.fastjson\n\n\n类\n单词首字母大写\nFeature, FieldDeserializer\n\n\n变量\n首字母小写 多个单词组成时， 除首个单词 其他单词首字母都要大写\npassword,  userName\n\n\n常量\n全部大写，多个单词，用’_’分隔\nCACHEEXPIREDTIME\n\n\n方法\n同变量\nread(),  getById(Long id)\n\n\n二，包命名包名统一使用小写，点分隔符之间有且仅有一个自然语义的英文单词或者多个单词自然连接到一块（如 springframework，deepspace不需要使用任何分割）。包名统一使用单数形式，如果类命有复数含义，则可以使用复数形式。\n包名的构成可以分为以下几四部分【前缀】 【发起者名】【项目名】【模块名】。常见的前缀可以分为以下几种：\n\n\n\n前缀\n例\n含义\n\n\n\nindi 或 onem\nindi.发起者名.项目名.模块名.……\n个体项目 个人发起，但非自己独自完成 可公开或私有项目， copyright主要属于发起者。\n\n\npers\npers.个人名.项目名.模块名.……\n个人项目 指个人发起，独自完成， 可分享的项目 copyright主要属于个人\n\n\npriv\npriv.个人名.项目名.模块名.……\n私有项目，指个人发起，独自完成 非公开的私人使用的项目， copyright属于个人。\n\n\nteam\nteam.团队名.项目名.模块名.……\n团队项目，指由团队发起 并由该团队开发的项目 copyright属于该团队所有\n\n\n顶级域名\ncom.公司名.项目名.模块名.……\n公司项目 copyright由项目发起的公司所有\n\n\n三，类命名类名使用大驼峰命名形式，类命通常时名词或名词短语，接口名除了用名词和名词短语以外，还可以使用形容词或形容词短语，如Cloneable，Callable等，表示实现该接口的类有某种功能或能力。对于测试类则以它要测试的类开头，以Test结尾，如HashMapTest。\n对于一些特殊特有名词缩写也可以使用全大写命名，比如XMLHttpRequest，不过笔者认为缩写三个字母以内都大写，超过三个字母则按照要给单词算。这个没有标准如阿里巴巴中fastjson用JSONObject作为类命，而google则使用JsonObjectRequest命名，对于这种特殊的缩写，原则是统一就好。\n\n\n\n属性(类)\n约束\n例\n\n\n\n抽象\nAbstract  或 Base 开头\nBaseUserService\n\n\n枚举\nEnum 作为后缀\nOSType\n\n\n工具\nUtils作为后缀\nStringUtils\n\n\n异常\nException结尾\nRuntimeException\n\n\n接口实现\n接口名+ Impl\nUserServiceImpl\n\n\n领域模型相\n/DO/DTO/VO/DAO\n正例：UserDAO 反例：UserDao\n\n\n设计模式相关\nBuilder，Factory等\n当使用到设计模式时 要使用对应的设计模式作为后缀 如ThreadFactory\n\n\n处理特定功能\nHandler，Predicate Validator\n表示处理器，校验器，断言 这些类工厂还有配套的方法名 如handle，predicate，validate\n\n\n测试\nTest后缀\nUserServiceTest 表示用来测试UserService类的\n\n\nMVC分层\nController，Service ServiceImpl，DAO 后缀\nUserManageController UserManageDAO\n\n\n四，方法方法命名采用小驼峰的形式，首字小写，往后的每个单词首字母都要大写。和类名不同的是，方法命名一般为动词或动词短语，与参数或参数名共同组成动宾短语，即动词 + 名词。一个好的函数名一般能通过名字直接获知该函数实现什么样的功能。\n4.1 返回真伪值的方法注：pre- prefix前缀，suf- suffix后缀，alo-alone 单独使用\n\n\n\n位置\n单词\n意义\n例\n\n\n\npre\nis\n对象是否符合期待的状态\nisValid\n\n\npre\ncan\n对象能否执行所期待的动作\ncanRemove\n\n\npre\nshould\n调用方执行某个命令 或方法是好还是不好 应不应该， 或者说推荐还是不推荐\nshouldMigrate\n\n\npre\nhas\n对象是否持有 所期待的数据和属性\nhasObservers\n\n\npre\nneeds\n调用方是否需要 执行某个命令或方法\nneedsMigrate\n\n\n4.2 用来检查的方法\n\n\n单词\n意义\n例\n\n\n\nensure\n检查是否为期待的状态 不是则抛出异常或返回error code\nensureCapacity\n\n\nvalidate\n检查是否为正确的状态 不是则抛出异常或返回error code\nvalidateInputs\n\n\n4.3 按需求才执行的方法\n\n\n位置\n单词\n意义\n例\n\n\n\nsuf\nIfNeeded\n需要的时候执行 不需要则什么都不做\ndrawIfNeeded\n\n\npre\nmight\n同上\nmightCreate\n\n\npre\ntry\n尝试执行 失败时抛出异常 或是返回errorcode\ntryCreate\n\n\nsuf\nOrDefault\n尝试执行 失败时返回默认值\ngetOrDefault\n\n\nsuf\nOrElse\n尝试执行 失败时返回 实际参数中指定的值\ngetOrElse\n\n\npre\nforce\n强制尝试执行 error抛出异常或是返回值\nforceCreate,  forceStop\n\n\n4.4 异步相关方法\n\n\n位置\n单词\n意义\n例\n\n\n\npre\nblocking\n线程阻塞方法\nblockingGetUser\n\n\nsuf\nInBackground\n执行在后台线程\ndoInBackground\n\n\nsuf\nAsync\n异步方法\nsendAsync\n\n\nsuf\nSync\n同步方法\nsendSync\n\n\npre / alo\nschedule\nJob和Tas k放入队列\nschedule,  scheduleJob\n\n\npre / alo\npost\n同上\npostJob\n\n\npre / alo\nexecute\n执行异步 或同步方法\nexecute, executeTask\n\n\npre / alo\nstart\n同上\nstar, tstartJob\n\n\npre / alo\ncancel\n停止异步方法\ncance, cancelJob\n\n\npre / alo\nstop\n同上\nstop,stopJob\n\n\n4.5 回调方法\n\n\n位置\n单词\n意义\n例\n\n\n\npre\non\n事件发生时执行\nonCompleted\n\n\npre\nbefore\n事件发生前执行\nbeforeUpdate\n\n\npre\npre\n同上\npreUpdate\n\n\npre\nwill\n同上\nwillUpdate\n\n\npre\nafter\n事件发生后执行\nafterUpdate\n\n\npre\npost\n同上\npostUpdate\n\n\npre\ndid\n同上\ndidUpdate\n\n\npre\nshould\n确认事件 是否可以执行\nshouldUpdate\n\n\n4.6 操作对象生命周期的方法\n\n\n单词\n意义\n例\n\n\n\ninitialize\n初始化或延迟初始化使用\ninitialize\n\n\npause\n暂停\nonPause , pause\n\n\nstop\n停止\nonStop, stop\n\n\nabandon\n销毁的替代\nabandon\n\n\ndestroy\n同上\ndestroy\n\n\ndispose\n同上\ndispose\n\n\n4.7 与集合操作相关的方法\n\n\n单词\n意义\n例\n\n\n\ncontains\n是包含指定对象相同的对象\ncontains\n\n\nadd\n添加\naddJob\n\n\nappend\n添加\nappendJob\n\n\ninsert\n插入到下标n\ninsertJob\n\n\nput\n添加与key对应的元素\nputJob\n\n\nremove\n移除元素\nremoveJob\n\n\nenqueue\n添加到队列的最末位\nenqueueJob\n\n\ndequeue\n从队列中头部取出并移除\ndequeueJob\n\n\npush\n添加到栈头\npushJob\n\n\npop\n从栈头取出并移除\npopJob\n\n\npeek\n从栈头取出但不移除\npeekJob\n\n\nfind\n寻找符合条件的某物\nfindById\n\n\n4.8 与数据相关的方法\n\n\n单词\n意义\n例\n\n\n\ncreate\n新创建\ncreateAccount\n\n\nnew\n新创建\nnewAccount\n\n\nfrom\n从既有的某物新建 或是从其他的数据新建\nfromConfig\n\n\nto\n转换\ntoString\n\n\nupdate\n更新既有某物\nupdateAccount\n\n\nload\n读取\nloadAccount\n\n\nfetch\n远程读取\nfetchAccount\n\n\ndelete\n删除\ndeleteAccount\n\n\nremove\n删除\nremoveAccount\n\n\nsave\n保存\nsaveAccount\n\n\nstore\n保存\nstoreAccount\n\n\ncommit\n保存\ncommitChange\n\n\napply\n保存或应用\napplyChange\n\n\nclear\n清除或是恢复到初始状态\nclearAll\n\n\nreset\n清除或是恢复到初始状态\nresetAll\n\n\n4.9 成对出现的动词\n\n\n单词\n意义\n\n\n\nget获取\nset 设置\n\n\nadd 增加\nremove 删除\n\n\ncreate 创建\ndestory 移除\n\n\nstart 启动\nstop 停止\n\n\nopen 打开\nclose 关闭\n\n\nread 读取\nwrite 写入\n\n\nload 载入\nsave 保存\n\n\ncreate 创建\ndestroy 销毁\n\n\nbegin 开始\nend 结束\n\n\nbackup 备份\nrestore 恢复\n\n\nimport 导入\nexport 导出\n\n\nsplit 分割\nmerge 合并\n\n\ninject 注入\nextract 提取\n\n\nattach 附着\ndetach 脱离\n\n\nbind 绑定\nseparate 分离\n\n\nview 查看\nbrowse 浏览\n\n\nedit 编辑\nmodify 修改\n\n\nselect 选取\nmark 标记\n\n\ncopy 复制\npaste 粘贴\n\n\nundo 撤销\nredo 重做\n\n\ninsert 插入\ndelete 移除\n\n\nadd 加入\nappend 添加\n\n\nclean 清理\nclear 清除\n\n\nindex 索引\nsort 排序\n\n\nfind 查找\nsearch 搜索\n\n\nincrease 增加\ndecrease 减少\n\n\nplay 播放\npause 暂停\n\n\nlaunch 启动\nrun 运行\n\n\ncompile 编译\nexecute 执行\n\n\ndebug 调试\ntrace 跟踪\n\n\nobserve 观察\nlisten 监听\n\n\nbuild 构建\npublish 发布\n\n\ninput 输入\noutput 输出\n\n\nencode 编码\ndecode 解码\n\n\nencrypt 加密\ndecrypt 解密\n\n\ncompress 压缩\ndecompress 解压缩\n\n\npack 打包\nunpack 解包\n\n\nparse 解析\nemit 生成\n\n\nconnect 连接\ndisconnect 断开\n\n\nsend 发送\nreceive 接收\n\n\ndownload 下载\nupload 上传\n\n\nrefresh 刷新\nsynchronize 同步\n\n\nupdate 更新\nrevert 复原\n\n\nlock 锁定\nunlock 解锁\n\n\ncheck out 签出\ncheck in 签入\n\n\nsubmit 提交\ncommit 交付\n\n\npush 推\npull 拉\n\n\nexpand 展开\ncollapse 折叠\n\n\nbegin 起始\nend 结束\n\n\nstart 开始\nfinish 完成\n\n\nenter 进入\nexit 退出\n\n\nabort 放弃\nquit 离开\n\n\nobsolete 废弃\ndepreciate 废旧\n\n\ncollect 收集\naggregate 聚集\n\n\n五，变量&amp;常量命名5.1 变量命名变量是指在程序运行中可以改变其值的量，包括成员变量和局部变量。变量名由多单词组成时，第一个单词的首字母小写，其后单词的首字母大写，俗称骆驼式命名法（也称驼峰命名法），如 computedValues，index，变量命名时，尽量简短且能清楚的表达变量的作用，命名体现具体的业务含义即可。\n变量名不应以下划线或美元符号开头，尽管这在语法上是允许的。变量名应简短且富于描述。变量名的选用应该易于记忆，即，能够指出其用途。尽量避免单个字符的变量名，除非是一次性的临时变量。pojo中的布尔变量，都不要加is(数据库中的布尔字段全都要加 is_ 前缀)。\n5.2 常量命名常量命名CONSTANT_CASE，一般采用全部大写（作为方法参数时除外），单词间用下划线分割。那么什么是常量呢？\n常量是在作用域内保持不变的值，一般使用final进行修饰。一般分为三种，全局常量（public static final修饰），类内常量（private static final 修饰）以及局部常量（方法内，或者参数中的常量），局部常量比较特殊，通常采用小驼峰命名即可。\n/** * 一个demo * @author Jann Lee * @date 2019-12-07 00:25 **/public class HelloWorld &#123;    /**     * 局部常量(正例)     */    public static final long USER_MESSAGE_CACHE_EXPIRE_TIME = 3600;    /**     * 局部常量(反例，命名不清晰）     */    public static final long MESSAGE_CACHE_TIME = 3600;    /**     * 全局常量     */    private static final String ERROR_MESSAGE = \" error message\";    /**     * 成员变量     */    private int currentUserId;    /**     * 控制台打印 &#123;@code message&#125; 信息     * @param message 消息体，局部常量     */    public void sayHello(final String message) &#123;        System.out.println(\"Hello world!\");    &#125;&#125;\n\n常量一般都有自己的业务含义,不要害怕长度过长而进行省略或者缩写。如，用户消息缓存过期时间的表示，那种方式更佳清晰，交给你来评判。更多BAT经验文章，可以在订阅号“码匠笔记”后台回复“经验”，N+1篇热文免费获取。\n通用命名规则\n尽量不要使用拼音；杜绝拼音和英文混用。对于一些通用的表示或者难以用英文描述的可以采用拼音，一旦采用拼音就坚决不能和英文混用。正例：BeiJing，HangZhou 反例：validateCanShu\n命名过程中尽量不要出现特殊的字符，常量除外。\n尽量不要和jdk或者框架中已存在的类重名，也不能使用java中的关键字命名。\n妙用介词，如for(可以用同音的4代替), to(可用同音的2代替)，from，with，of等。如类名采用User4RedisDO，方法名getUserInfoFromRedis，convertJson2Map等。\n\n六，代码注解6.1 注解的原则好的命名增加代码阅读性，代码的命名往往有严格的限制。而注解不同，程序员往往可以自由发挥，单并不意味着可以为所欲为之胡作非为。优雅的注解通常要满足三要素。\n\nNothing is strange 没有注解的代码对于阅读者非常不友好，哪怕代码写的在清除，阅读者至少从心理上会有抵触，更何况代码中往往有许多复杂的逻辑，所以一定要写注解，不仅要记录代码的逻辑，还有说清楚修改的逻辑。\nLess is more 从代码维护角度来讲，代码中的注解一定是精华中的精华。合理清晰的命名能让代码易于理解，对于逻辑简单且命名规范，能够清楚表达代码功能的代码不需要注解。滥用注解会增加额外的负担，更何况大部分都是废话。\n\n// 根据id获取信息【废话注解】getMessageById(id)\n\n\nAdvance with the time 注解应该随着代码的变动而改变，注解表达的信息要与代码中完全一致。通常情况下修改代码后一定要修改注解。\n\n6.2 注解格式注解大体上可以分为两种，一种是javadoc注解，另一种是简单注解。javadoc注解可以生成JavaAPI为外部用户提供有效的支持javadoc注解通常在使用IDEA，或者Eclipse等开发工具时都可以自动生成，也支持自定义的注解模板，仅需要对对应的字段进行解释。参与同一项目开发的同学，尽量设置成相同的注解模板。\na. 包注解包注解在工作中往往比较特殊，通过包注解可以快速知悉当前包下代码是用来实现哪些功能，强烈建议工作中加上，尤其是对于一些比较复杂的包，包注解一般在包的根目录下，名称统一为package-info.java。\n/** * 落地也质量检测 * 1. 用来解决什么问题对广告主投放的广告落地页进行性能检测，模拟不同的系统，如Android，IOS等; 模拟不同的网络：2G，3G，4G，wifi等 * 2. 如何实现基于chrome浏览器，用chromedriver驱动浏览器，设置对应的网络，OS参数，获取到浏览器返回结果。 * 注意：网络环境配置信息&#123;@link cn.mycookies.landingpagecheck.meta.NetWorkSpeedEnum&#125;目前使用是常规速度，可以根据实际情况进行调整 * * @author cruder * @time 2019/12/7 20:3 下午 */package cn.mycookies.landingpagecheck;\n\nb. 类注接javadoc注解中，每个类都必须有注解。\n/*** Copyright (C), 2019-2020, Jann  balabala...** 类的介绍：这是一个用来做什么事情的类，有哪些功能，用到的技术.....** @author   类创建者姓名 保持对齐* @date     创建日期 保持对齐* @version  版本号 保持对齐*/\n\nc. 属性注解在每个属性前面必须加上属性注释，通常有一下两种形式，至于怎么选择，你高兴就好，不过一个项目中要保持统一。\n/** 提示信息 */private String userName;/** * 密码 */private String password;\n\nd. 方法注释在每个方法前面必须加上方法注释，对于方法中的每个参数，以及返回值都要有说明。\n/**  * 方法的详细说明，能干嘛，怎么实现的，注意事项...  *  * @param xxx      参数1的使用说明， 能否为null  * @return 返回结果的说明， 不同情况下会返回怎样的结果  * @throws 异常类型   注明从此类方法中抛出异常的说明  */\n\ne. 构造方法注释在每个构造方法前面必须加上注释，注释模板如下：\n/**  * 构造方法的详细说明  *  * @param xxx      参数1的使用说明， 能否为null  * @throws 异常类型   注明从此类方法中抛出异常的说明  */\n\n而简单注解往往是需要工程师字节定义，在使用注解时应该注意一下几点：\n\n枚举类的各个属性值都要使用注解，枚举可以理解为是常量，通常不会发生改变，通常会被在多个地方引用，对枚举的修改和添加属性通常会带来很大的影响。\n保持排版整洁，不要使用行尾注释；双斜杠和星号之后要用1个空格分隔。\n\nint id = 1; // 反例：不要使用行尾注释//反例：换行符与注释之间没有缩进int age = 18;// 正例：姓名String name;/**  * 1. 多行注释  *  * 2. 对于不同的逻辑说明，可以用空行分隔  */\n\n总结无论是命名和注解，他们的目的都是为了让代码和工程师进行对话，增强代码的可读性，可维护性。优秀的代码往往能够见名知意，注解往往是对命名的补充和完善。命名太难了！\n","tags":["Java"]},{"title":"Java应用性能调优实践","url":"/2020/07/21/Java%E5%BA%94%E7%94%A8%E6%80%A7%E8%83%BD%E8%B0%83%E4%BC%98%E5%AE%9E%E8%B7%B5/","content":"概述Java 应用性能优化是一个老生常谈的话题，典型的性能问题如页面响应慢、接口超时，服务器负载高、并发数低，数据库频繁死锁等。尤其是在”糙快猛”的互联网开发模式大行其道的今天，随着系统访问量的日益增加和代码的臃肿，各种性能问题开始纷至沓来。Java 应用性能的瓶颈点非常多，比如磁盘、内存、网络 I/O 等系统因素，Java 应用代码，JVM GC，数据库，缓存等。笔者根据个人经验，将 Java 性能优化分为 4 个层级：应用层、数据库层、框架层、JVM 层，如图 1 所示。\n\n图 1.Java 性能优化分层模型\n\n每层优化难度逐级增加，涉及的知识和解决的问题也会不同。比如应用层需要理解代码逻辑，通过 Java 线程栈定位有问题代码行等；数据库层面需要分析 SQL、定位死锁等；框架层需要懂源代码，理解框架机制；JVM 层需要对 GC 的类型和工作机制有深入了解，对各种 JVM 参数作用了然于胸。\n围绕 Java 性能优化，有两种最基本的分析方法：现场分析法和事后分析法。现场分析法通过保留现场，再采用诊断工具分析定位。现场分析对线上影响较大，部分场景（特别是涉及到用户关键的在线业务时）不太合适。事后分析法需要尽可能多收集现场数据，然后立即恢复服务，同时针对收集的现场数据进行事后分析和复现。下面我们从性能诊断工具出发，分享搜狗商业平台在其中的一些案例与实践。\n性能诊断工具性能诊断一种是针对已经确定有性能问题的系统和代码进行诊断，还有一种是对预上线系统提前性能测试，确定性能是否符合上线要求。本文主要针对前者，后者可以用各种性能压测工具（例如 JMeter）进行测试，不在本文讨论范围内。针对 Java 应用，性能诊断工具主要分为两层：OS 层面和 Java 应用层面（包括应用代码诊断和 GC 诊断）。\nOS 诊断OS 的诊断主要关注的是 CPU、Memory、I/O 三个方面。\nCPU 诊断对于 CPU 主要关注平均负载（Load Average），CPU 使用率，上下文切换次数（Context Switch）。\n通过 top 命令可以查看系统平均负载和 CPU 使用率，图 2 为通过 top 命令查看某系统的状态。\n\n图 2.top 命令示例\n\n平均负载有三个数字：63.66，58.39，57.18，分别表示过去 1 分钟、5 分钟、15 分钟机器的负载。按照经验，若数值小于 0.7*CPU 个数，则系统工作正常；若超过这个值，甚至达到 CPU 核数的四五倍，则系统的负载就明显偏高。图 2 中 15 分钟负载已经高达 57.18，1 分钟负载是 63.66（系统为 16 核），说明系统出现负载问题，且存在进一步升高趋势，需要定位具体原因了。\n通过 vmstat 命令可以查看 CPU 的上下文切换次数，如图 3 所示：\n\n图 3.vmstat 命令示例\n\n上下文切换次数发生的场景主要有如下几种：1）时间片用完，CPU 正常调度下一个任务；2）被其它优先级更高的任务抢占；3）执行任务碰到 I/O 阻塞，挂起当前任务，切换到下一个任务；4）用户代码主动挂起当前任务让出 CPU；5）多任务抢占资源，由于没有抢到被挂起；6）硬件中断。Java 线程上下文切换主要来自共享资源的竞争。一般单个对象加锁很少成为系统瓶颈，除非锁粒度过大。但在一个访问频度高，对多个对象连续加锁的代码块中就可能出现大量上下文切换，成为系统瓶颈。比如在我们系统中就曾出现 log4j 1.x 在较大并发下大量打印日志，出现频繁上下文切换，大量线程阻塞，导致系统吞吐量大降的情况，其相关代码如清单 1 所示，升级到 log4j 2.x 才解决这个问题。\n\n清单 1. log4j 1.x 同步代码片段\n\nfor(Category c = this; c != null; c=c.parent) &#123;    // Protected against simultaneous call to addAppender, removeAppender,...    synchronized(c) &#123;        if (c.aai != null) &#123;            write += c.aai.appendLoopAppenders(event);        &#125;        ...    &#125;&#125;\n\nMemory从操作系统角度，内存关注应用进程是否足够，可以使用 free –m 命令查看内存的使用情况。通过 top 命令可以查看进程使用的虚拟内存 VIRT 和物理内存 RES，根据公式 VIRT = SWAP + RES 可以推算出具体应用使用的交换分区（Swap）情况，使用交换分区过大会影响 Java 应用性能，可以将 swappiness 值调到尽可能小。因为对于 Java 应用来说，占用太多交换分区可能会影响性能，毕竟磁盘性能比内存慢太多。\nI/OI/O 包括磁盘 I/O 和网络 I/O，一般情况下磁盘更容易出现 I/O 瓶颈。通过 iostat 可以查看磁盘的读写情况，通过 CPU 的 I/O wait 可以看出磁盘 I/O 是否正常。如果磁盘 I/O 一直处于很高的状态，说明磁盘太慢或故障，成为了性能瓶颈，需要进行应用优化或者磁盘更换。\n除了常用的 top、 ps、vmstat、iostat 等命令，还有其他 Linux 工具可以诊断系统问题，如 mpstat、tcpdump、netstat、pidstat、sar 等。Brendan 总结列出了 Linux 不同设备类型的性能诊断工具，如图 4 所示，可供参考。\n\n图 4.Linux 性能观测工具\n\n\nJava 应用诊断工具应用代码诊断应用代码性能问题是相对好解决的一类性能问题。通过一些应用层面监控报警，如果确定有问题的功能和代码，直接通过代码就可以定位；或者通过 top+jstack，找出有问题的线程栈，定位到问题线程的代码上，也可以发现问题。对于更复杂，逻辑更多的代码段，通过 Stopwatch 打印性能日志往往也可以定位大多数应用代码性能问题。\n常用的 Java 应用诊断包括线程、堆栈、GC 等方面的诊断。\njstackjstack 命令通常配合 top 使用，通过 top -H -p pid 定位 Java 进程和线程，再利用 jstack -l pid 导出线程栈。由于线程栈是瞬态的，因此需要多次 dump，一般 3 次 dump，一般每次隔 5s 就行。将 top 定位的 Java 线程 pid 转成 16 进制，得到 Java 线程栈中的 nid，可以找到对应的问题线程栈。\n\n图 5. 通过 top –H -p 查看运行时间较长 Java 线程\n\n如图 5 所示，其中的线程 24985 运行时间较长，可能存在问题，转成 16 进制后，通过 Java 线程栈找到对应线程 0x6199 的栈如下，从而定位问题点，如图 6 所示。\n\n图 6.jstack 查看线程堆栈\n\n\nJProfilerJProfiler 可对 CPU、堆、内存进行分析，功能强大，如图 7 所示。同时结合压测工具，可以对代码耗时采样统计。\n\n图 7. 通过 JProfiler 进行内存分析\n\n\nGC 诊断Java GC 解决了程序员管理内存的风险，但 GC 引起的应用暂停成了另一个需要解决的问题。JDK 提供了一系列工具来定位 GC 问题，比较常用的有 jstat、jmap，还有第三方工具 MAT 等。\njstatjstat 命令可打印 GC 详细信息，Young GC 和 Full GC 次数，堆信息等。其命令格式为\njstat –gcxxx -t pid ，如图 8 所示。\n\n图 8.jstat 命令示例\n\n\njmapjmap 打印 Java 进程堆信息 jmap –heap pid。通过 jmap –dump:file=xxx pid 可 dump 堆到文件，然后通过其它工具进一步分析其堆使用情况\nMATMAT 是 Java 堆的分析利器，提供了直观的诊断报告，内置的 OQL 允许对堆进行类 SQL 查询，功能强大，outgoing reference 和 incoming reference 可以对对象引用追根溯源。\n\n图 9.MAT 示例\n\n图 9 是 MAT 使用示例，MAT 有两列显示对象大小，分别是 Shallow size 和 Retained size，前者表示对象本身占用内存的大小，不包含其引用的对象，后者是对象自己及其直接或间接引用的对象的 Shallow size 之和，即该对象被回收后 GC 释放的内存大小，一般说来关注后者大小即可。对于有些大堆 (几十 G) 的 Java 应用，需要较大内存才能打开 MAT。通常本地开发机内存过小，是无法打开的，建议在线下服务器端安装图形环境和 MAT，远程打开查看。或者执行 mat 命令生成堆索引，拷贝索引到本地，不过这种方式看到的堆信息有限。\n为了诊断 GC 问题，建议在 JVM 参数中加上-XX:+PrintGCDateStamps。常用的 GC 参数如图 10 所示。\n\n图 10. 常用 GC 参数\n\n对于 Java 应用，通过 top+jstack+jmap+MAT 可以定位大多数应用和内存问题，可谓必备工具。有些时候，Java 应用诊断需要参考 OS 相关信息，可使用一些更全面的诊断工具，比如 Zabbix（整合了 OS 和 JVM 监控）等。在分布式环境中，分布式跟踪系统等基础设施也对应用性能诊断提供了有力支持。\n性能优化实践在介绍了一些常用的性能诊断工具后，下面将结合我们在 Java 应用调优中的一些实践，从 JVM 层、应用代码层以及数据库层进行案例分享。\nJVM 调优：GC 之痛搜狗商业平台某系统重构时选择 RMI 作为内部远程调用协议，系统上线后开始出现周期性的服务停止响应，暂停时间由数秒到数十秒不等。通过观察 GC 日志，发现服务自启动后每小时会出现一次 Full GC。由于系统堆设置较大，Full GC 一次暂停应用时间会较长，这对线上实时服务影响较大。经过分析，在重构前系统没有出现定期 Full GC 的情况，因此怀疑是 RMI 框架层面的问题。通过公开资料，发现 RMI 的 GDC（Distributed Garbage Collection，分布式垃圾收集）会启动守护线程定期执行 Full GC 来回收远程对象，清单 2 中展示了其守护线程代码。\n\n清单 2.DGC 守护线程源代码\n\nprivate static class Daemon extends Thread &#123;    public void run() &#123;        for (;;) &#123;            //...            long d = maxObjectInspectionAge();            if (d &gt;= l) &#123;                System.gc();                d = 0;            &#125;            //...        &#125;    &#125;&#125;\n\n显示更多\n定位问题后解决起来就比较容易了。一种是通过增加-XX:+DisableExplicitGC 参数，直接禁用系统 GC 的显示调用，但对使用 NIO 的系统，会有堆外内存溢出的风险。另一种方式是通过调大 -Dsun.rmi.dgc.server.gcInterval 和-Dsun.rmi.dgc.client.gcInterval 参数，增加 Full GC 间隔，同时增加参数-XX:+ExplicitGCInvokesConcurrent，将一次完全 Stop-The-World 的 Full GC 调整为一次并发 GC 周期，减少应用暂停时间，同时对 NIO 应用也不会造成影响。从图 11 可知，调整之后的 Full GC 次数 在 3 月之后明显减少。\n\n图 11.Full GC 监控统计\n\nGC 调优对高并发大数据量交互的应用还是很有必要的，尤其是默认 JVM 参数通常不满足业务需求，需要进行专门调优。GC 日志的解读有很多公开的资料，本文不再赘述。GC 调优目标基本有三个思路：降低 GC 频率，可以通过增大堆空间，减少不必要对象生成；降低 GC 暂停时间，可以通过减少堆空间，使用 CMS GC 算法实现；避免 Full GC，调整 CMS 触发比例，避免 Promotion Failure 和 Concurrent mode failure（老年代分配更多空间，增加 GC 线程数加快回收速度），减少大对象生成等。\n应用层调优：嗅到代码的坏味道从应用层代码调优入手，剖析代码效率下降的根源，无疑是提高 Java 应用性能的很好的手段之一。\n某商业广告系统（采用 Nginx 进行负载均衡）某次日常上线后，其中有几台机器负载急剧升高，CPU 使用率迅速打满。我们对线上进行了紧急回滚，并通过 jmap 和 jstack 对其中某台服务器的现场进行保存。\n\n图 12. 通过 MAT 分析堆栈现场\n\n堆栈现场如图 12 所示，根据 MAT 对 dump 数据的分析，发现最多的内存对象为 byte[] 和 java.util.HashMap $Entry，且 java.util.HashMap $Entry 对象存在循环引用。初步定位在该 HashMap 的 put 过程中有可能出现了死循环问题（图中 java.util.HashMap $Entry 0x2add6d992cb8 和 0x2add6d992ce8 的 next 引用形成循环）。查阅相关文档定位这属于典型的并发使用的场景错误 (http://bugs.java.com/bugdatabase/view_bug.do?bug_id=6423457) ，简要的说就是 HashMap 本身并不具备多线程并发的特性，在多个线程同时 put 操作的情况下，内部数组进行扩容时会导致 HashMap 的内部链表形成环形结构，从而出现死循环。\n针对此次上线，最大的改动在于通过内存缓存网站数据来提升系统性能，同时使用了懒加载机制，如清单 3 所示。\n\n清单 3. 网站数据懒加载代码\n\nprivate static Map&lt;Long, UnionDomain&gt; domainMap = new HashMap&lt;Long, UnionDomain&gt;();private boolean isResetDomains() &#123;    if (CollectionUtils.isEmpty(domainMap)) &#123;        // 从远端 http 接口获取网站详情        List&lt;UnionDomain&gt; newDomains = unionDomainHttpClient            .queryAllUnionDomain();        if (CollectionUtils.isEmpty(domainMap)) &#123;            domainMap = new HashMap&lt;Long, UnionDomain&gt;();            for (UnionDomain domain : newDomains) &#123;                if (domain != null) &#123;                    domainMap.put(domain.getSubdomainId(), domain);                &#125;            &#125;        &#125;        return true;    &#125;    return false;&#125;\n\n显示更多\n可以看到此处的 domainMap 为静态共享资源，它是 HashMap 类型，在多线程情况下会导致其内部链表形成环形结构，出现死循环。\n通过对前端 Nginx 的连接和访问日志可以看到，由于在系统重启后 Nginx 积攒了大量的用户请求，在 Resin 容器启动，大量用户请求涌入应用系统，多个用户同时进行网站数据的请求和初始化工作，导致 HashMap 出现并发问题。在定位故障原因后解决方法则比较简单，主要的解决方法有：\n（1）采用 ConcurrentHashMap 或者同步块的方式解决上述并发问题;\n（2）在系统启动前完成网站缓存加载，去除懒加载等；\n（3）采用分布式缓存替换本地缓存等。\n对于坏代码的定位，除了常规意义上的代码审查外，借助诸如 MAT 之类的工具也可以在一定程度对系统性能瓶颈点进行快速定位。但是一些与特定场景绑定或者业务数据绑定的情况，却需要辅助代码走查、性能检测工具、数据模拟甚至线上引流等方式才能最终确认性能问题的出处。以下是我们总结的一些坏代码可能的一些特征，供大家参考：\n（1）代码可读性差，无基本编程规范；\n（2）对象生成过多或生成大对象，内存泄露等；\n（3）IO 流操作过多，或者忘记关闭；\n（4）数据库操作过多，事务过长;\n（5）同步使用的场景错误;\n（6）循环迭代耗时操作等。\n数据库层调优：死锁噩梦对于大部分 Java 应用来说，与数据库进行交互的场景非常普遍，尤其是 OLTP 这种对于数据一致性要求较高的应用，数据库的性能会直接影响到整个应用的性能。搜狗商业平台系统作为广告主的广告发布和投放平台，对其物料的实时性和一致性都有极高的要求，我们在关系型数据库优化方面也积累了一定的经验。\n对于广告物料库来说，较高的操作频繁度（特别是通过批量物料工具操作）很极易造成数据库的死锁情况发生，其中一个比较典型的场景是广告物料调价。客户往往会频繁的对物料的出价进行调整，从而间接给数据库系统造成较大的负载压力，也加剧了死锁发生的可能性。下面以搜狗商业平台某广告系统广告物料调价的案例进行说明。\n某商业广告系统某天访问量突增，造成系统负载升高以及数据库频繁死锁，死锁语句如图 13 所示。\n\n图 13. 死锁语句\n\n其中，groupdomain 表上索引为 idx_groupdomain_accountid (accountid)，idx_groupdomain_groupid(groupid)，primary(groupdomainid) 三个单索引结构，采用 Mysql innodb 引擎。\n此场景发生在更新组出价时，场景中存在着组、组行业（groupindus 表）和组网站（groupdomain 表）。当更新组出价时，若组行业出价使用组出价（通过 isusegroupprice 标示，若为 1 则使用组出价）。同时若组网站出价使用组行业出价（通过 isuseindusprice 标示，若为 1 则使用组行业出价）时，也需要同时更新其组网站出价。由于每个组下面最大可以有 3000 个网站，因此在更新组出价时会长时间的对相关记录进行锁定。从上面发生死锁的问题可以看到，事务 1 和事务 2 均选择了 idx_groupdomain_accountid 的单列索引。根据 Mysql innodb 引擎加锁的特点，在一次事务中只会选择一个索引使用，而且如果一旦使用二级索引进行加锁后，会尝试将主键索引进行加锁。进一步分析可知事务 1 在请求事务 2 持有的idx_groupdomain_accountid二级索引加锁（加锁范围”space id 5726 page no 8658 n bits 824 index”），但是事务 2 已获得该二级索引 (“space id 5726 page no 8658 n bits 824 index”) 上所加的锁，在等待请求锁定主键索引 PRIMARY 索引上的锁。由于事务 2 等待执行时间过长或长时间不释放锁，导致事务 1 最终发生回滚。\n通过对当天访问日志跟踪可以看到，当天有客户通过脚本方式发起大量的修改推广组出价的操作，导致有大量事务在循环等待前一个事务释放锁定的主键 PRIMARY 索引。该问题的根源实际上在于 Mysql innodb 引擎对于索引利用有限，在 Oracle 数据库中此问题并不突出。解决的方式自然是希望单个事务锁定的记录数越少越好，这样产生死锁的概率也会大大降低。最终使用了（accountid, groupid）的复合索引，缩小了单个事务锁定的记录条数，也实现了不同计划下的推广组数据记录的隔离，从而减少该类死锁的发生几率。\n通常来说，对于数据库层的调优我们基本上会从以下几个方面出发：\n（1）在 SQL 语句层面进行优化：慢 SQL 分析、索引分析和调优、事务拆分等；\n（2）在数据库配置层面进行优化：比如字段设计、调整缓存大小、磁盘 I/O 等数据库参数优化、数据碎片整理等；\n（3）从数据库结构层面进行优化：考虑数据库的垂直拆分和水平拆分等；\n（4）选择合适的数据库引擎或者类型适应不同场景，比如考虑引入 NoSQL 等。\n总结与建议性能调优同样遵循 2-8 原则，80%的性能问题是由 20%的代码产生的，因此优化关键代码事半功倍。同时，对性能的优化要做到按需优化，过度优化可能引入更多问题。对于 Java 性能优化，不仅要理解系统架构、应用代码，同样需要关注 JVM 层甚至操作系统底层。总结起来主要可以从以下几点进行考虑：\n1）基础性能的调优\n这里的基础性能指的是硬件层级或者操作系统层级的升级优化，比如网络调优，操作系统版本升级，硬件设备优化等。比如 F5 的使用和 SDD 硬盘的引入，包括新版本 Linux 在 NIO 方面的升级，都可以极大的促进应用的性能提升；\n2）数据库性能优化\n包括常见的事务拆分，索引调优，SQL 优化，NoSQL 引入等，比如在事务拆分时引入异步化处理，最终达到一致性等做法的引入，包括在针对具体场景引入的各类 NoSQL 数据库，都可以大大缓解传统数据库在高并发下的不足；\n3）应用架构优化\n引入一些新的计算或者存储框架，利用新特性解决原有集群计算性能瓶颈等；或者引入分布式策略，在计算和存储进行水平化，包括提前计算预处理等，利用典型的空间换时间的做法等；都可以在一定程度上降低系统负载；\n4）业务层面的优化\n技术并不是提升系统性能的唯一手段，在很多出现性能问题的场景中，其实可以看到很大一部分都是因为特殊的业务场景引起的，如果能在业务上进行规避或者调整，其实往往是最有效的。\n转自：https://developer.ibm.com/zh/articles/j-lo-performance-tuning-practice/\n","tags":["Java"]},{"title":"Linux文件路径介绍","url":"/2020/06/01/Linux%E6%96%87%E4%BB%B6%E8%B7%AF%E5%BE%84%E4%BB%8B%E7%BB%8D/","content":"大纲\n\n\n目录\n\n\n\n\n/bin\n存放二进制可执行文件(ls,cat,mkdir等)，常用命令一般都在这里。\n\n\n/etc\n存放系统管理和配置文件\n\n\n/home\n存放所有用户文件的根目录，是用户主目录的基点，比如用户user的主目录就是/home/user，可以用~user表示\n\n\n/usr\n用于存放系统应用程序，比较重要的目录/usr/local 本地系统管理员软件安装目录（安装系统级的应用）。这是最庞大的目录，要用到的应用程序和文件几乎都在这个目录。/usr/x11r6 存放x window的目录/usr/bin 众多的应用程序  /usr/sbin 超级用户的一些管理程序  /usr/doc linux文档  /usr/include linux下开发和编译应用程序所需要的头文件  /usr/lib 常用的动态链接库和软件包的配置文件  /usr/man 帮助文档  /usr/src 源代码，linux内核的源代码就放在/usr/src/linux里  /usr/local/bin 本地增加的命令  /usr/local/lib 本地增加的库\n\n\n/opt\n额外安装的可选应用程序包所放置的位置。一般情况下，我们可以把tomcat等都安装到这里。\n\n\n/proc\n虚拟文件系统目录，是系统内存的映射。可直接访问这个目录来获取系统信息。\n\n\n/root\n超级用户（系统管理员）的主目录（特权阶级^o^）\n\n\n/sbin\n存放二进制可执行文件，只有root才能访问。这里存放的是系统管理员使用的系统级别的管理命令和程序。如ifconfig等。\n\n\n/dev\n用于存放设备文件。\n\n\n/mnt\n系统管理员安装临时文件系统的安装点，系统提供这个目录是让用户临时挂载其他的文件系统。\n\n\n/boot\n存放用于系统引导时使用的各种文件\n\n\n/lib\n存放跟文件系统中的程序运行所需要的共享库及内核模块。共享库又叫动态链接共享库，作用类似windows里的.dll文件，存放了根文件系统程序运行所需的共享文件。\n\n\n/tmp\n用于存放各种临时文件，是公用的临时文件存储点。\n\n\n/var\n用于存放运行时需要改变数据的文件，也是某些大文件的溢出区，比方说各种服务的日志文件（系统启动日志等。）等。\n\n\n/lost+found\n这个目录平时是空的，系统非正常关机而留下“无家可归”的文件（windows下叫什么.chk）就在这里\n\n\n\n/bin 二进制可执行命令\n/dev 设备特殊文件\n/etc 系统管理和配置文件\n/etc/rc.d 启动的配置文件和脚本\n/home 用户主目录的基点，比如用户user的主目录就是/home/user，可以用~user表示\n/lib 标准程序设计库，又叫动态链接共享库，作用类似windows里的.dll文件\n/sbin 超级管理命令，这里存放的是系统管理员使用的管理程序\n/tmp 公共的临时文件存储点\n/root 系统管理员的主目录\n/mnt 系统提供这个目录是让用户临时挂载其他的文件系统\n/lost+found 这个目录平时是空的，系统非正常关机而留下“无家可归”的文件（windows下叫什么.chk）就在这里\n/proc 虚拟的目录，是系统内存的映射。可直接访问这个目录来获取系统信息。\n/var 某些大文件的溢出区，比方说各种服务的日志文件\n/usr 最庞大的目录，要用到的应用程序和文件几乎都在这个目录，其中包含：\n/usr/x11R6 存放x window的目录\n/usr/bin 众多的应用程序\n/usr/sbin 超级用户的一些管理程序\n/usr/doc linux文档\n/usr/include linux下开发和编译应用程序所需要的头文件\n/usr/lib 常用的动态链接库和软件包的配置文件\n/usr/man 帮助文档\n/usr/src 源代码，linux内核的源代码就放在/usr/src/linux里\n/usr/local/bin 本地增加的命令\n/usr/local/lib 本地增加的库根文件系统\n\n\n\n通常情况下，根文件系统所占空间一般应该比较小，因为其中的绝大部分文件都不需要经常改动，而且包括严格的文件和一个小的不经常改变的文件系统不容易损坏。除了可能的一个叫/ vmlinuz标准的系统引导映像之外，根目录一般不含任何文件。所有其他文件在根文件系统的子目录中。\n\n/bin目录/bin目录包含了引导启动所需的命令或普通用户可能用的命令(可能在引导启动后)。这些命令都是二进制文件的可执行程序(bin是binary–二进制的简称)，多是系统中重要的系统文件。\n/sbin目录/sbin目录类似/bin，也用于存储二进制文件。因为其中的大部分文件多是系统管理员使用的基本的系统程序，所以虽然普通用户必要且允许时可以使用，但一般不给普通用户使用。\n/etc目录/etc目录存放着各种系统配置文件，其中包括了用户信息文件/etc/passwd，系统初始化文件/etc/rc等。linux正是*这些文件才得以正常地运行。\n/root目录/root目录是超级用户的目录。\n/lib目录/lib目录是根文件系统上的程序所需的共享库，存放了根文件系统程序运行所需的共享文件。这些文件包含了可被许多程序共享的代码，以避免每个程序都包含有相同的子程序的副本，故可以使得可执行文件变得更小，节省空间。\n/lib/modules目录/lib/modules目录包含系统核心可加载各种模块，尤其是那些在恢复损坏的系统时重新引导系统所需的模块(例如网络和文件系统驱动)。\n/dev目录/dev目录存放了设备文件，即设备驱动程序，用户通过这些文件访问外部设备。比如，用户可以通过访问/dev/mouse来访问鼠标的输入，就像访问其他文件一样。\n/tmp目录/tmp目录存放程序在运行时产生的信息和数据。但在引导启动后，运行的程序最好使用/var/tmp来代替/tmp，因为前者可能拥有一个更大的磁盘空间。\n/boot目录/boot目录存放引导加载器(bootstraploader)使用的文件，如lilo，核心映像也经常放在这里，而不是放在根目录中。但是如果有许多核心映像，这个目录就可能变得很大，这时使用单独的文件系统会更好一些。还有一点要注意的是，要确保核心映像必须在ide硬盘的前1024柱面内。\n/mnt目录/mnt目录是系统管理员临时安装(mount)文件系统的安装点。程序并不自动支持安装到/mnt。/mnt下面可以分为许多子目录，例如/mnt/dosa可能是使用msdos文件系统的软驱，而/mnt/exta可能是使用ext2文件系统的软驱，/mnt/cdrom光驱等等。\n/proc,/usr,/var,/home目录其他文件系统的安装点。\n\n下面详细介绍；\n/etc文件系统/etc目录包含各种系统配置文件，下面说明其中的一些。其他的你应该知道它们属于哪个程序，并阅读该程序的man页。许多网络配置文件也在/etc中。\n\n/etc/rc或/etc/rc. d或/etc/rc?. d启动、或改变运行级时运行的脚本或脚本的目录。\n/etc/passwd用户数据库，其中的域给出了用户名、真实姓名、用户起始目录、加密口令和用户的其他信息。\n/etc/fdprm软盘参数表，用以说明不同的软盘格式。可用setfdprm进行设置。更多的信息见setfdprm的帮助页。\n/etc/fstab指定启动时需要自动安装的文件系统列表。也包括用swapon-a启用的swap区的信息。\n/etc/group类似/etc/passwd，但说明的不是用户信息而是组的信息。包括组的各种数据。\n/etc/inittabinit的配置文件。\n/etc/issue包括用户在登录提示符前的输出信息。通常包括系统的一段短说明或欢迎信息。具体内容由系统管理员确定。\n/etc/magic“file”的配置文件。包含不同文件格式的说明，“file”基于它猜测文件类型。\n/etc/motdmotd是messageoftheday的缩写，用户成功登录后自动输出。内容由系统管理员确定。常用于通告信息，如计划关机时间的警告等。\n/etc/mtab当前安装的文件系统列表。由脚本(scritp)初始化，并由mount命令自动更新。当需要一个当前安装的文件系统的列表时使用(例如df命令)。\n/etc/shadow在安装了影子(shadow)口令软件的系统上的影子口令文件。影子口令文件将/etc/passwd文件中的加密口令移动到/etc/shadow中，而后者只对超级用户(root)可读。这使破译口令更困难，以此增加系统的安全性。\n/etc/login. defslogin命令的配置文件。\n/etc/printcap类似/etc/termcap，但针对打印机。语法不同。\n/etc/profile、/etc/csh. login、/etc/csh. cshrc登录或启动时bourne或cshells执行的文件。这允许系统管理员为所有用户建立全局缺省环境。\n/etc/securetty确认安全终端，即哪个终端允许超级用户(root)登录。一般只列出虚拟控制台，这样就不可能(至少很困难)通过调制解调器(modem)或网络闯入系统并得到超级用户特权。\n/etc/shells列出可以使用的shell。chsh命令允许用户在本文件指定范围内改变登录的shell。提供一台机器ftp服务的服务进程ftpd检查用户shell是否列在/etc/shells文件中，如果不是，将不允许该用户登录。\n/etc/termcap终端性能数据库。说明不同的终端用什么“转义序列”控制。写程序时不直接输出转义序列(这样只能工作于特定品牌的终端)，而是从/etc/termcap中查找要做的工作的正确序列。这样，多数的程序可以在多数终端上运行。\n\n/dev文件系统/dev目录包括所有设备的设备文件。设备文件用特定的约定命名，这在设备列表中说明。设备文件在安装时由系统产生，以后可以用/dev/makedev描述。/dev/makedev. local是系统管理员为本地设备文件(或连接)写的描述文稿(即如一些非标准设备驱动不是标准makedev的一部分)。下面简要介绍/dev下一些常用文件。\n\n/dev/console系统控制台，也就是直接和系统连接的监视器。\n/dev/hdide硬盘驱动程序接口。如：/dev/hda指的是第一个硬盘，had1则是指/dev/hda的第一个分区。如系统中有其他的硬盘，则依次为/dev/hdb、/dev/hdc、. . . . . . ；如有多个分区则依次为hda1、hda2. . . . . .\n/dev/sdscsi磁盘驱动程序接口。如有系统有scsi硬盘，就不会访问/dev/had，而会访问/dev/sda。\n/dev/fd软驱设备驱动程序。如：/dev/fd0指系统的第一个软盘，也就是通常所说的a：盘，/dev/fd1指第二个软盘，. . . . . . 而/dev/fd1h1440则表示访问驱动器1中的4. 5高密盘。\n/dev/stscsi磁带驱动器驱动程序。\n/dev/tty提供虚拟控制台支持。如：/dev/tty1指的是系统的第一个虚拟控制台，/dev/tty2则是系统的第二个虚拟控制台。\n/dev/pty提供远程登陆伪终端支持。在进行telnet登录时就要用到/dev/pty设备。\n/dev/ttys计算机串行接口，对于dos来说就是“com1”口。\n/dev/cua计算机串行接口，与调制解调器一起使用的设备。\n/dev/null“黑洞”，所有写入该设备的信息都将消失。例如：当想要将屏幕上的输出信息隐藏起来时，只要将输出信息输入到/dev/null中即可。\n\n/usr文件系统/usr是个很重要的目录，通常这一文件系统很大，因为所有程序安装在这里。/usr里的所有文件一般来自linux发行版(distribution)；本地安装的程序和其他东西在/usr/local下，因为这样可以在升级新版系统或新发行版时无须重新安装全部程序。/usr目录下的许多内容是可选的，但这些功能会使用户使用系统更加有效。/usr可容纳许多大型的软件包和它们的配置文件。下面列出一些重要的目录(一些不太重要的目录被省略了)。\n\n/usr/x11r6包含xwindow系统的所有可执行程序、配置文件和支持文件。为简化x的开发和安装，x的文件没有集成到系统中。xwindow系统是一个功能强大的图形环境，提供了大量的图形工具程序。用户如果对microsoftwindows或machintosh比较熟悉的话，就不会对xwindow系统感到束手无策了。\n/usr/x386类似/usr/x11r6，但是是专门给x11release5的。\n/usr/bin集中了几乎所有用户命令，是系统的软件库。另有些命令在/bin或/usr/local/bin中。\n/usr/sbin包括了根文件系统不必要的系统管理命令，例如多数服务程序。\n/usr/man、/usr/info、/usr/doc这些目录包含所有手册页、gnu信息文档和各种其他文档文件。每个联机手册的“节”都有两个子目录。例如：/usr/man/man1中包含联机手册第一节的源码(没有格式化的原始文件)，/usr/man/cat1包含第一节已格式化的内容。l联机手册分为以下九节：内部命令、系统调用、库函数、设备、文件格式、游戏、宏软件包、系统管理和核心程序。\n/usr/include包含了c语言的头文件，这些文件多以. h结尾，用来描述c语言程序中用到的数据结构、子过程和常量。为了保持一致性，这实际上应该放在/usr/lib下，但习惯上一直沿用了这个名字。\n/usr/lib包含了程序或子系统的不变的数据文件，包括一些site-wide配置文件。名字lib来源于库(library);编程的原始库也存在/usr/lib里。当编译程序时，程序便会和其中的库进行连接。也有许多程序把配置文件存入其中。\n/usr/local本地安装的软件和其他文件放在这里。这与/usr很相似。用户可能会在这发现一些比较大的软件包，如tex、emacs等。\n\n/var文件系统/var包含系统一般运行时要改变的数据。通常这些数据所在的目录的大小是要经常变化或扩充的。原来/var目录中有些内容是在/usr中的，但为了保持/usr目录的相对稳定，就把那些需要经常改变的目录放到/var中了。每个系统是特定的，即不通过网络与其他计算机共享。下面列出一些重要的目录(一些不太重要的目录省略了)。\n\n/var/catman包括了格式化过的帮助(man)页。帮助页的源文件一般存在/usr/man/man中；有些man页可能有预格式化的版本，存在/usr/man/cat中。而其他的man页在第一次看时都需要格式化，格式化完的版本存在/var/man中，这样其他人再看相同的页时就无须等待格式化了。(/var/catman经常被清除，就像清除临时目录一样。)\n/var/lib存放系统正常运行时要改变的文件。\n/var/local存放/usr/local中安装的程序的可变数据(即系统管理员安装的程序)。注意，如果必要，即使本地安装的程序也会使用其他/var目录，例如/var/lock。\n/var/lock锁定文件。许多程序遵循在/var/lock中产生一个锁定文件的约定，以用来支持他们正在使用某个特定的设备或文件。其他程序注意到这个锁定文件时，就不会再使用这个设备或文件。\n/var/log各种程序的日志(log)文件，尤其是login(/var/log/wtmplog纪录所有到系统的登录和注销)和syslog(/var/log/messages纪录存储所有核心和系统程序信息)。/var/log里的文件经常不确定地增长，应该定期清除。\n/var/run保存在下一次系统引导前有效的关于系统的信息文件。例如，/var/run/utmp包含当前登录的用户的信息。\n/var/spool放置“假脱机(spool)”程序的目录，如mail、news、打印队列和其他队列工作的目录。每个不同的spool在/var/spool下有自己的子目录，例如，用户的邮箱就存放在/var/spool/mail中。\n/var/tmp比/tmp允许更大的或需要存在较长时间的临时文件。注意系统管理员可能不允许/var/tmp有很旧的文件。\n\n/proc文件系统/proc文件系统是一个伪的文件系统，就是说它是一个实际上不存在的目录，因而这是一个非常特殊的目录。它并不存在于某个磁盘上，而是由核心在内存中产生。这个目录用于提供关于系统的信。下面说明一些最重要的文件和目录(/proc文件系统在procman页中有更详细的说明)。\n\n/proc/x关于进程x的信息目录，这一x是这一进程的标识号。每个进程在/proc下有一个名为自己进程号的目录。\n/proc/cpuinfo存放处理器(cpu)的信息，如cpu的类型、制造商、型号和性能等。\n/proc/devices当前运行的核心配置的设备驱动的列表。\n/proc/dma显示当前使用的dma通道。\n/proc/filesystems核心配置的文件系统信息。\n/proc/interrupts显示被占用的中断信息和占用者的信息，以及被占用的数量。\n/proc/ioports当前使用的i/o端口。\n/proc/kcore系统物理内存映像。与物理内存大小完全一样，然而实际上没有占用这么多内存；它仅仅是在程序访问它时才被创建。(注意：除非你把它拷贝到什么地方，否则/proc下没有任何东西占用任何磁盘空间。)\n/proc/kmsg核心输出的消息。也会被送到syslog。\n/proc/ksyms核心符号表。\n/proc/loadavg系统“平均负载”；3个没有意义的指示器指出系统当前的工作量。\n/proc/meminfo各种存储器使用信息，包括物理内存和交换分区(swap)。\n/proc/modules存放当前加载了哪些核心模块信息。\n/proc/net网络协议状态信息。\n/proc/self存放到查看/proc的程序的进程目录的符号连接。当2个进程查看/proc时，这将会是不同的连接。这主要便于程序得到它自己的进程目录。\n/proc/stat系统的不同状态，例如，系统启动后页面发生错误的次数。\n/proc/uptime系统启动的时间长度。\n/proc/version核心版本\n\n","tags":["Linux"]},{"title":"Linux系统中bash的四种模式","url":"/2019/12/09/Linux%E7%B3%BB%E7%BB%9F%E4%B8%ADbash%E7%9A%84%E5%9B%9B%E7%A7%8D%E6%A8%A1%E5%BC%8F/","content":"一、前言今天在配置jenkins的执行节点，但是执行节点shell的PATH变量始终不对，无法找到git命令。我先前已经在/etc/profile中配置了git的PATH,通过putty连接的shell中也检查PATH变量是正确的，且git命令也能正常执行。后来查阅资料才知道这个问题是由于我没有很好的理解bash的四种模式而造成的。\n解决办法：\n#!&#x2F;bin&#x2F;bash -ilex......对于e参数表示一旦出错,就退出当前的shell，x参数表示可以显示所执行的每一条命令\n\nLinux的bash的其实分为四种模式，bash会依据这四种模式而选择加载不同的配置文件，而且加载的顺序也有所不同.\n这四种bash模式分别是：\n1、interactive + login\n2、non-interactive + login\n3、interactive + non-login\n4、non-interactive + non-login\n本文在整理前人资料的基础上，着重介绍这四种bash模式在初始化时如何进行配置文件加载的。\n二、bash四种模式的shell（一）、interactive + login模式的shell第一种模式是交互式的登陆shell，这里面有两个概念需要解释：interactive和login：\nlogin故名思义，即登陆，login shell是指用户以非图形化界面或者以ssh登陆到机器上时获得的第一个shell，简单些说就是需要输入用户名和密码的shell。因此通常不管以何种方式登陆机器后用户获得的第一个shell就是login shell。\ninteractive意为交互式，这也很好理解，interactive  shell会有一个输入提示符，并且它的标准输入、输出和错误输出都会显示在控制台上。所以一般来说只要是需要用户交互的，即一个命令一个命令的输入的shell都是interactive  shell。而如果无需用户交互，它便是non-interactive shell。通常来说如bash script.sh此类执行脚本的命令就会启动一个non-interactive shell，它不需要与用户进行交互，执行完后它便会退出创建的shell。\n那么此模式最简单的两个例子为：\n\n用户直接登陆到机器获得的第一个shell\n用户使用ssh user@remote获得的shell\n\n加载配置文件\n这种模式下，shell首先加载/etc/profile，然后再尝试依次去加载下列三个配置文件之一，一旦找到其中一个便不再接着寻找：\n\n~/.bash_profile\n~/.bash_login\n~/.profile\n\n下面给出这个加载过程的伪代码：\nexecute /etc/profileIF ~/.bash_profile exists THENexecute ~/.bash_profileELSEIF ~/.bash_login exist THENexecute ~/.bash_loginELSEIF ~/.profile exist THENexecute ~/.profileEND IFEND IFEND IF\n\n为了验证这个过程，我们来做一些测试。首先设计每个配置文件的内容如下：\nuser@remote &gt; cat &#x2F;etc&#x2F;profileecho @ &#x2F;etc&#x2F;profileuser@remote &gt; cat ~&#x2F;.bash_profileecho @ ~&#x2F;.bash_profileuser@remote &gt; cat ~&#x2F;.bash_loginecho @ ~&#x2F;.bash_loginuser@remote &gt; cat ~&#x2F;.profileecho @ ~&#x2F;.profile\n\n然后打开一个login shell，注意，为方便起见，这里使用bash -l命令，它会打开一个login shell，在man bash中可以看到此参数的解释：\n\n-l Make bash act as if it had been invoked as a login shell\n\n进入这个新的login shell，便会得到以下输出：\n@ &#x2F;etc&#x2F;profile@ &#x2F;home&#x2F;user&#x2F;.bash_profile\n\n因为没有了~/.bash_profile的屏蔽，所以~/.bash_login被加载，但最后一个~/.profile仍被忽略。\n再次移除~/.bash_login，启动login shell的输出结果为：\n@ &#x2F;etc&#x2F;profile@ &#x2F;home&#x2F;user&#x2F;.profile\n\n~/.profile终于熬出头，得见天日。通过以上三个实验，配置文件的加载过程得到了验证，除去/etc/profile首先被加载外，其余三个文件的加载顺序为：~/.bash_profile&gt; ~/.bash_login &gt; ~/.profile，只要找到一个便终止查找。\n前面说过，使用ssh也会得到一个login shell，所以如果在另外一台机器上运行ssh user@remote时，也会得到上面一样的结论。\n配置文件的意义\n那么，为什么bash要弄得这么复杂？每个配置文件存在的意义是什么？\n/etc/profile很好理解，它是一个全局的配置文件。后面三个位于用户主目录中的配置文件都针对用户个人，也许你会问为什么要有这么多，只用一个~/.profile不好么？究竟每个文件有什么意义呢？这是个好问题。\nCameron Newham和Bill Rosenblatt在他们的著作《Learning the bash Shell, 2nd Edition》的59页解释了原因：\n\nbash allows two synonyms for .bash_profile: .bash_login, derived from  the C shell’s file named .login, and .profile, derived from the Bourne  shell and Korn shell files named .profile. Only one of these three is  read when you log in. If .bash_profile doesn’t exist in your home  directory, then bash will look for .bash_login. If that doesn’t exist it  will look for .profile.\nOne advantage of bash’s ability to look for either synonym is that  you can retain your .profile if you have been using the Bourne shell. If  you need to add bash-specific commands, you can put them in  .bash_profile followed by the command source .profile. When you log in,  all the bash-specific commands will be executed and bash will source  .profile, executing the remaining commands. If you decide to switch to  using the Bourne shell you don’t have to modify your existing files. A  similar approach was intended for .bash_login and the C shell .login,  but due to differences in the basic syntax of the shells, this is not a  good idea.\n\n原来一切都是为了兼容，这么设计是为了更好的应付在不同shell之间切换的场景。因为bash完全兼容Bourne shell，所以.bash_profile和.profile可以很好的处理bash和Bourne shell之间的切换。但是由于C shell和bash之间的基本语法存在着差异，作者认为引入.bash_login并不是个好主意。所以由此我们可以得出这样的最佳实践：\n\n应该尽量杜绝使用.bash_login，如果已经创建，那么需要创建.bash_profile来屏蔽它被调用\n.bash_profile适合放置bash的专属命令，可以在其最后读取.profile，如此一来，便可以很好的在Bourne shell和bash之间切换了\n\n（二）、non-interactive + login模式的shell第二种模式的shell为non-interactive login shell，即非交互式的登陆shell，这种是不太常见的情况。一种创建此shell的方法为：bash -l script.sh，前面提到过-l参数是将shell作为一个login shell启动，而执行脚本又使它为non-interactive shell。\n对于这种类型的shell，配置文件的加载与第一种完全一样，在此不再赘述。\n（三）、interactive + non-login模式的shell第三种模式为交互式的非登陆shell，这种模式最常见的情况为在一个已有shell中运行bash，此时会打开一个交互式的shell，而因为不再需要登陆，因此不是login shell。\n加载配置文件\n对于此种情况，启动shell时会去查找并加载/etc/bash.bashrc和~/.bashrc文件。\n为了进行验证，与第一种模式一样，设计各配置文件内容如下：\nuser@remote &gt; cat &#x2F;etc&#x2F;bash.bashrcecho @ &#x2F;etc&#x2F;bash.bashrcuser@remote &gt; cat ~&#x2F;.bashrcecho @ ~&#x2F;.bashrc\n\n然后我们启动一个交互式的非登陆shell，直接运行bash即可，可以得到以下结果：\n@ &#x2F;etc&#x2F;bash.bashrc@ &#x2F;home&#x2F;user&#x2F;.bashrc\n\nbashrc VS profile\n从刚引入的两个配置文件的存放路径可以很容易的判断，第一个文件是全局性的，第二个文件属于当前用户。在前面的模式当中，已经出现了几种配置文件，多数是以profile命名的，那么为什么这里又增加两个文件呢？这样不会增加复杂度么？我们来看看此处的文件和前面模式中的文件的区别。\n首先看第一种模式中的profile类型文件，它是某个用户唯一的用来设置全局环境变量的地方, 因为用户可以有多个shell比如bash,  sh, zsh等, 但像环境变量这种其实只需要在统一的一个地方初始化就可以, 而这个地方就是profile，所以启动一个login  shell会加载此文件，后面由此shell中启动的新shell进程如bash，sh，zsh等都可以由login shell中继承环境变量等配置。\n接下来看bashrc，其后缀rc的意思为Run Commands，由名字可以推断出，此处存放bash需要运行的命令，但注意，这些命令一般只用于交互式的shell，通常在这里会设置交互所需要的所有信息，比如bash的补全、alias、颜色、提示符等等。\n所以可以看出，引入多种配置文件完全是为了更好的管理配置，每个文件各司其职，只做好自己的事情。\n下面给出这个加载过程的伪代码：\n（四）、non-interactive + non-login模式的shell最后一种模式为非交互非登陆的shell，创建这种shell典型有两种方式：\n\nbash script.sh\nssh user@remote command\n\n这两种都是创建一个shell，执行完脚本之后便退出，不再需要与用户交互。\n加载配置文件\n对于这种模式而言，它会去寻找环境变量BASH_ENV，将变量的值作为文件名进行查找，如果找到便加载它。\n同样，我们对其进行验证。首先，测试该环境变量未定义时配置文件的加载情况，这里需要一个测试脚本：\nuser@remote &gt; cat ~&#x2F;script.shecho Hello World\n\n再次执行bash script.sh，结果为：\n@ &#x2F;home&#x2F;user&#x2F;.bashrcHello World\n\n果然，~/.bashrc被加载，而它是由环境变量BASH_ENV设定的。\n三、关于bash四种模式的直观示图至此，四种模式下配置文件如何加载已经讲完，因为涉及的配置文件有些多，我们再以两个图来更为直观的进行描述：\n第一张图来自这篇文章，bash的每种模式会读取其所在列的内容，首先执行A，然后是B，C。而B1，B2和B3表示只会执行第一个存在的文件：\n+----------------+--------+-----------+---------------+|                | login  |interactive|non-interactive||                |        |non-login  |non-login      |+----------------+--------+-----------+---------------+|/etc/profile    |   A    |           |               |+----------------+--------+-----------+---------------+|/etc/bash.bashrc|        |    A      |               |+----------------+--------+-----------+---------------+|~/.bashrc       |        |    B      |               |+----------------+--------+-----------+---------------+|~/.bash_profile |   B1   |           |               |+----------------+--------+-----------+---------------+|~/.bash_login   |   B2   |           |               |+----------------+--------+-----------+---------------+|~/.profile      |   B3   |           |               |+----------------+--------+-----------+---------------+|BASH_ENV        |        |           |       A       |+----------------+--------+-----------+---------------+\n\n上图只给出了三种模式，原因是第一种login实际上已经包含了两种，因为这两种模式下对配置文件的加载是一致的。\n另外一篇文章给出了一个更直观的图：\n\n上图的情况稍稍复杂一些，因为它使用了几个关于配置文件的参数：--login，--rcfile，--noprofile，--norc，这些参数的引入会使配置文件的加载稍稍发生改变，不过总体来说，不影响我们前面的讨论，相信这张图不会给你带来更多的疑惑。\n四、bash与sh陷阱ssh user@remote ~/myscript.sh属于哪一种模式？相信此时你可以非常轻松的回答出来：non-login + non-interactive。对于这种模式，bash会选择加载$BASH_ENV的值所对应的文件，所以为了让它加载/etc/profile，可以设定：\nuser@local &gt; export BASH_ENV&#x3D;&#x2F;etc&#x2F;profile\n\n然后执行上面的命令，依旧会出现如下错误：\n~/myscript.sh: line n: app: command not found\n\n这是怎么回事？这看起来像是环境变量引起的问题，为了证实这一猜想，我在这条命令之前加了一句：which app，来查看app的安装路径。在remote本机上执行脚本时，它会打印出app正确的安装路径。但再次用ssh来执行时，却遇到下面的错误：\nwhich: no app in (/usr/bin:/bin:/usr/sbin:/sbin)\n\n这很奇怪，怎么括号中的环境变量没有了app程序的安装路径？不是已通过/etc/profile设置到PATH中了？再次在脚本中加入echo $PATH并以ssh执行，这才发现，环境变量仍是系统初始化时的结果：\n/usr/bin:/bin:/usr/sbin:/sbin\n\n这证明/etc/profile根本没有被调用。为什么？我们已经将BASH_ENV的值设置成了/etc/profile。但是似乎并没有加载/etc/profile呢？\n仔细查看之后才发现脚本myscript.sh的第一行为#!/usr/bin/env sh，注意看，它和前面提到的#!/usr/bin/env bash不一样，可能就是这里出了问题。我们先尝试把它改成#!/usr/bin/env bash，再次执行，错误果然消失了，这与我们前面的分析结果一致。\n第一行的这个语句有什么用？设置成sh和bash有什么区别？带着这些疑问，再来查看man bash：\n\nIf the program is a file beginning with #!, the remainder of the first line specifies an interpreter for the program.\n\n它表示这个文件的解释器，即用什么程序来打开此文件，就好比Windows上双击一个文件时会以什么程序打开一样。因为这里不是bash，而是sh，那么我们前面讨论的都不复有效了，真糟糕。我们来看看这个sh的路径：\nuser@remote &gt; ll &#96;which sh&#96;lrwxrwxrwx 1 root root 9 Apr 25  2014 &#x2F;usr&#x2F;bin&#x2F;sh -&gt; &#x2F;bin&#x2F;bash\n\n原来sh只是bash的一个软链接，既然如此，BASH_ENV应该是有效的啊，为何此处无效？还是回到man bash，同样在INVOCATION一节的下部看到了这样的说明：\n\nIf bash is invoked with the name sh, it tries to mimic the startup  behavior of historical versions of sh as closely as possible, while  conforming to the POSIX standard as well. When invoked as an interactive  login shell, or a non-interactive shell with the –login option, it  first attempts to read and execute commands from /etc/profile and  ~/.profile, in that order. The –noprofile option may be used to inhibit  this behavior. When invoked as an interactive shell with the name sh,  bash looks for the variable ENV, expands its value if it is defined, and  uses the expanded value as the name of a file to read and execute.  Since a shell invoked as sh does not attempt to read and execute  commands from any other startup files, the –rcfile option has no effect.  A non-interactive shell invoked with the name sh does not attempt to  read any other startup files. When invoked as sh, bash enters posix mode  after the startup files are read.\n\n简而言之，当bash以是sh命启动时，即我们此处的情况，bash会尽可能的模仿sh，所以配置文件的加载变成了下面这样：\n\ninteractive + login: 读取/etc/profile和~/.profile\nnon-interactive + login: 同上\ninteractive + non-login: 读取ENV环境变量对应的文件\nnon-interactive + non-login: 不读取任何文件\n\n这样便可以解释为什么出错了，因为这里属于non-interactive + non-login，所以bash不会读取任何文件，故而即使设置了BASH_ENV也不会起作用。所以为了解决问题，只需要把sh换成bash，再设置环境变量BASH_ENV即可。\n另外，其实我们还可以设置参数到第一行的解释器中，如#!/bin/bash --login，如此一来，bash便会强制为login shell，所以/etc/profile也会被加载。相比上面那种方法，这种更为简单。\n五、总结与建议（一）、总结为了更好的理清这几种模式，下面我们对一些典型的启动方式各属于什么模式进行一个总结：\n\n登陆机器后的第一个shell：login + interactive\n新启动一个shell进程，如运行bash：non-login + interactive\n执行脚本，如bash script.sh：non-login + non-interactive\n运行头部有如#!/usr/bin/env bash的可执行文件，如./executable：non-login + non-interactive\n通过ssh登陆到远程主机：login + interactive\n远程执行脚本，如ssh user@remote script.sh：non-login + non-interactive\n远程执行脚本，同时请求控制台，如ssh user@remote -t &#39;echo $PWD&#39;：non-login + interactive\n在图形化界面中打开terminal：\nLinux上: non-login + interactive\nMac OS X上: login + interactive\n\n（二）、建议回顾一下前面提到的所有配置文件，总共有以下几种：\n\n/etc/profile\n~/.bash_profile\n~/.bash_login\n~/.profile\n/etc/bash.bashrc\n~/.bashrc\n$BASH_ENV\n$ENV\n\n不知你是否会有疑问，这么多的配置文件，究竟每个文件里面应该包含哪些配置，比如PATH应该在哪？提示符应该在哪配置？启动的程序应该在哪？等等。所以在文章的最后，我搜罗了一些最佳实践供各位参考。（这里只讨论属于用户个人的配置文件）\n\n~/.bash_profile：应该尽可能的简单，通常会在最后加载.profile和.bashrc(注意顺序)\n~/.bash_login：在前面讨论过，别用它\n~/.profile：此文件用于login shell，所有你想在整个用户会话期间都有效的内容都应该放置于此，比如启动进程，环境变量等\n~/.bashrc：只放置与bash有关的命令，所有与交互有关的命令都应该出现在此，比如bash的补全、alias、颜色、提示符等等。\n\n的。\n转自：https://blog.csdn.net/hudashi/article/details/82464995\n","tags":["Linux"]},{"title":"图解ReentrantReadWriteLock实现分析","url":"/2020/06/03/%E5%9B%BE%E8%A7%A3ReentrantReadWriteLock%E5%AE%9E%E7%8E%B0%E5%88%86%E6%9E%90/","content":"概述本文主要分析JCU包中读写锁接口(ReadWriteLock)的重要实现类ReentrantReadWriteLock。主要实现读共享，写互斥功能，对比单纯的互斥锁在共享资源使用场景为频繁读取及少量修改的情况下可以较好的提高性能。\nReadWriteLock接口简单说明ReadWriteLock接口只定义了两个方法：\npublic interface ReadWriteLock &#123;    /**     * Returns the lock used for reading.     *     * @return the lock used for reading     */    Lock readLock();    /**     * Returns the lock used for writing.     *     * @return the lock used for writing     */    Lock writeLock();&#125;\n\n通过调用相应方法获取读锁或写锁，获取的读锁及写锁都是Lock接口的实现，可以如同使用Lock接口一样使用（其实也有一些特性是不支持的）。\nReentrantReadWriteLock使用示例读写锁的使用并不复杂，可以参考以下使用示例：\nclass RWDictionary &#123;    private final Map&lt;String, Data&gt; m = new TreeMap&lt;String, Data&gt;();    private final ReentrantReadWriteLock rwl = new ReentrantReadWriteLock();    private final Lock r = rwl.readLock();    private final Lock w = rwl.writeLock();    public Data get(String key) &#123;        r.lock();        try &#123; return m.get(key); &#125;        finally &#123; r.unlock(); &#125;    &#125;    public String[] allKeys() &#123;        r.lock();        try &#123; return m.keySet().toArray(); &#125;        finally &#123; r.unlock(); &#125;    &#125;    public Data put(String key, Data value) &#123;        w.lock();        try &#123; return m.put(key, value); &#125;        finally &#123; w.unlock(); &#125;    &#125;    public void clear() &#123;        w.lock();        try &#123; m.clear(); &#125;        finally &#123; w.unlock(); &#125;    &#125;&#125;\n\n与普通重入锁使用的主要区别在于需要使用不同的锁对象引用读写锁，并且在读写时分别调用对应的锁。\nReentrantReadWriteLock锁实现分析本节通过学习源码分析可重入读写锁的实现。\n图解重要函数及对象关系从图中可见读写锁的加锁解锁操作最终都是调用ReentrantReadWriteLock类的内部类Sync提供的方法。与一文中描述相似，Sync对象通过继承AbstractQueuedSynchronizer进行实现，故后续分析主要基于Sync类进行。\n读写锁Sync结构分析Sync继承于AbstractQueuedSynchronizer，其中主要功能均在AbstractQueuedSynchronizer中完成，其中最重要功能为控制线程获取锁失败后转换为等待状态及在满足一定条件后唤醒等待状态的线程。先对AbstractQueuedSynchronizer进行观察。\nAbstractQueuedSynchronizer图解图中展示AQS类较为重要的数据结构，包括int类型变量state用于记录锁的状态，继承自AbstractOwnableSynchronizer类的Thread类型变量exclusiveOwnerThread用于指向当前排他的获取锁的线程，AbstractQueuedSynchronizer.Node类型的变量head及tail。其中Node对象表示当前等待锁的节点，Node中thread变量指向等待的线程，waitStatus表示当前等待节点状态，mode为节点类型。多个节点之间使用prev及next组成双向链表，参考CLH锁队列的方式进行锁的获取，但其中与CLH队列的重要区别在于CLH队列中后续节点需要自旋轮询前节点状态以确定前置节点是否已经释放锁，期间不释放CPU资源，而AQS中Node节点指向的线程在获取锁失败后调用LockSupport.park函数使其进入阻塞状态，让出CPU资源，故在前置节点释放锁时需要调用unparkSuccessor函数唤醒后继节点。根据以上说明可得知此上图图主要表现当前thread0线程获取了锁，thread1线程正在等待。\n读写锁Sync对于AQS使用读写锁中Sync类是继承于AQS，并且主要使用上文介绍的数据结构中的state及waitStatus变量进行实现。实现读写锁与实现普通互斥锁的主要区别在于需要分别记录读锁状态及写锁状态，并且等待队列中需要区别处理两种加锁操作。Sync使用不同的mode描述等待队列中的节点以区分读锁等待节点和写锁等待节点。mode取值包括SHARED及EXCLUSIVE两种，分别代表当前等待节点为读锁和写锁。\n读写锁Sync代码过程分析写锁加锁通过对于重要函数关系的分析，写锁加锁最终调用Sync类的acquire函数（继承自AQS）\npublic final void acquire(int arg) &#123;    if (!tryAcquire(arg) &amp;&amp;        acquireQueued(addWaiter(Node.EXCLUSIVE), arg))        selfInterrupt();&#125;\n\n现在分情况图解分析\n无锁状态其中state变量为0，表示高位地位地位均为0，没有任何锁，且等待节点的首尾均指向空（此处特指head节点没有初始化时），锁的所有者线程也为空。\n有锁状态在加写锁时如果当前AQS已经是有锁状态，则需要进一步处理。有锁状态主要分为已有写锁和已有读锁状态，并且根据最终当前线程是否可直接获取锁分为两种情况：\n\n非重入：如果满足一下两个条件之一，当前线程必须加入等待队列（暂不考虑非公平锁抢占情况）a. 已有读锁；b. 有写锁且获取写锁的线程不为当前请求锁的线程。\n重入：有写锁且当前获取写锁的线程与当前请求锁的线程为同一线程，则直接获取锁并将写锁状态值加1。\n\n在非重入状态，当前线程创建等待节点追加到等待队列队尾，如果当前头结点为空，则需要创建一个默认的头结点。之后再当前获取锁的线程释放锁后，会唤醒等待中的节点，即为thread1。如果当前等待队列存在多个等待节点，由于thread1等待节点为EXCLUSIVE模式，则只会唤醒当前一个节点，不会传播唤醒信号。\n读锁加锁通过对于重要函数关系的分析，写锁加锁最终调用Sync类的acquireShared函数（继承自AQS）：\npublic final void acquireShared(int arg) &#123;    if (tryAcquireShared(arg) &lt; 0)        doAcquireShared(arg);&#125;\n\n同上文，现在分情况图解分析\n无锁状态其中有两个新的变量：firstReader及firstReaderHoldCount。firstReader指向在无锁状态下第一个获取读锁的线程，firstReaderHoldCount记录第一个获取读锁的线程持有当前锁的计数（主要用于重入）。\n有锁状态无锁状态获取读锁比较简单，在有锁状态则需要分情况讨论。其中需要分当前被持有的锁是读锁还是写锁，并且每种情况需要区分等待队列中是否有等待节点。\n已有读锁且等待队列为空由于本节的前提是等待队列为空的情况，故readerShouldBlock函数一定返回false，则当前线程使用CAS对读锁计数进行增加（同上文，如果同时多个线程在读锁进行竞争，则只有一个线程能够直接获取读锁，其他线程需要进入fullTryAcquireShared函数继续进行锁的获取）。在成功对读锁计数器进行增加后，当前线程需要继续对当前线程持有读锁的计数进行增加。此时分为两种情况：\n\n当前线程是第一个获取读锁的线程，此时由于第一个获取读锁的线程已经通过firstReader及firstReaderHoldCount两个变量进行存储，则仅仅需要将firstReaderHoldCount加1即可;\n当前线程不是第一个获取读锁的线程，则需要使用readHolds进行存储，readHolds是ThreadLocal的子类，通过readHolds可获取当前线程对应的HoldCounter类的对象，该对象保存了当前线程获取读锁的计数。考虑程序的局部性原理，又使用cachedHoldCounter缓存最近使用的HoldCounter类的对象，如在一段时间内只有一个线程请求读锁则可加速对读锁获取的计数。\n\n根据上图所示，thread0为首节点，thread1线程继续申请读锁，获取成功后使用ThreadLocal链接的方式进行存储计数对象，并且由于其为最近获取读锁的线程，则cachedHoldCounter对象设置指向thread1对应的计数对象。\n已有读锁且等待队列不为空上图展示当前thread0与thread1线程获取读锁，thread0为首个获取读锁的节点，并且thread2线程在等待获取写锁。如图所示，在当前锁被为读锁且有等待队列情况下，thread3及thread4线程申请读锁，则被封装为等待节点追加到当前等待队列后，节点模式为SHARED，线程使用LockSupport.park函数进入阻塞状态，让出CPU资源，直到前驱的等待节点完成锁的获取和释放后进行唤醒。\n已有写锁被获取在两种情况下，读锁获取都会进入等待队列等待前序节点唤醒，这里不再赘述。\n读等待节点被唤醒读写锁与单纯的排他锁主要区别在于读锁的共享性，在读写锁实现中保证读锁能够共享的其中一个机制就在于，如果一个读锁等待节点被唤醒后其会继续唤醒拍在当前唤醒节点之后的SHARED模式等待节点。查看源码：\nprivate void doAcquireShared(int arg) &#123;    final Node node = addWaiter(Node.SHARED);    boolean failed = true;    try &#123;        boolean interrupted = false;        for (;;) &#123;            final Node p = node.predecessor();            if (p == head) &#123;                int r = tryAcquireShared(arg);                if (r &gt;= 0) &#123;                    //注意看这里                    setHeadAndPropagate(node, r);                    p.next = null; // help GC                    if (interrupted)                        selfInterrupt();                    failed = false;                    return;                &#125;            &#125;            if (shouldParkAfterFailedAcquire(p, node) &amp;&amp;                parkAndCheckInterrupt())                interrupted = true;        &#125;    &#125; finally &#123;        if (failed)            cancelAcquire(node);    &#125;&#125;\n\n在for循环中，线程如果获取读锁成功后，需要调用setHeadAndPropagate方法。查看其源码：\nprivate void setHeadAndPropagate(Node node, int propagate) &#123;    Node h = head; // Record old head for check below    setHead(node);    if (propagate &gt; 0 || h == null || h.waitStatus &lt; 0 ||        (h = head) == null || h.waitStatus &lt; 0) &#123;        Node s = node.next;        if (s == null || s.isShared())            doReleaseShared();    &#125;&#125;\n\n在满足传播条件情况下，获取读锁后继续唤醒后续节点，所以如果当前锁是读锁状态则等待节点第一个节点一定是写锁等待节点。\n锁降级锁降级算是获取读锁的特例，如在t0线程已经获取写锁的情况下，再调取读锁加锁函数则可以直接获取读锁，但此时其他线程仍然无法获取读锁或写锁，在t0线程释放写锁后，如果有节点等待则会唤醒后续节点，后续节点可见的状态为目前有t0线程获取了读锁。所降级有什么应用场景呢？引用读写锁中使用示例代码\nclass CachedData &#123;    Object data;    volatile boolean cacheValid;    final ReentrantReadWriteLock rwl = new ReentrantReadWriteLock();    void processCachedData() &#123;        rwl.readLock().lock();        if (!cacheValid) &#123;            // Must release read lock before acquiring write lock            rwl.readLock().unlock();            rwl.writeLock().lock();            try &#123;                // Recheck state because another thread might have                // acquired write lock and changed state before we did.                if (!cacheValid) &#123;                    data = ...                        cacheValid = true;                &#125;                // Downgrade by acquiring read lock before releasing write lock                rwl.readLock().lock();            &#125; finally &#123;                rwl.writeLock().unlock(); // Unlock write, still hold read            &#125;        &#125;        try &#123;            use(data);        &#125; finally &#123;            rwl.readLock().unlock();        &#125;    &#125;&#125;\n\n其中针对变量cacheValid的使用主要过程为加读锁、读取、释放读锁、加写锁、修改值、加读锁、释放写锁、使用数据、释放读锁。其中后续几步（加写锁、修改值、加读锁、释放写锁、使用数据、释放读锁）为典型的锁降级。如果不使用锁降级，则过程可能有三种情况：\n\n第一种：加写锁、修改值、释放写锁、使用数据，即使用写锁修改数据后直接使用刚修改的数据，这样可能有数据的不一致，如当前线程释放写锁的同时其他线程（如t0）获取写锁准备修改（还没有改）cacheValid变量，而当前线程却继续运行，则当前线程读到的cacheValid变量的值为t0修改前的老数据；\n第二种：加写锁、修改值、使用数据、释放写锁，即将修改数据与再次使用数据合二为一，这样不会有数据的不一致，但是由于混用了读写两个过程，以排它锁的方式使用读写锁，减弱了读写锁读共享的优势，增加了写锁（独占锁）的占用时间；\n第三种：加写锁、修改值、释放写锁、加读锁、使用数据、释放读锁，即使用写锁修改数据后再请求读锁来使用数据，这是时数据的一致性是可以得到保证的，但是由于释放写锁和获取读锁之间存在时间差，则当前想成可能会需要进入等待队列进行等待，可能造成线程的阻塞降低吞吐量。\n\n因此针对以上情况提供了锁的降级功能，可以在完成数据修改后尽快读取最新的值，且能够减少写锁占用时间。最后注意，读写锁不支持锁升级，即获取读锁、读数据、获取写锁、释放读锁、释放写锁这个过程，因为读锁为共享锁，如同时有多个线程获取了读锁后有一个线程进行锁升级获取了写锁，这会造成同时有读锁（其他线程）和写锁的情况，造成其他线程可能无法感知新修改的数据（此为逻辑性错误），并且在JAVA读写锁实现上由于当前线程获取了读锁，再次请求写锁时必然会阻塞而导致后续释放读锁的方法无法执行，这回造成死锁（此为功能性错误）。\n写锁释放锁过程了解了加锁过程后解锁过程就非常简单，每次调用解锁方法都会减少重入计数次数，直到减为0则唤醒后续第一个等待节点，如唤醒的后续节点为读等待节点，则后续节点会继续传播唤醒状态。\n读锁释放过程读锁释放过比写锁稍微复杂，因为是共享锁，所以可能会有多个线程同时获取读锁，故在解锁时需要做两件事：\n\n获取当前线程对应的重入计数，并进行减1，此处天生为线程安全的，不需要特殊处理；\n当前读锁获取次数减1，此处由于可能存在多线程竞争，故使用自旋CAS进行设置。\n\n完成以上两步后，如读状态为0，则唤醒后续等待节点。\n总结根据以上分析，本文主要展示了读写锁的场景及方式，并分析读写锁核心功能（加解锁）的代码实现。Java读写锁同时附带了更多其他方法，包括锁状态监控和带超时机制的加锁方法等，本文不在赘述。并且读写锁中写锁可使用Conditon机制也不在详细说明。\n","tags":["Java"]},{"title":"排序算法","url":"/2020/03/23/%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95/","content":"\n来源：https://github.com/hustcc/JS-Sorting-Algorithm\n分享只为更多人受益，如有侵权请联系删除！\n\n总览\n一、冒泡排序冒泡排序（Bubble Sort）也是一种简单直观的排序算法。它重复地走访过要排序的数列，一次比较两个元素，如果他们的顺序错误就把他们交换过来。走访数列的工作是重复地进行直到没有再需要交换，也就是说该数列已经排序完成。这个算法的名字由来是因为越小的元素会经由交换慢慢“浮”到数列的顶端。\n作为最简单的排序算法之一，冒泡排序给我的感觉就像 Abandon 在单词书里出现的感觉一样，每次都在第一页第一位，所以最熟悉。冒泡排序还有一种优化算法，就是立一个 flag，当在一趟序列遍历中元素没有发生交换，则证明该序列已经有序。但这种改进对于提升性能来说并没有什么太大作用。\n1. 算法步骤\n比较相邻的元素。如果第一个比第二个大，就交换他们两个。\n\n对每一对相邻元素作同样的工作，从开始第一对到结尾的最后一对。这步做完后，最后的元素会是最大的数。\n\n针对所有的元素重复以上的步骤，除了最后一个。\n\n持续每次对越来越少的元素重复上面的步骤，直到没有任何一对数字需要比较。\n\n\n2. 动图演示\n3. 什么时候最快当输入的数据已经是正序时（都已经是正序了，我还要你冒泡排序有何用啊）。\n4. 什么时候最慢当输入的数据是反序时（写一个 for 循环反序输出数据不就行了，干嘛要用你冒泡排序呢，我是闲的吗）。\n5. Java代码实现public class BubbleSort implements IArraySort &#123;  @Override  public int[] sort(int[] sourceArray) throws Exception &#123;    // 对 arr 进行拷贝，不改变参数内容    int[] arr = Arrays.copyOf(sourceArray, sourceArray.length);    for (int i = 1; i &lt; arr.length; i++) &#123;      // 设定一个标记，若为true，则表示此次循环没有进行交换，也就是待排序列已经有序，排序已经完成。      boolean flag = true;      for (int j = 0; j &lt; arr.length - i; j++) &#123;        if (arr[j] &gt; arr[j + 1]) &#123;          int tmp = arr[j];          arr[j] = arr[j + 1];          arr[j + 1] = tmp;          flag = false;        &#125;      &#125;      if (flag) &#123;        break;      &#125;    &#125;    return arr;  &#125;&#125;\n\n二、选择排序选择排序是一种简单直观的排序算法，无论什么数据进去都是 O(n²) 的时间复杂度。所以用到它的时候，数据规模越小越好。唯一的好处可能就是不占用额外的内存空间了吧。\n1. 算法步骤\n首先在未排序序列中找到最小（大）元素，存放到排序序列的起始位置\n\n再从剩余未排序元素中继续寻找最小（大）元素，然后放到已排序序列的末尾。\n\n重复第二步，直到所有元素均排序完毕。\n\n\n2. 动图演示\n3.Java代码实现public class SelectionSort implements IArraySort &#123;  @Override  public int[] sort(int[] sourceArray) throws Exception &#123;    int[] arr = Arrays.copyOf(sourceArray, sourceArray.length);    // 总共要经过 N-1 轮比较    for (int i = 0; i &lt; arr.length - 1; i++) &#123;      int min = i;      // 每轮需要比较的次数 N-i      for (int j = i + 1; j &lt; arr.length; j++) &#123;        if (arr[j] &lt; arr[min]) &#123;          // 记录目前能找到的最小值元素的下标          min = j;        &#125;      &#125;      // 将找到的最小值和i位置所在的值进行交换      if (i != min) &#123;        int tmp = arr[i];        arr[i] = arr[min];        arr[min] = tmp;      &#125;    &#125;    return arr;  &#125;&#125;\n\n三、插入排序插入排序的代码实现虽然没有冒泡排序和选择排序那么简单粗暴，但它的原理应该是最容易理解的了，因为只要打过扑克牌的人都应该能够秒懂。插入排序是一种最简单直观的排序算法，它的工作原理是通过构建有序序列，对于未排序数据，在已排序序列中从后向前扫描，找到相应位置并插入。\n插入排序和冒泡排序一样，也有一种优化算法，叫做拆半插入。\n1. 算法步骤\n将第一待排序序列第一个元素看做一个有序序列，把第二个元素到最后一个元素当成是未排序序列。\n\n从头到尾依次扫描未排序序列，将扫描到的每个元素插入有序序列的适当位置。（如果待插入的元素与有序序列中的某个元素相等，则将待插入元素插入到相等元素的后面。）\n\n\n2. 动图演示\n3. Java 代码实现public class InsertSort implements IArraySort &#123;  @Override  public int[] sort(int[] sourceArray) throws Exception &#123;    // 对 arr 进行拷贝，不改变参数内容    int[] arr = Arrays.copyOf(sourceArray, sourceArray.length);    // 从下标为1的元素开始选择合适的位置插入，因为下标为0的只有一个元素，默认是有序的    for (int i = 1; i &lt; arr.length; i++) &#123;      // 记录要插入的数据      int tmp = arr[i];      // 从已经排序的序列最右边的开始比较，找到比其小的数      int j = i;      while (j &gt; 0 &amp;&amp; tmp &lt; arr[j - 1]) &#123;        arr[j] = arr[j - 1];        j--;      &#125;      // 存在比其小的数，插入      if (j != i) &#123;        arr[j] = tmp;      &#125;    &#125;    return arr;  &#125;&#125;\n\n四、希尔排序希尔排序，也称递减增量排序算法，是插入排序的一种更高效的改进版本。但希尔排序是非稳定排序算法。\n希尔排序是基于插入排序的以下两点性质而提出改进方法的：\n\n插入排序在对几乎已经排好序的数据操作时，效率高，即可以达到线性排序的效率；\n但插入排序一般来说是低效的，因为插入排序每次只能将数据移动一位；\n\n希尔排序的基本思想是：先将整个待排序的记录序列分割成为若干子序列分别进行直接插入排序，待整个序列中的记录“基本有序”时，再对全体记录进行依次直接插入排序。\n1. 算法步骤\n选择一个增量序列 t1，t2，……，tk，其中 ti &gt; tj, tk = 1；\n按增量序列个数 k，对序列进行 k 趟排序；\n每趟排序，根据对应的增量 ti，将待排序列分割成若干长度为 m 的子序列，分别对各子表进行直接插入排序。仅增量因子为 1 时，整个序列作为一个表来处理，表长度即为整个序列的长度。\n\n2. Java 代码实现public class ShellSort implements IArraySort &#123;  @Override  public int[] sort(int[] sourceArray) throws Exception &#123;    // 对 arr 进行拷贝，不改变参数内容    int[] arr = Arrays.copyOf(sourceArray, sourceArray.length);    int gap = 1;    while (gap &lt; arr.length/3) &#123;      gap = gap * 3 + 1;    &#125;    while (gap &gt; 0) &#123;      for (int i = gap; i &lt; arr.length; i++) &#123;        int tmp = arr[i];        int j = i - gap;        while (j &gt;= 0 &amp;&amp; arr[j] &gt; tmp) &#123;          arr[j + gap] = arr[j];          j -= gap;        &#125;        arr[j + gap] = tmp;      &#125;      gap = (int) Math.floor(gap / 3);    &#125;    return arr;  &#125;&#125;\n\n五、归并排序归并排序（Merge sort）是建立在归并操作上的一种有效的排序算法。该算法是采用分治法（Divide and Conquer）的一个非常典型的应用。\n作为一种典型的分而治之思想的算法应用，归并排序的实现由两种方法：\n\n自上而下的递归（所有递归的方法都可以用迭代重写，所以就有了第 2 种方法）；\n自下而上的迭代；\n\n和选择排序一样，归并排序的性能不受输入数据的影响，但表现比选择排序好的多，因为始终都是 O(nlogn) 的时间复杂度。代价是需要额外的内存空间。\n2. 算法步骤\n申请空间，使其大小为两个已经排序序列之和，该空间用来存放合并后的序列；\n\n设定两个指针，最初位置分别为两个已经排序序列的起始位置；\n\n比较两个指针所指向的元素，选择相对小的元素放入到合并空间，并移动指针到下一位置；\n\n重复步骤 3 直到某一指针达到序列尾；\n\n将另一序列剩下的所有元素直接复制到合并序列尾。\n\n\n3. 动图演示\n4. Java 代码实现public class MergeSort implements IArraySort &#123;  @Override  public int[] sort(int[] sourceArray) throws Exception &#123;    // 对 arr 进行拷贝，不改变参数内容    int[] arr = Arrays.copyOf(sourceArray, sourceArray.length);    if (arr.length &lt; 2) &#123;      return arr;    &#125;    int middle = (int) Math.floor(arr.length / 2);    int[] left = Arrays.copyOfRange(arr, 0, middle);    int[] right = Arrays.copyOfRange(arr, middle, arr.length);    return merge(sort(left), sort(right));  &#125;  protected int[] merge(int[] left, int[] right) &#123;    int[] result = new int[left.length + right.length];    int i = 0;    while (left.length &gt; 0 &amp;&amp; right.length &gt; 0) &#123;      if (left[0] &lt;= right[0]) &#123;        result[i++] = left[0];        left = Arrays.copyOfRange(left, 1, left.length);      &#125; else &#123;        result[i++] = right[0];        right = Arrays.copyOfRange(right, 1, right.length);      &#125;    &#125;    while (left.length &gt; 0) &#123;      result[i++] = left[0];      left = Arrays.copyOfRange(left, 1, left.length);    &#125;    while (right.length &gt; 0) &#123;      result[i++] = right[0];      right = Arrays.copyOfRange(right, 1, right.length);    &#125;    return result;  &#125;&#125;\n\n六、快速排序快速排序是由东尼·霍尔所发展的一种排序算法。在平均状况下，排序 n 个项目要 Ο(nlogn) 次比较。在最坏状况下则需要 Ο(n2) 次比较，但这种状况并不常见。事实上，快速排序通常明显比其他 Ο(nlogn) 算法更快，因为它的内部循环（inner loop）可以在大部分的架构上很有效率地被实现出来。\n快速排序使用分治法（Divide and conquer）策略来把一个串行（list）分为两个子串行（sub-lists）。\n快速排序又是一种分而治之思想在排序算法上的典型应用。本质上来看，快速排序应该算是在冒泡排序基础上的递归分治法。\n\n快速排序的最坏运行情况是 O(n²)，比如说顺序数列的快排。但它的平摊期望时间是 O(nlogn)，且 O(nlogn) 记号中隐含的常数因子很小，比复杂度稳定等于 O(nlogn) 的归并排序要小很多。所以，对绝大多数顺序性较弱的随机数列而言，快速排序总是优于归并排序。\n\n1. 算法步骤\n从数列中挑出一个元素，称为 “基准”（pivot）;\n\n重新排序数列，所有元素比基准值小的摆放在基准前面，所有元素比基准值大的摆在基准的后面（相同的数可以到任一边）。在这个分区退出之后，该基准就处于数列的中间位置。这个称为分区（partition）操作；\n\n递归地（recursive）把小于基准值元素的子数列和大于基准值元素的子数列排序；\n\n\n递归的最底部情形，是数列的大小是零或一，也就是永远都已经被排序好了。虽然一直递归下去，但是这个算法总会退出，因为在每次的迭代（iteration）中，它至少会把一个元素摆到它最后的位置去。\n2. 动图演示\n3. Java 代码实现public class QuickSort implements IArraySort &#123;  @Override  public int[] sort(int[] sourceArray) throws Exception &#123;    // 对 arr 进行拷贝，不改变参数内容    int[] arr = Arrays.copyOf(sourceArray, sourceArray.length);    return quickSort(arr, 0, arr.length - 1);  &#125;  private int[] quickSort(int[] arr, int left, int right) &#123;    if (left &lt; right) &#123;      int partitionIndex = partition(arr, left, right);      quickSort(arr, left, partitionIndex - 1);      quickSort(arr, partitionIndex + 1, right);    &#125;    return arr;  &#125;  private int partition(int[] arr, int left, int right) &#123;    // 设定基准值（pivot）    int pivot = left;    int index = pivot + 1;    for (int i = index; i &lt;= right; i++) &#123;      if (arr[i] &lt; arr[pivot]) &#123;        swap(arr, i, index);        index++;      &#125;    &#125;    swap(arr, pivot, index - 1);    return index - 1;  &#125;  private void swap(int[] arr, int i, int j) &#123;    int temp = arr[i];    arr[i] = arr[j];    arr[j] = temp;  &#125;&#125;\n\n七、堆排序堆排序（Heapsort）是指利用堆这种数据结构所设计的一种排序算法。堆积是一个近似完全二叉树的结构，并同时满足堆积的性质：即子结点的键值或索引总是小于（或者大于）它的父节点。堆排序可以说是一种利用堆的概念来排序的选择排序。分为两种方法：\n\n大顶堆：每个节点的值都大于或等于其子节点的值，在堆排序算法中用于升序排列；\n小顶堆：每个节点的值都小于或等于其子节点的值，在堆排序算法中用于降序排列；\n\n堆排序的平均时间复杂度为 Ο(nlogn)。\n1. 算法步骤\n将待排序序列构建成一个堆 H[0……n-1]，根据（升序降序需求）选择大顶堆或小顶堆；\n\n把堆首（最大值）和堆尾互换；\n\n把堆的尺寸缩小 1，并调用 shift_down(0)，目的是把新的数组顶端数据调整到相应位置；\n\n重复步骤 2，直到堆的尺寸为 1。\n\n\n2. 动图演示\n3. Java 代码实现public class HeapSort implements IArraySort &#123;  @Override  public int[] sort(int[] sourceArray) throws Exception &#123;    // 对 arr 进行拷贝，不改变参数内容    int[] arr = Arrays.copyOf(sourceArray, sourceArray.length);    int len = arr.length;    buildMaxHeap(arr, len);    for (int i = len - 1; i &gt; 0; i--) &#123;      swap(arr, 0, i);      len--;      heapify(arr, 0, len);    &#125;    return arr;  &#125;  private void buildMaxHeap(int[] arr, int len) &#123;    for (int i = (int) Math.floor(len / 2); i &gt;= 0; i--) &#123;      heapify(arr, i, len);    &#125;  &#125;  private void heapify(int[] arr, int i, int len) &#123;    int left = 2 * i + 1;    int right = 2 * i + 2;    int largest = i;    if (left &lt; len &amp;&amp; arr[left] &gt; arr[largest]) &#123;      largest = left;    &#125;    if (right &lt; len &amp;&amp; arr[right] &gt; arr[largest]) &#123;      largest = right;    &#125;    if (largest != i) &#123;      swap(arr, i, largest);      heapify(arr, largest, len);    &#125;  &#125;  private void swap(int[] arr, int i, int j) &#123;    int temp = arr[i];    arr[i] = arr[j];    arr[j] = temp;  &#125;&#125;\n\n八、计数排序计数排序的核心在于将输入的数据值转化为键存储在额外开辟的数组空间中。作为一种线性时间复杂度的排序，计数排序要求输入的数据必须是有确定范围的整数。\n1. 动图演示\n2. Java 代码实现public class CountingSort implements IArraySort &#123;  @Override  public int[] sort(int[] sourceArray) throws Exception &#123;    // 对 arr 进行拷贝，不改变参数内容    int[] arr = Arrays.copyOf(sourceArray, sourceArray.length);    int maxValue = getMaxValue(arr);    return countingSort(arr, maxValue);  &#125;  private int[] countingSort(int[] arr, int maxValue) &#123;    int bucketLen = maxValue + 1;    int[] bucket = new int[bucketLen];    for (int value : arr) &#123;      bucket[value]++;    &#125;    int sortedIndex = 0;    for (int j = 0; j &lt; bucketLen; j++) &#123;      while (bucket[j] &gt; 0) &#123;        arr[sortedIndex++] = j;        bucket[j]--;      &#125;    &#125;    return arr;  &#125;  private int getMaxValue(int[] arr) &#123;    int maxValue = arr[0];    for (int value : arr) &#123;      if (maxValue &lt; value) &#123;        maxValue = value;      &#125;    &#125;    return maxValue;  &#125;&#125;\n\n九、桶排序桶排序是计数排序的升级版。它利用了函数的映射关系，高效与否的关键就在于这个映射函数的确定。为了使桶排序更加高效，我们需要做到这两点：\n\n在额外空间充足的情况下，尽量增大桶的数量\n使用的映射函数能够将输入的 N 个数据均匀的分配到 K 个桶中\n\n同时，对于桶中元素的排序，选择何种比较排序算法对于性能的影响至关重要。\n1. 什么时候最快当输入的数据可以均匀的分配到每一个桶中。\n2. 什么时候最慢当输入的数据被分配到了同一个桶中。\n3. Java 代码实现public class BucketSort implements IArraySort &#123;  private static final InsertSort insertSort = new InsertSort();  @Override  public int[] sort(int[] sourceArray) throws Exception &#123;    // 对 arr 进行拷贝，不改变参数内容    int[] arr = Arrays.copyOf(sourceArray, sourceArray.length);    return bucketSort(arr, 5);  &#125;  private int[] bucketSort(int[] arr, int bucketSize) throws Exception &#123;    if (arr.length == 0) &#123;      return arr;    &#125;    int minValue = arr[0];    int maxValue = arr[0];    for (int value : arr) &#123;      if (value &lt; minValue) &#123;        minValue = value;      &#125; else if (value &gt; maxValue) &#123;        maxValue = value;      &#125;    &#125;    int bucketCount = (int) Math.floor((maxValue - minValue) / bucketSize) + 1;    int[][] buckets = new int[bucketCount][0];    // 利用映射函数将数据分配到各个桶中    for (int i = 0; i &lt; arr.length; i++) &#123;      int index = (int) Math.floor((arr[i] - minValue) / bucketSize);      buckets[index] = arrAppend(buckets[index], arr[i]);    &#125;    int arrIndex = 0;    for (int[] bucket : buckets) &#123;      if (bucket.length &lt;= 0) &#123;        continue;      &#125;      // 对每个桶进行排序，这里使用了插入排序      bucket = insertSort.sort(bucket);      for (int value : bucket) &#123;        arr[arrIndex++] = value;      &#125;    &#125;    return arr;  &#125;  /**     * 自动扩容，并保存数据     *     * @param arr     * @param value     */  private int[] arrAppend(int[] arr, int value) &#123;    arr = Arrays.copyOf(arr, arr.length + 1);    arr[arr.length - 1] = value;    return arr;  &#125;&#125;\n\n十、基数排序基数排序是一种非比较型整数排序算法，其原理是将整数按位数切割成不同的数字，然后按每个位数分别比较。由于整数也可以表达字符串（比如名字或日期）和特定格式的浮点数，所以基数排序也不是只能使用于整数。\n1. 基数排序 vs 计数排序 vs 桶排序基数排序有两种方法：\n这三种排序算法都利用了桶的概念，但对桶的使用方法上有明显差异案例看大家发的：\n\n基数排序：根据键值的每位数字来分配桶；\n计数排序：每个桶只存储单一键值；\n桶排序：每个桶存储一定范围的数值；\n\n2. LSD 基数排序动图演示\n3. Java 代码实现/** * 基数排序 * 考虑负数的情况还可以参考： https://code.i-harness.com/zh-CN/q/e98fa9 */public class RadixSort implements IArraySort &#123;  @Override  public int[] sort(int[] sourceArray) throws Exception &#123;    // 对 arr 进行拷贝，不改变参数内容    int[] arr = Arrays.copyOf(sourceArray, sourceArray.length);    int maxDigit = getMaxDigit(arr);    return radixSort(arr, maxDigit);  &#125;  /**     * 获取最高位数     */  private int getMaxDigit(int[] arr) &#123;    int maxValue = getMaxValue(arr);    return getNumLenght(maxValue);  &#125;  private int getMaxValue(int[] arr) &#123;    int maxValue = arr[0];    for (int value : arr) &#123;      if (maxValue &lt; value) &#123;        maxValue = value;      &#125;    &#125;    return maxValue;  &#125;  protected int getNumLenght(long num) &#123;    if (num == 0) &#123;      return 1;    &#125;    int lenght = 0;    for (long temp = num; temp != 0; temp /= 10) &#123;      lenght++;    &#125;    return lenght;  &#125;  private int[] radixSort(int[] arr, int maxDigit) &#123;    int mod = 10;    int dev = 1;    for (int i = 0; i &lt; maxDigit; i++, dev *= 10, mod *= 10) &#123;      // 考虑负数的情况，这里扩展一倍队列数，其中 [0-9]对应负数，[10-19]对应正数 (bucket + 10)      int[][] counter = new int[mod * 2][0];      for (int j = 0; j &lt; arr.length; j++) &#123;        int bucket = ((arr[j] % mod) / dev) + mod;        counter[bucket] = arrayAppend(counter[bucket], arr[j]);      &#125;      int pos = 0;      for (int[] bucket : counter) &#123;        for (int value : bucket) &#123;          arr[pos++] = value;        &#125;      &#125;    &#125;    return arr;  &#125;  /**     * 自动扩容，并保存数据     *     * @param arr     * @param value     */  private int[] arrayAppend(int[] arr, int value) &#123;    arr = Arrays.copyOf(arr, arr.length + 1);    arr[arr.length - 1] = value;    return arr;  &#125;&#125;\n","tags":["算法相关"]},{"title":"Java中各种锁详细介绍","url":"/2020/04/07/Java%E4%B8%AD%E5%90%84%E7%A7%8D%E9%94%81%E8%AF%A6%E7%BB%86%E4%BB%8B%E7%BB%8D/","content":"\n转自：https://www.cnblogs.com/jyroy/p/11365935.html\n相关文章：https://www.cnblogs.com/hustzzl/p/9343797.html\nhttps://www.jianshu.com/p/e674ee68fd3f\nhttps://mp.weixin.qq.com/s/-fDGn-AIYJ64Q1MlqpDiBg\n\nJava提供了种类丰富的锁，每种锁因其特性的不同，在适当的场景下能够展现出非常高的效率。本文旨在对锁相关源码（本文中的源码来自JDK 8）、使用场景进行举例，为读者介绍主流锁的知识点，以及不同的锁的适用场景。\nJava中往往是按照是否含有某一特性来定义锁，我们通过特性将锁进行分组归类，再使用对比的方式进行介绍，帮助大家更快捷的理解相关知识。下面给出本文内容的总体分类目录：\n\n1. 乐观锁 VS 悲观锁乐观锁与悲观锁是一种广义上的概念，体现了看待线程同步的不同角度。在Java和数据库中都有此概念对应的实际应用。\n先说概念。对于同一个数据的并发操作，悲观锁认为自己在使用数据的时候一定有别的线程来修改数据，因此在获取数据的时候会先加锁，确保数据不会被别的线程修改。Java中，synchronized关键字和Lock的实现类都是悲观锁。\n而乐观锁认为自己在使用数据时不会有别的线程修改数据，所以不会添加锁，只是在更新数据的时候去判断之前有没有别的线程更新了这个数据。如果这个数据没有被更新，当前线程将自己修改的数据成功写入。如果数据已经被其他线程更新，则根据不同的实现方式执行不同的操作（例如报错或者自动重试）。\n乐观锁在Java中是通过使用无锁编程来实现，最常采用的是CAS算法，Java原子类中的递增操作就通过CAS自旋实现的。\n\n根据从上面的概念描述我们可以发现：\n\n悲观锁适合写操作多的场景，先加锁可以保证写操作时数据正确。\n乐观锁适合读操作多的场景，不加锁的特点能够使其读操作的性能大幅提升。\n\n光说概念有些抽象，我们来看下乐观锁和悲观锁的调用方式示例：\n\n通过调用方式示例，我们可以发现悲观锁基本都是在显式的锁定之后再操作同步资源，而乐观锁则直接去操作同步资源。那么，为何乐观锁能够做到不锁定同步资源也可以正确的实现线程同步呢？我们通过介绍乐观锁的主要实现方式 “CAS” 的技术原理来为大家解惑。\nCAS全称 Compare And Swap（比较与交换），是一种无锁算法。在不使用锁（没有线程被阻塞）的情况下实现多线程之间的变量同步。java.util.concurrent包中的原子类就是通过CAS来实现了乐观锁。\nCAS算法涉及到三个操作数：\n\n需要读写的内存值 V。\n进行比较的值 A。\n要写入的新值 B。\n\n当且仅当 V 的值等于 A 时，CAS通过原子方式用新值B来更新V的值（“比较+更新”整体是一个原子操作），否则不会执行任何操作。一般情况下，“更新”是一个不断重试的操作。\n之前提到java.util.concurrent包中的原子类，就是通过CAS来实现了乐观锁，那么我们进入原子类AtomicInteger的源码，看一下AtomicInteger的定义：\n\n根据定义我们可以看出各属性的作用：\n\nunsafe： 获取并操作内存的数据。\nvalueOffset： 存储value在AtomicInteger中的偏移量。\nvalue： 存储AtomicInteger的int值，该属性需要借助volatile关键字保证其在线程间是可见的。\n\n接下来，我们查看AtomicInteger的自增函数incrementAndGet()的源码时，发现自增函数底层调用的是unsafe.getAndAddInt()。但是由于JDK本身只有Unsafe.class，只通过class文件中的参数名，并不能很好的了解方法的作用，所以我们通过OpenJDK 8 来查看Unsafe的源码：\n\n根据OpenJDK 8的源码我们可以看出，getAndAddInt()循环获取给定对象o中的偏移量处的值v，然后判断内存值是否等于v。如果相等则将内存值设置为 v + delta，否则返回false，继续循环进行重试，直到设置成功才能退出循环，并且将旧值返回。整个“比较+更新”操作封装在compareAndSwapInt()中，在JNI里是借助于一个CPU指令完成的，属于原子操作，可以保证多个线程都能够看到同一个变量的修改值。\n后续JDK通过CPU的cmpxchg指令，去比较寄存器中的 A 和 内存中的值 V。如果相等，就把要写入的新值 B 存入内存中。如果不相等，就将内存值 V 赋值给寄存器中的值 A。然后通过Java代码中的while循环再次调用cmpxchg指令进行重试，直到设置成功为止。\nCAS虽然很高效，但是它也存在三大问题，这里也简单说一下：\n\nABA问题。CAS需要在操作值的时候检查内存值是否发生变化，没有发生变化才会更新内存值。但是如果内存值原来是A，后来变成了B，然后又变成了A，那么CAS进行检查时会发现值没有发生变化，但是实际上是有变化的。ABA问题的解决思路就是在变量前面添加版本号，每次变量更新的时候都把版本号加一，这样变化过程就从“A－B－A”变成了“1A－2B－3A”。\n\nJDK从1.5开始提供了AtomicStampedReference类来解决ABA问题，具体操作封装在compareAndSet()中。compareAndSet()首先检查当前引用和当前标志与预期引用和预期标志是否相等，如果都相等，则以原子方式将引用值和标志的值设置为给定的更新值。\n\n循环时间长开销大。CAS操作如果长时间不成功，会导致其一直自旋，给CPU带来非常大的开销。\n\n只能保证一个共享变量的原子操作。对一个共享变量执行操作时，CAS能够保证原子操作，但是对多个共享变量操作时，CAS是无法保证操作的原子性的。\n\n\nJava从1.5开始JDK提供了AtomicReference类来保证引用对象之间的原子性，可以把多个变量放在一个对象里来进行CAS操作。\n2. 自旋锁 VS 适应性自旋锁在介绍自旋锁前，我们需要介绍一些前提知识来帮助大家明白自旋锁的概念。\n阻塞或唤醒一个Java线程需要操作系统切换CPU状态来完成，这种状态转换需要耗费处理器时间。如果同步代码块中的内容过于简单，状态转换消耗的时间有可能比用户代码执行的时间还要长。\n在许多场景中，同步资源的锁定时间很短，为了这一小段时间去切换线程，线程挂起和恢复现场的花费可能会让系统得不偿失。如果物理机器有多个处理器，能够让两个或以上的线程同时并行执行，我们就可以让后面那个请求锁的线程不放弃CPU的执行时间，看看持有锁的线程是否很快就会释放锁。\n而为了让当前线程“稍等一下”，我们需让当前线程进行自旋，如果在自旋完成后前面锁定同步资源的线程已经释放了锁，那么当前线程就可以不必阻塞而是直接获取同步资源，从而避免切换线程的开销。这就是自旋锁。\n\n自旋锁本身是有缺点的，它不能代替阻塞。自旋等待虽然避免了线程切换的开销，但它要占用处理器时间。如果锁被占用的时间很短，自旋等待的效果就会非常好。反之，如果锁被占用的时间很长，那么自旋的线程只会白浪费处理器资源。所以，自旋等待的时间必须要有一定的限度，如果自旋超过了限定次数（默认是10次，可以使用-XX:PreBLockSpin来更改）没有成功获得锁，就应当挂起线程。\n自旋锁的实现原理同样也是CAS，AtomicInteger中调用unsafe进行自增操作的源码中的do-while循环就是一个自旋操作，如果修改数值失败则通过循环来执行自旋，直至修改成功。\n\n自旋锁在JDK1.4.2中引入，使用-XX:+UseSpinning来开启。JDK 6中变为默认开启，并且引入了自适应的自旋锁（适应性自旋锁）。\n自适应意味着自旋的时间（次数）不再固定，而是由前一次在同一个锁上的自旋时间及锁的拥有者的状态来决定。如果在同一个锁对象上，自旋等待刚刚成功获得过锁，并且持有锁的线程正在运行中，那么虚拟机就会认为这次自旋也是很有可能再次成功，进而它将允许自旋等待持续相对更长的时间。如果对于某个锁，自旋很少成功获得过，那在以后尝试获取这个锁时将可能省略掉自旋过程，直接阻塞线程，避免浪费处理器资源。\n在自旋锁中 另有三种常见的锁形式:TicketLock、CLHLock和MCSLock，本文中仅做名词介绍，不做深入讲解，感兴趣的同学可以自行查阅相关资料。\n3. 无锁 VS 偏向锁 VS 轻量级锁 VS 重量级锁这四种锁是指锁的状态，专门针对synchronized的。在介绍这四种锁状态之前还需要介绍一些额外的知识。\n首先为什么synchronized能实现线程同步？\n在回答这个问题之前我们需要了解两个重要的概念：“Java对象头”、“Monitor”。\n\nJava对象头\n\nsynchronized是悲观锁，在操作同步资源之前需要给同步资源先加锁，这把锁就是存在Java对象头里的，而Java对象头又是什么呢？\n我们以Hotspot虚拟机为例，Hotspot的对象头主要包括两部分数据：Mark Word（标记字段）、Klass Pointer（类型指针）。\nMark Word：默认存储对象的HashCode，分代年龄和锁标志位信息。这些信息都是与对象自身定义无关的数据，所以Mark Word被设计成一个非固定的数据结构以便在极小的空间内存存储尽量多的数据。它会根据对象的状态复用自己的存储空间，也就是说在运行期间Mark Word里存储的数据会随着锁标志位的变化而变化。\nKlass Point：对象指向它的类元数据的指针，虚拟机通过这个指针来确定这个对象是哪个类的实例。\n\nMonitor\n\nMonitor可以理解为一个同步工具或一种同步机制，通常被描述为一个对象。每一个Java对象就有一把看不见的锁，称为内部锁或者Monitor锁。\nMonitor是线程私有的数据结构，每一个线程都有一个可用monitor record列表，同时还有一个全局的可用列表。每一个被锁住的对象都会和一个monitor关联，同时monitor中有一个Owner字段存放拥有该锁的线程的唯一标识，表示该锁被这个线程占用。\n现在话题回到synchronized，synchronized通过Monitor来实现线程同步，Monitor是依赖于底层的操作系统的Mutex Lock（互斥锁）来实现的线程同步。\n如同我们在自旋锁中提到的“阻塞或唤醒一个Java线程需要操作系统切换CPU状态来完成，这种状态转换需要耗费处理器时间。如果同步代码块中的内容过于简单，状态转换消耗的时间有可能比用户代码执行的时间还要长”。这种方式就是synchronized最初实现同步的方式，这就是JDK 6之前synchronized效率低的原因。这种依赖于操作系统Mutex Lock所实现的锁我们称之为“重量级锁”，JDK 6中为了减少获得锁和释放锁带来的性能消耗，引入了“偏向锁”和“轻量级锁”。\n所以目前锁一共有4种状态，级别从低到高依次是：无锁、偏向锁、轻量级锁和重量级锁。锁状态只能升级不能降级。\n通过上面的介绍，我们对synchronized的加锁机制以及相关知识有了一个了解，那么下面我们给出四种锁状态对应的的Mark Word内容，然后再分别讲解四种锁状态的思路以及特点：\n\n无锁无锁没有对资源进行锁定，所有的线程都能访问并修改同一个资源，但同时只有一个线程能修改成功。\n无锁的特点就是修改操作在循环内进行，线程会不断的尝试修改共享资源。如果没有冲突就修改成功并退出，否则就会继续循环尝试。如果有多个线程修改同一个值，必定会有一个线程能修改成功，而其他修改失败的线程会不断重试直到修改成功。上面我们介绍的CAS原理及应用即是无锁的实现。无锁无法全面代替有锁，但无锁在某些场合下的性能是非常高的。\n偏向锁偏向锁是指一段同步代码一直被一个线程所访问，那么该线程会自动获取锁，降低获取锁的代价。\n在大多数情况下，锁总是由同一线程多次获得，不存在多线程竞争，所以出现了偏向锁。其目标就是在只有一个线程执行同步代码块时能够提高性能。\n当一个线程访问同步代码块并获取锁时，会在Mark Word里存储锁偏向的线程ID。在线程进入和退出同步块时不再通过CAS操作来加锁和解锁，而是检测Mark Word里是否存储着指向当前线程的偏向锁。引入偏向锁是为了在无多线程竞争的情况下尽量减少不必要的轻量级锁执行路径，因为轻量级锁的获取及释放依赖多次CAS原子指令，而偏向锁只需要在置换ThreadID的时候依赖一次CAS原子指令即可。\n偏向锁只有遇到其他线程尝试竞争偏向锁时，持有偏向锁的线程才会释放锁，线程不会主动释放偏向锁。偏向锁的撤销，需要等待全局安全点（在这个时间点上没有字节码正在执行），它会首先暂停拥有偏向锁的线程，判断锁对象是否处于被锁定状态。撤销偏向锁后恢复到无锁（标志位为“01”）或轻量级锁（标志位为“00”）的状态。\n偏向锁在JDK 6及以后的JVM里是默认启用的。可以通过JVM参数关闭偏向锁：-XX:-UseBiasedLocking=false，关闭之后程序默认会进入轻量级锁状态。\n轻量级锁是指当锁是偏向锁的时候，被另外的线程所访问，偏向锁就会升级为轻量级锁，其他线程会通过自旋的形式尝试获取锁，不会阻塞，从而提高性能。\n在代码进入同步块的时候，如果同步对象锁状态为无锁状态（锁标志位为“01”状态，是否为偏向锁为“0”），虚拟机首先将在当前线程的栈帧中建立一个名为锁记录（Lock Record）的空间，用于存储锁对象目前的Mark Word的拷贝，然后拷贝对象头中的Mark Word复制到锁记录中。\n拷贝成功后，虚拟机将使用CAS操作尝试将对象的Mark Word更新为指向Lock Record的指针，并将Lock Record里的owner指针指向对象的Mark Word。\n如果这个更新动作成功了，那么这个线程就拥有了该对象的锁，并且对象Mark Word的锁标志位设置为“00”，表示此对象处于轻量级锁定状态。\n如果轻量级锁的更新操作失败了，虚拟机首先会检查对象的Mark Word是否指向当前线程的栈帧，如果是就说明当前线程已经拥有了这个对象的锁，那就可以直接进入同步块继续执行，否则说明多个线程竞争锁。\n若当前只有一个等待线程，则该线程通过自旋进行等待。但是当自旋超过一定的次数，或者一个线程在持有锁，一个在自旋，又有第三个来访时，轻量级锁升级为重量级锁。\n重量级锁升级为重量级锁时，锁标志的状态值变为“10”，此时Mark Word中存储的是指向重量级锁的指针，此时等待锁的线程都会进入阻塞状态。\n整体的锁状态升级流程如下：\n\n综上，偏向锁通过对比Mark Word解决加锁问题，避免执行CAS操作。而轻量级锁是通过用CAS操作和自旋来解决加锁问题，避免线程阻塞和唤醒而影响性能。重量级锁是将除了拥有锁的线程以外的线程都阻塞。\n4. 公平锁 VS 非公平锁公平锁是指多个线程按照申请锁的顺序来获取锁，线程直接进入队列中排队，队列中的第一个线程才能获得锁。公平锁的优点是等待锁的线程不会饿死。缺点是整体吞吐效率相对非公平锁要低，等待队列中除第一个线程以外的所有线程都会阻塞，CPU唤醒阻塞线程的开销比非公平锁大。\n非公平锁是多个线程加锁时直接尝试获取锁，获取不到才会到等待队列的队尾等待。但如果此时锁刚好可用，那么这个线程可以无需阻塞直接获取到锁，所以非公平锁有可能出现后申请锁的线程先获取锁的场景。非公平锁的优点是可以减少唤起线程的开销，整体的吞吐效率高，因为线程有几率不阻塞直接获得锁，CPU不必唤醒所有线程。缺点是处于等待队列中的线程可能会饿死，或者等很久才会获得锁。\n直接用语言描述可能有点抽象，这里作者用从别处看到的一个例子来讲述一下公平锁和非公平锁。\n\n如上图所示，假设有一口水井，有管理员看守，管理员有一把锁，只有拿到锁的人才能够打水，打完水要把锁还给管理员。每个过来打水的人都要管理员的允许并拿到锁之后才能去打水，如果前面有人正在打水，那么这个想要打水的人就必须排队。管理员会查看下一个要去打水的人是不是队伍里排最前面的人，如果是的话，才会给你锁让你去打水；如果你不是排第一的人，就必须去队尾排队，这就是公平锁。\n但是对于非公平锁，管理员对打水的人没有要求。即使等待队伍里有排队等待的人，但如果在上一个人刚打完水把锁还给管理员而且管理员还没有允许等待队伍里下一个人去打水时，刚好来了一个插队的人，这个插队的人是可以直接从管理员那里拿到锁去打水，不需要排队，原本排队等待的人只能继续等待。如下图所示：\n\n接下来我们通过ReentrantLock的源码来讲解公平锁和非公平锁。\n\n根据代码可知，ReentrantLock里面有一个内部类Sync，Sync继承AQS（AbstractQueuedSynchronizer），添加锁和释放锁的大部分操作实际上都是在Sync中实现的。它有公平锁FairSync和非公平锁NonfairSync两个子类。ReentrantLock默认使用非公平锁，也可以通过构造器来显示的指定使用公平锁。\n下面我们来看一下公平锁与非公平锁的加锁方法的源码:\n\n通过上图中的源代码对比，我们可以明显的看出公平锁与非公平锁的Lock()方法唯一的区别就在于公平锁在获取同步状态时多了一个限制条件：hasQueuedPredecessors()。\n\n再进入hasQueuedPredecessors()，可以看到该方法主要做一件事情：主要是判断当前线程是否位于同步队列中的第一个。如果是则返回true，否则返回false。\n综上，公平锁就是通过同步队列来实现多个线程按照申请锁的顺序来获取锁，从而实现公平的特性。非公平锁加锁时不考虑排队等待问题，直接尝试获取锁，所以存在后申请却先获得锁的情况。\n5. 可重入锁 VS 非可重入锁可重入锁又名递归锁，是指在同一个线程在外层方法获取锁的时候，再进入该线程的内层方法会自动获取锁（前提锁对象得是同一个对象或者class），不会因为之前已经获取过还没释放而阻塞。Java中ReentrantLock和synchronized都是可重入锁，可重入锁的一个优点是可一定程度避免死锁。下面用示例代码来进行分析：\n\n在上面的代码中，类中的两个方法都是被内置锁synchronized修饰的，doSomething()方法中调用doOthers()方法。因为内置锁是可重入的，所以同一个线程在调用doOthers()时可以直接获得当前对象的锁，进入doOthers()进行操作。\n如果是一个不可重入锁，那么当前线程在调用doOthers()之前需要将执行doSomething()时获取当前对象的锁释放掉，实际上该对象锁已被当前线程所持有，且无法释放。所以此时会出现死锁。\n而为什么可重入锁就可以在嵌套调用时可以自动获得锁呢？我们通过图示和源码来分别解析一下。\n还是打水的例子，有多个人在排队打水，此时管理员允许锁和同一个人的多个水桶绑定。这个人用多个水桶打水时，第一个水桶和锁绑定并打完水之后，第二个水桶也可以直接和锁绑定并开始打水，所有的水桶都打完水之后打水人才会将锁还给管理员。这个人的所有打水流程都能够成功执行，后续等待的人也能够打到水。这就是可重入锁。\n\n但如果是非可重入锁的话，此时管理员只允许锁和同一个人的一个水桶绑定。第一个水桶和锁绑定打完水之后并不会释放锁，导致第二个水桶不能和锁绑定也无法打水。当前线程出现死锁，整个等待队列中的所有线程都无法被唤醒。\n\n之前我们说过ReentrantLock和synchronized都是重入锁，那么我们通过重入锁ReentrantLock以及非可重入锁NonReentrantLock的源码来对比分析一下为什么非可重入锁在重复调用同步资源时会出现死锁。\n首先ReentrantLock和NonReentrantLock都继承父类AQS，其父类AQS中维护了一个同步状态status来计数重入次数，status初始值为0。\n当线程尝试获取锁时，可重入锁先尝试获取并更新status值，如果status == 0表示没有其他线程在执行同步代码，则把status置为1，当前线程开始执行。如果status != 0，则判断当前线程是否是获取到这个锁的线程，如果是的话执行status+1，且当前线程可以再次获取锁。而非可重入锁是直接去获取并尝试更新当前status的值，如果status != 0的话会导致其获取锁失败，当前线程阻塞。\n释放锁时，可重入锁同样先获取当前status的值，在当前线程是持有锁的线程的前提下。如果status-1 == 0，则表示当前线程所有重复获取锁的操作都已经执行完毕，然后该线程才会真正释放锁。而非可重入锁则是在确定当前线程是持有锁的线程之后，直接将status置为0，将锁释放。\n\n6. 独享锁 VS 共享锁独享锁和共享锁同样是一种概念。我们先介绍一下具体的概念，然后通过ReentrantLock和ReentrantReadWriteLock的源码来介绍独享锁和共享锁。\n独享锁也叫排他锁，是指该锁一次只能被一个线程所持有。如果线程T对数据A加上排它锁后，则其他线程不能再对A加任何类型的锁。获得排它锁的线程即能读数据又能修改数据。JDK中的synchronized和JUC中Lock的实现类就是互斥锁。\n共享锁是指该锁可被多个线程所持有。如果线程T对数据A加上共享锁后，则其他线程只能对A再加共享锁，不能加排它锁。获得共享锁的线程只能读数据，不能修改数据。\n独享锁与共享锁也是通过AQS来实现的，通过实现不同的方法，来实现独享或者共享。\n下图为ReentrantReadWriteLock的部分源码：\n\n我们看到ReentrantReadWriteLock有两把锁：ReadLock和WriteLock，由词知意，一个读锁一个写锁，合称“读写锁”。再进一步观察可以发现ReadLock和WriteLock是靠内部类Sync实现的锁。Sync是AQS的一个子类，这种结构在CountDownLatch、ReentrantLock、Semaphore里面也都存在。\n在ReentrantReadWriteLock里面，读锁和写锁的锁主体都是Sync，但读锁和写锁的加锁方式不一样。读锁是共享锁，写锁是独享锁。读锁的共享锁可保证并发读非常高效，而读写、写读、写写的过程互斥，因为读锁和写锁是分离的。所以ReentrantReadWriteLock的并发性相比一般的互斥锁有了很大提升。\n那读锁和写锁的具体加锁方式有什么区别呢？在了解源码之前我们需要回顾一下其他知识。\n在最开始提及AQS的时候我们也提到了state字段（int类型，32位），该字段用来描述有多少线程获持有锁。\n在独享锁中这个值通常是0或者1（如果是重入锁的话state值就是重入的次数），在共享锁中state就是持有锁的数量。但是在ReentrantReadWriteLock中有读、写两把锁，所以需要在一个整型变量state上分别描述读锁和写锁的数量（或者也可以叫状态）。于是将state变量“按位切割”切分成了两个部分，高16位表示读锁状态（读锁个数），低16位表示写锁状态（写锁个数）。如下图所示：\n\n了解了概念之后我们再来看代码，先看写锁的加锁源码：\n\n\n这段代码首先取到当前锁的个数c，然后再通过c来获取写锁的个数w。因为写锁是低16位，所以取低16位的最大值与当前的c做与运算（ int w = exclusiveCount(c); ），高16位和0与运算后是0，剩下的就是低位运算的值，同时也是持有写锁的线程数目。\n在取到写锁线程的数目后，首先判断是否已经有线程持有了锁。如果已经有线程持有了锁（c!=0），则查看当前写锁线程的数目，如果写线程数为0（即此时存在读锁）或者持有锁的线程不是当前线程就返回失败（涉及到公平锁和非公平锁的实现）。\n如果写入锁的数量大于最大数（65535，2的16次方-1）就抛出一个Error。\n如果当且写线程数为0（那么读线程也应该为0，因为上面已经处理c!=0的情况），并且当前线程需要阻塞那么就返回失败；如果通过CAS增加写线程数失败也返回失败。\n如果c=0，w=0或者c&gt;0，w&gt;0（重入），则设置当前线程或锁的拥有者，返回成功！\n\ntryAcquire()除了重入条件（当前线程为获取了写锁的线程）之外，增加了一个读锁是否存在的判断。如果存在读锁，则写锁不能被获取，原因在于：必须确保写锁的操作对读锁可见，如果允许读锁在已被获取的情况下对写锁的获取，那么正在运行的其他读线程就无法感知到当前写线程的操作。\n因此，只有等待其他读线程都释放了读锁，写锁才能被当前线程获取，而写锁一旦被获取，则其他读写线程的后续访问均被阻塞。写锁的释放与ReentrantLock的释放过程基本类似，每次释放均减少写状态，当写状态为0时表示写锁已被释放，然后等待的读写线程才能够继续访问读写锁，同时前次写线程的修改对后续的读写线程可见。\n接着是读锁的代码：\n\n可以看到在tryAcquireShared(int unused)方法中，如果其他线程已经获取了写锁，则当前线程获取读锁失败，进入等待状态。如果当前线程获取了写锁或者写锁未被获取，则当前线程（线程安全，依靠CAS保证）增加读状态，成功获取读锁。读锁的每次释放（线程安全的，可能有多个读线程同时释放读锁）均减少读状态，减少的值是“1&lt;&lt;16”。所以读写锁才能实现读读的过程共享，而读写、写读、写写的过程互斥。\n此时，我们再回头看一下互斥锁ReentrantLock中公平锁和非公平锁的加锁源码：\n\n我们发现在ReentrantLock虽然有公平锁和非公平锁两种，但是它们添加的都是独享锁。根据源码所示，当某一个线程调用Lock方法获取锁时，如果同步资源没有被其他线程锁住，那么当前线程在使用CAS更新state成功后就会成功抢占该资源。而如果公共资源被占用且不是被当前线程占用，那么就会加锁失败。所以可以确定ReentrantLock无论读操作还是写操作，添加的锁都是都是独享锁。\n","tags":["Java"]},{"title":"MySQL-锁","url":"/2019/11/13/MySQL%E9%94%81/","content":"一、概述数据库锁定机制简单来说，就是数据库为了保证数据的一致性，而使各种共享资源在被并发访问变得有序所设计的一种规则。对于任何一种数据库来说都需要有相应的锁定机制，所以MySQL自然也不能例外。MySQL数据库由于其自身架构的特点，存在多种数据存储引擎，每种存储引擎所针对的应用场景特点都不太一样，为了满足各自特定应用场景的需求，每种存储引擎的锁定机制都是为各自所面对的特定场景而优化设计，所以各存储引擎的锁定机制也有较大区别。MySQL各存储引擎使用了三种类型（级别）的锁定机制：表级锁定，行级锁定和页级锁定。\n1. 表级锁定（table-level）表级别的锁定是MySQL各存储引擎中最大颗粒度的锁定机制。该锁定机制最大的特点是实现逻辑非常简单，带来的系统负面影响最小。所以获取锁和释放锁的速度很快。由于表级锁一次会将整个表锁定，所以可以很好的避免困扰我们的死锁问题。当然，锁定颗粒度大所带来最大的负面影响就是出现锁定资源争用的概率也会最高，致使并大度大打折扣。使用表级锁定的主要是MyISAM，MEMORY，CSV等一些非事务性存储引擎。\n2. 行级锁定（row-level）行级锁定最大的特点就是锁定对象的颗粒度很小，也是目前各大数据库管理软件所实现的锁定颗粒度最小的。由于锁定颗粒度很小，所以发生锁定资源争用的概率也最小，能够给予应用程序尽可能大的并发处理能力而提高一些需要高并发应用系统的整体性能。虽然能够在并发处理能力上面有较大的优势，但是行级锁定也因此带来了不少弊端。由于锁定资源的颗粒度很小，所以每次获取锁和释放锁需要做的事情也更多，带来的消耗自然也就更大了。此外，行级锁定也最容易发生死锁。使用行级锁定的主要是InnoDB存储引擎。\n3. 页级锁定（page-level）页级锁定是MySQL中比较独特的一种锁定级别，在其他数据库管理软件中也并不是太常见。页级锁定的特点是锁定颗粒度介于行级锁定与表级锁之间，所以获取锁定所需要的资源开销，以及所能提供的并发处理能力也同样是介于上面二者之间。另外，页级锁定和行级锁定一样，会发生死锁。在数据库实现资源锁定的过程中，随着锁定资源颗粒度的减小，锁定相同数据量的数据所需要消耗的内存数量是越来越多的，实现算法也会越来越复杂。不过，随着锁定资源颗粒度的减小，应用程序的访问请求遇到锁等待的可能性也会随之降低，系统整体并发度也随之提升。使用页级锁定的主要是BerkeleyDB存储引擎。\n4. 总结MySQL这3种锁的特性可大致归纳如下：\n\n表级锁：开销小，加锁快；不会出现死锁；锁定粒度大，发生锁冲突的概率最高，并发度最低；\n行级锁：开销大，加锁慢；会出现死锁；锁定粒度最小，发生锁冲突的概率最低，并发度也最高；\n页面锁：开销和加锁时间界于表锁和行锁之间；会出现死锁；锁定粒度界于表锁和行锁之间，并发度一般。\n\n适用：从锁的角度来说，表级锁更适合于以查询为主，只有少量按索引条件更新数据的应用，如Web应用；而行级锁则更适合于有大量按索引条件并发更新少量不同数据，同时又有并发查询的应用，如一些在线事务处理（OLTP）系统。\n二、表级锁定由于MyISAM存储引擎使用的锁定机制完全是由MySQL提供的表级锁定实现，所以下面我们将以MyISAM存储引擎作为示例存储引擎。\n1. MySQL表级锁的锁模式MySQL的表级锁有两种模式：表共享读锁（Table Read Lock）和表独占写锁（Table Write Lock）。锁模式的兼容性：\n\n对MyISAM表的读操作，不会阻塞其他用户对同一表的读请求，但会阻塞对同一表的写请求；\n对MyISAM表的写操作，则会阻塞其他用户对同一表的读和写操作；\nMyISAM表的读操作与写操作之间，以及写操作之间是串行的。当一个线程获得对一个表的写锁后，只有持有锁的线程可以对表进行更新操作。其他线程的读、写操作都会等待，直到锁被释放为止。\n\n2. 如何加表锁MyISAM在执行查询语句（SELECT）前，会自动给涉及的所有表加读锁，在执行更新操作（UPDATE、DELETE、INSERT等）前，会自动给涉及的表加写锁，这个过程并不需要用户干预，因此，用户一般不需要直接用LOCK  TABLE命令给MyISAM表显式加锁。\n3. MyISAM表锁优化建议对于MyISAM存储引擎，虽然使用表级锁定在锁定实现的过程中比实现行级锁定或者页级锁所带来的附加成本都要小，锁定本身所消耗的资源也是最少。但是由于锁定的颗粒度比较到，所以造成锁定资源的争用情况也会比其他的锁定级别都要多，从而在较大程度上会降低并发处理能力。所以，在优化MyISAM存储引擎锁定问题的时候，最关键的就是如何让其提高并发度。由于锁定级别是不可能改变的了，所以我们首先需要尽可能让锁定的时间变短，然后就是让可能并发进行的操作尽可能的并发。\n（1）查询表级锁争用情况MySQL内部有两组专门的状态变量记录系统内部锁资源争用情况：\nmysql&gt; show status like &#39;table%&#39;;+----------------------------+---------+| Variable_name              | Value   |+----------------------------+---------+| Table_locks_immediate      | 100     || Table_locks_waited         | 11      |+----------------------------+---------+\n\n这里有两个状态变量记录MySQL内部表级锁定的情况，两个变量说明如下：\n\nTable_locks_immediate：产生表级锁定的次数；\nTable_locks_waited：出现表级锁定争用而发生等待的次数；\n\n两个状态值都是从系统启动后开始记录，出现一次对应的事件则数量加1。如果这里的Table_locks_waited状态值比较高，那么说明系统中表级锁定争用现象比较严重，就需要进一步分析为什么会有较多的锁定资源争用了。\n（2）缩短锁定时间如何让锁定时间尽可能的短呢？唯一的办法就是让我们的Query执行时间尽可能的短。\n\na) 尽两减少大的复杂Query，将复杂Query分拆成几个小的Query分布进行；\nb) 尽可能的建立足够高效的索引，让数据检索更迅速；\nc) 尽量让MyISAM存储引擎的表只存放必要的信息，控制字段类型；\nd) 利用合适的机会优化MyISAM表数据文件。\n\n（3）分离能并行的操作说到MyISAM的表锁，而且是读写互相阻塞的表锁，可能有些人会认为在MyISAM存储引擎的表上就只能是完全的串行化，没办法再并行了。大家不要忘记了，MyISAM的存储引擎还有一个非常有用的特性，那就是ConcurrentInsert（并发插入）的特性。\nMyISAM存储引擎有一个控制是否打开Concurrent Insert功能的参数选项：concurrent_insert，可以设置为0，1或者2。三个值的具体说明如下：\n\nconcurrent_insert=2，无论MyISAM表中有没有空洞，都允许在表尾并发插入记录；\nconcurrent_insert=1，如果MyISAM表中没有空洞（即表的中间没有被删除的行），MyISAM允许在一个进程读表的同时，另一个进程从表尾插入记录。这也是MySQL的默认设置；\nconcurrent_insert=0，不允许并发插入。\n\n可以利用MyISAM存储引擎的并发插入特性，来解决应用中对同一表查询和插入的锁争用。例如，将concurrent_insert系统变量设为2，总是允许并发插入；同时，通过定期在系统空闲时段执行OPTIMIZE  TABLE语句来整理空间碎片，收回因删除记录而产生的中间空洞。\n（4）合理利用读写优先级MyISAM存储引擎的是读写互相阻塞的，那么，一个进程请求某个MyISAM表的读锁，同时另一个进程也请求同一表的写锁，MySQL如何处理呢？\n答案是写进程先获得锁。不仅如此，即使读请求先到锁等待队列，写请求后到，写锁也会插到读锁请求之前。\n这是因为MySQL的表级锁定对于读和写是有不同优先级设定的，默认情况下是写优先级要大于读优先级。\n所以，如果我们可以根据各自系统环境的差异决定读与写的优先级：\n通过执行命令SET LOW_PRIORITY_UPDATES=1，使该连接读比写的优先级高。如果我们的系统是一个以读为主，可以设置此参数，如果以写为主，则不用设置；\n通过指定INSERT、UPDATE、DELETE语句的LOW_PRIORITY属性，降低该语句的优先级。\n虽然上面方法都是要么更新优先，要么查询优先的方法，但还是可以用其来解决查询相对重要的应用（如用户登录系统）中，读锁等待严重的问题。\n另外，MySQL也提供了一种折中的办法来调节读写冲突，即给系统参数max_write_lock_count设置一个合适的值，当一个表的读锁达到这个值后，MySQL就暂时将写请求的优先级降低，给读进程一定获得锁的机会。\n这里还要强调一点：一些需要长时间运行的查询操作，也会使写进程“饿死”，因此，应用中应尽量避免出现长时间运行的查询操作，不要总想用一条SELECT语句来解决问题，因为这种看似巧妙的SQL语句，往往比较复杂，执行时间较长，在可能的情况下可以通过使用中间表等措施对SQL语句做一定的“分解”，使每一步查询都能在较短时间完成，从而减少锁冲突。如果复杂查询不可避免，应尽量安排在数据库空闲时段执行，比如一些定期统计可以安排在夜间执行。\n三、行级锁定行级锁定不是MySQL自己实现的锁定方式，而是由其他存储引擎自己所实现的，如广为大家所知的InnoDB存储引擎，以及MySQL的分布式存储引擎NDBCluster等都是实现了行级锁定。考虑到行级锁定君由各个存储引擎自行实现，而且具体实现也各有差别，而InnoDB是目前事务型存储引擎中使用最为广泛的存储引擎，所以这里我们就主要分析一下InnoDB的锁定特性。\n1. InnoDB锁定模式及实现机制考虑到行级锁定君由各个存储引擎自行实现，而且具体实现也各有差别，而InnoDB是目前事务型存储引擎中使用最为广泛的存储引擎，所以这里我们就主要分析一下InnoDB的锁定特性。\n总的来说，InnoDB的锁定机制和Oracle数据库有不少相似之处。InnoDB的行级锁定同样分为两种类型，共享锁和排他锁，而在锁定机制的实现过程中为了让行级锁定和表级锁定共存，InnoDB也同样使用了意向锁（表级锁定）的概念，也就有了意向共享锁和意向排他锁这两种。\n当一个事务需要给自己需要的某个资源加锁的时候，如果遇到一个共享锁正锁定着自己需要的资源的时候，自己可以再加一个共享锁，不过不能加排他锁。但是，如果遇到自己需要锁定的资源已经被一个排他锁占有之后，则只能等待该锁定释放资源之后自己才能获取锁定资源并添加自己的锁定。而意向锁的作用就是当一个事务在需要获取资源锁定的时候，如果遇到自己需要的资源已经被排他锁占用的时候，该事务可以需要锁定行的表上面添加一个合适的意向锁。如果自己需要一个共享锁，那么就在表上面添加一个意向共享锁。而如果自己需要的是某行（或者某些行）上面添加一个排他锁的话，则先在表上面添加一个意向排他锁。意向共享锁可以同时并存多个，但是意向排他锁同时只能有一个存在。所以，可以说InnoDB的锁定模式实际上可以分为四种：共享锁（S），排他锁（X），意向共享锁（IS）和意向排他锁（IX）\n如果一个事务请求的锁模式与当前的锁兼容，InnoDB就将请求的锁授予该事务；反之，如果两者不兼容，该事务就要等待锁释放。\n意向锁是InnoDB自动加的，不需用户干预。对于UPDATE、DELETE和INSERT语句，InnoDB会自动给涉及数据集加排他锁（X)；对于普通SELECT语句，InnoDB不会加任何锁；事务可以通过以下语句显示给记录集加共享锁或排他锁。\n共享锁（S）：SELECT * FROM table_name WHERE ... LOCK IN SHARE MODE排他锁（X)：SELECT * FROM table_name WHERE ... FOR UPDATE\n\n用SELECT … IN SHARE MODE获得共享锁，主要用在需要数据依存关系时来确认某行记录是否存在，并确保没有人对这个记录进行UPDATE或者DELETE操作。但是如果当前事务也需要对该记录进行更新操作，则很有可能造成死锁，对于锁定行记录后需要进行更新操作的应用，应该使用SELECT… FOR UPDATE方式获得排他锁。\n2. InnoDB行锁实现方式InnoDB行锁是通过给索引上的索引项加锁来实现的，只有通过索引条件检索数据，InnoDB才使用行级锁，否则，InnoDB将使用表锁\n在实际应用中，要特别注意InnoDB行锁的这一特性，不然的话，可能导致大量的锁冲突，从而影响并发性能。下面通过一些实际例子来加以说明。\n\n（1）在不通过索引条件查询的时候，InnoDB确实使用的是表锁，而不是行锁。\n（2）由于MySQL的行锁是针对索引加的锁，不是针对记录加的锁，所以虽然是访问不同行的记录，但是如果是使用相同的索引键，是会出现锁冲突的。\n（3）当表有多个索引的时候，不同的事务可以使用不同的索引锁定不同的行，另外，不论是使用主键索引、唯一索引或普通索引，InnoDB都会使用行锁来对数据加锁。\n（4）即便在条件中使用了索引字段，但是否使用索引来检索数据是由MySQL通过判断不同执行计划的代价来决定的，如果MySQL认为全表扫描效率更高，比如对一些很小的表，它就不会使用索引，这种情况下InnoDB将使用表锁，而不是行锁。因此，在分析锁冲突时，别忘了检查SQL的执行计划，以确认是否真正使用了索引。\n\n3. 间隙锁（Next-Key锁）当我们用范围条件而不是相等条件检索数据，并请求共享或排他锁时，InnoDB会给符合条件的已有数据记录的索引项加锁；对于键值在条件范围内但并不存在的记录，叫做“间隙（GAP)”，InnoDB也会对这个“间隙”加锁，这种锁机制就是所谓的间隙锁（Next-Key锁）。例：假如emp表中只有101条记录，其empid的值分别是 1,2,…,100,101，下面的SQL：\nmysql&gt; select * from emp where empid &gt; 100 for update;\n\n是一个范围条件的检索，InnoDB不仅会对符合条件的empid值为101的记录加锁，也会对empid大于101（这些记录并不存在）的“间隙”加锁。InnoDB使用间隙锁的目的：\n\n（1）防止幻读，以满足相关隔离级别的要求。对于上面的例子，要是不使用间隙锁，如果其他事务插入了empid大于100的任何记录，那么本事务如果再次执行上述语句，就会发生幻读；\n（2）为了满足其恢复和复制的需要。\n\n很显然，在使用范围条件检索并锁定记录时，即使某些不存在的键值也会被无辜的锁定，而造成在锁定的时候无法插入锁定键值范围内的任何数据。在某些场景下这可能会对性能造成很大的危害。除了间隙锁给InnoDB带来性能的负面影响之外，通过索引实现锁定的方式还存在其他几个较大的性能隐患：\n\n（1）当Query无法利用索引的时候，InnoDB会放弃使用行级别锁定而改用表级别的锁定，造成并发性能的降低；\n（2）当Query使用的索引并不包含所有过滤条件的时候，数据检索使用到的索引键所只想的数据可能有部分并不属于该Query的结果集的行列，但是也会被锁定，因为间隙锁锁定的是一个范围，而不是具体的索引键；\n（3）当Query在使用索引定位数据的时候，如果使用的索引键一样但访问的数据行不同的时候（索引只是过滤条件的一部分），一样会被锁定。\n\n因此，在实际应用开发中，尤其是并发插入比较多的应用，我们要尽量优化业务逻辑，尽量使用相等条件来访问更新数据，避免使用范围条件。\n还要特别说明的是，InnoDB除了通过范围条件加锁时使用间隙锁外，如果使用相等条件请求给一个不存在的记录加锁，InnoDB也会使用间隙锁。\n4. 死锁上文讲过，MyISAM表锁是deadlock   free的，这是因为MyISAM总是一次获得所需的全部锁，要么全部满足，要么等待，因此不会出现死锁。但在InnoDB中，除单个SQL组成的事务外，锁是逐步获得的，当两个事务都需要获得对方持有的排他锁才能继续完成事务，这种循环锁等待就是典型的死锁。\n在InnoDB的事务管理和锁定机制中，有专门检测死锁的机制，会在系统中产生死锁之后的很短时间内就检测到该死锁的存在。当InnoDB检测到系统中产生了死锁之后，InnoDB会通过相应的判断来选这产生死锁的两个事务中较小的事务来回滚，而让另外一个较大的事务成功完成。\n那InnoDB是以什么来为标准判定事务的大小的呢？MySQL官方手册中也提到了这个问题，实际上在InnoDB发现死锁之后，会计算出两个事务各自插入、更新或者删除的数据量来判定两个事务的大小。也就是说哪个事务所改变的记录条数越多，在死锁中就越不会被回滚掉。\n但是有一点需要注意的就是，当产生死锁的场景中涉及到不止InnoDB存储引擎的时候，InnoDB是没办法检测到该死锁的，这时候就只能通过锁定超时限制参数InnoDB_lock_wait_timeout来解决。需要说明的是，这个参数并不是只用来解决死锁问题，在并发访问比较高的情况下，如果大量事务因无法立即获得所需的锁而挂起，会占用大量计算机资源，造成严重性能问题，甚至拖跨数据库。我们通过设置合适的锁等待超时阈值，可以避免这种情况发生。\n通常来说，死锁都是应用设计的问题，通过调整业务流程、数据库对象设计、事务大小，以及访问数据库的SQL语句，绝大部分死锁都可以避免。下面就通过实例来介绍几种避免死锁的常用方法：\n\n（1）在应用中，如果不同的程序会并发存取多个表，应尽量约定以相同的顺序来访问表，这样可以大大降低产生死锁的机会。\n（2）在程序以批量方式处理数据的时候，如果事先对数据排序，保证每个线程按固定的顺序来处理记录，也可以大大降低出现死锁的可能。\n（3）在事务中，如果要更新记录，应该直接申请足够级别的锁，即排他锁，而不应先申请共享锁，更新时再申请排他锁，因为当用户申请排他锁时，其他事务可能又已经获得了相同记录的共享锁，从而造成锁冲突，甚至死锁。\n（4）在REPEATABLE-READ隔离级别下，如果两个线程同时对相同条件记录用SELECT…FOR   UPDATE加排他锁，在没有符合该条件记录情况下，两个线程都会加锁成功。程序发现记录尚不存在，就试图插入一条新记录，如果两个线程都这么做，就会出现死锁。这种情况下，将隔离级别改成READ  COMMITTED，就可避免问题。\n（5）当隔离级别为READ COMMITTED时，如果两个线程都先执行SELECT…FOR  UPDATE，判断是否存在符合条件的记录，如果没有，就插入记录。此时，只有一个线程能插入成功，另一个线程会出现锁等待，当第1个线程提交后，第2个线程会因主键重出错，但虽然这个线程出错了，却会获得一个排他锁。这时如果有第3个线程又来申请排他锁，也会出现死锁。对于这种情况，可以直接做插入操作，然后再捕获主键重异常，或者在遇到主键重错误时，总是执行ROLLBACK释放获得的排他锁。\n\n5. 什么时候使用表锁对于InnoDB表，在绝大部分情况下都应该使用行级锁，因为事务和行锁往往是我们之所以选择InnoDB表的理由。但在个别特殊事务中，也可以考虑使用表级锁：\n\n（1）事务需要更新大部分或全部数据，表又比较大，如果使用默认的行锁，不仅这个事务执行效率低，而且可能造成其他事务长时间锁等待和锁冲突，这种情况下可以考虑使用表锁来提高该事务的执行速度。\n（2）事务涉及多个表，比较复杂，很可能引起死锁，造成大量事务回滚。这种情况也可以考虑一次性锁定事务涉及的表，从而避免死锁、减少数据库因事务回滚带来的开销。当然，应用中这两种事务不能太多，否则，就应该考虑使用MyISAM表了。\n\n在InnoDB下，使用表锁要注意以下两点。\n\n（1）使用LOCK  TABLES虽然可以给InnoDB加表级锁，但必须说明的是，表锁不是由InnoDB存储引擎层管理的，而是由其上一层──MySQL  Server负责的，仅当autocommit=0、InnoDB_table_locks=1（默认设置）时，InnoDB层才能知道MySQL加的表锁，MySQL   Server也才能感知InnoDB加的行锁，这种情况下，InnoDB才能自动识别涉及表级锁的死锁，否则，InnoDB将无法自动检测并处理这种死锁。\n（2）在用  LOCK TABLES对InnoDB表加锁时要注意，要将AUTOCOMMIT设为0，否则MySQL不会给表加锁；事务结束前，不要用UNLOCK  TABLES释放表锁，因为UNLOCK TABLES会隐含地提交事务；COMMIT或ROLLBACK并不能释放用LOCK  TABLES加的表级锁，必须用UNLOCK TABLES释放表锁。正确的方式见如下语句：例如，如果需要写表t1并从表t读，可以按如下做：\n\nSET AUTOCOMMIT&#x3D;0;LOCK TABLES t1 WRITE, t2 READ, ...;[do something with tables t1 and t2 here];COMMIT;UNLOCK TABLES;\n\n6. InnoDB行锁优化建议InnoDB存储引擎由于实现了行级锁定，虽然在锁定机制的实现方面所带来的性能损耗可能比表级锁定会要更高一些，但是在整体并发处理能力方面要远远优于MyISAM的表级锁定的。当系统并发量较高的时候，InnoDB的整体性能和MyISAM相比就会有比较明显的优势了。但是，InnoDB的行级锁定同样也有其脆弱的一面，当我们使用不当的时候，可能会让InnoDB的整体性能表现不仅不能比MyISAM高，甚至可能会更差。\n\n（1）要想合理利用InnoDB的行级锁定，做到扬长避短，我们必须做好以下工作：\na) 尽可能让所有的数据检索都通过索引来完成，从而避免InnoDB因为无法通过索引键加锁而升级为表级锁定；\nb) 合理设计索引，让InnoDB在索引键上面加锁的时候尽可能准确，尽可能的缩小锁定范围，避免造成不必要的锁定而影响其他Query的执行；\nc) 尽可能减少基于范围的数据检索过滤条件，避免因为间隙锁带来的负面影响而锁定了不该锁定的记录；\nd) 尽量控制事务的大小，减少锁定的资源量和锁定时间长度；\ne) 在业务环境允许的情况下，尽量使用较低级别的事务隔离，以减少MySQL因为实现事务隔离级别所带来的附加成本。\n\n\n（2）由于InnoDB的行级锁定和事务性，所以肯定会产生死锁，下面是一些比较常用的减少死锁产生概率的小建议：\na) 类似业务模块中，尽可能按照相同的访问顺序来访问，防止产生死锁；\nb) 在同一个事务中，尽可能做到一次锁定所需要的所有资源，减少死锁产生概率；\nc) 对于非常容易产生死锁的业务部分，可以尝试使用升级锁定颗粒度，通过表级锁定来减少死锁产生的概率。\n\n\n（3）可以通过检查InnoDB_row_lock状态变量来分析系统上的行锁的争夺情况：mysql&gt; show status like &#39;InnoDB_row_lock%&#39;;+-------------------------------+-------+| Variable_name                 | Value |+-------------------------------+-------+| InnoDB_row_lock_current_waits | 0     || InnoDB_row_lock_time          | 0     || InnoDB_row_lock_time_avg      | 0     || InnoDB_row_lock_time_max      | 0     || InnoDB_row_lock_waits         | 0     |+-------------------------------+-------+\n\n\n\nInnoDB 的行级锁定状态变量不仅记录了锁定等待次数，还记录了锁定总时长，每次平均时长，以及最大时长，此外还有一个非累积状态量显示了当前正在等待锁定的等待数量。对各个状态量的说明如下：\n\nInnoDB_row_lock_current_waits：当前正在等待锁定的数量；\nInnoDB_row_lock_time：从系统启动到现在锁定总时间长度；\nInnoDB_row_lock_time_avg：每次等待所花平均时间；\nInnoDB_row_lock_time_max：从系统启动到现在等待最常的一次所花的时间；\nInnoDB_row_lock_waits：系统启动后到现在总共等待的次数；\n\n对于这5个状态变量，比较重要的主要是InnoDB_row_lock_time_avg（等待平均时长），InnoDB_row_lock_waits（等待总次数）以及InnoDB_row_lock_time（等待总时长）这三项。尤其是当等待次数很高，而且每次等待时长也不小的时候，我们就需要分析系统中为什么会有如此多的等待，然后根据分析结果着手指定优化计划。\n如果发现锁争用比较严重，如InnoDB_row_lock_waits和InnoDB_row_lock_time_avg的值比较高，还可以通过设置InnoDB Monitors 来进一步观察发生锁冲突的表、数据行等，并分析锁争用的原因。\n锁冲突的表、数据行等，并分析锁争用的原因。具体方法如下：\nmysql&gt; create table InnoDB_monitor(a INT) engine&#x3D;InnoDB;\n\n然后就可以用下面的语句来进行查看：\nmysql&gt; show engine InnoDB status;\n\n监视器可以通过发出下列语句来停止查看：\nmysql&gt; drop table InnoDB_monitor;\n\n设置监视器后，会有详细的当前锁等待的信息，包括表名、锁类型、锁定记录的情况等，便于进行进一步的分析和问题的确定。可能会有读者朋友问为什么要先创建一个叫InnoDB_monitor的表呢？因为创建该表实际上就是告诉InnoDB我们开始要监控他的细节状态了，然后InnoDB就会将比较详细的事务以及锁定信息记录进入MySQL的errorlog中，以便我们后面做进一步分析使用。打开监视器以后，默认情况下每15秒会向日志中记录监控的内容，如果长时间打开会导致.err文件变得非常的巨大，所以用户在确认问题原因之后，要记得删除监控表以关闭监视器，或者通过使用“–console”选项来启动服务器以关闭写日志文件。\n四、常用命令查询哪些线程运行show full processlist;\n\n查看哪些表可以打开show open tables WHERE In_use&gt;0;\n","tags":["MySQL","数据库"]},{"title":"NIO详细介绍","url":"/2020/07/06/NIO%E8%AF%A6%E7%BB%86%E4%BB%8B%E7%BB%8D/","content":"一、介绍Doug Lea写的一篇文章来阐述NIO\nNIO是一个双向的缓存通道，通道负责建立和缓冲区的链接。\nChannel负责传输，Buffer负责中转储存。\n二、要素1. 缓存区（Buffer）1.1 介绍缓存区（Buffer）：一个用于特定基本数据类型的容器。由java.nio包定义的，所有缓冲区都是Buffer抽象类的子类。\nJava NIO中的Buffer主要用于与NIO通道进行交互，数据是从通道读入缓冲区，从缓冲区写入通道中。\nBuffer就像一个数组，可以保存多个相同类型的数据。根据数据类型不同（boolean除外），有以下Buffer常用子类：\n\nByteBuffer\nCharBuffer\nShortBuffer\nIntBuffer\nLongBuffer\nFloatBuffer\nDoubleBuffer\n\n上述Buffer类都是采用相似的方法进行管理数据，只是各自管理的数据类型不同而已。都是通过如下方法获取一个Buffer对象：\nstatic XXXBufer allocate(int capacity)：创建一个容量为capacity的XXXBuffer对象。\n1.2 基本属性\n容量（capacity）：表示Buffer最大数据容量，缓冲区容量不能为负，并且创建后不能更改。\n\n限制（limit）：第一个不应该读取或写入的数据的索引，即位于limit后的数据不可读写。缓存区的限制不能为负，并且不能大于其容量。\n\n位置（position）：下一个要读取或写入的数据的索引。缓冲区的位置不能为负，并且不能大于其容量。\n\n标记（mark）与重置（reset）：标记是一个索引，通过Buffer中的mark()方法指定Buffer中一个特定的position，之后可以通过reset()方法恢复到这个position。\n\n\n遵守原则：0&lt;=mark&lt;=position&lt;=limit&lt;=capacity，管道将会从Buffer中读取position到limit的内容。\n1.3 常用方法\n\n\n方法\n描述\n\n\n\nBuffer clear()\n清空缓冲区并返回对缓冲区的引用\n\n\nBuffer flip()\n将缓冲区的界限设置为当前位置，并将当前位置重置为0\n\n\nint capacity()\n返回Buffer的capacity的大小\n\n\nboolean hasRemaining()\n判断缓冲区中是否还有元素\n\n\nint limit()\n返回Buffer的界限（limit）的位置\n\n\nBuffer limit(int newLimit)\n将设置缓冲区界限为newLimit，并返回一个具有新limit的缓冲区对象\n\n\nBuffer mark()\n对缓冲区设置标记\n\n\nint position()\n返回缓冲区的当前位置position\n\n\nBuffer position(int newPosition)\n将设置缓冲区的当前位置为newPosition，并返回修改后的Buffer对象\n\n\nint remaining()\n返回position和limit之间的元素个数\n\n\nBuffer reset()\n将位置position转到以前设置的mark所在的位置\n\n\nBuffer rewind()\n将位置设置为0，取消设置mark\n\n\n1.4 缓冲区的数据操作Buffer所有子类提供了两个用于数据操作的方法：get()与put()方法\n\n获取Buffer中的数据\nget()：读取单个字节\nget(int index)：读取指定索引位置的字节（不会移动position）\nget(byte[] dst, int offset, int length)：\nget(byte[] dst)：批量读取多个字节到dst中\n\n放入数据到Buffer\nput(byte b)：将给定单个字节写入缓冲区的当前位置\nput(byte[] src, int offset, int length)：\nput(byte[] src)：将src中的字节写入缓冲区的当前位置\nput(ByteBuffer src)：\nput(int index, byte b)：将指定字节写入缓冲区的索引位置（不会移动position）\n\n\n/** * 一、缓冲区（Buffer）:在java NIO中负责数据的存取。缓冲区就是数组。用于存储 * 不同数据类型的数据 * * 根据数据类型的不同（boolean除外），提供对应类型的缓冲区： * ByteBuffer - 最常用的 * CharBuffer * ShortBuffer * IntBuffer * LongBuffer * FloatBuffer * DoubleBuffer * * 上述的缓冲区的管理方式几乎是一致的 ，通过allocate()获取缓冲区 * * 二、缓冲区里面的存取数据的两个核心方法： * put()：存入数据到缓冲区中 * get()：获取缓冲区中的数据 * * 四 、缓冲区中的核心属性 * capacity：容量，表示缓冲区中最大存储数据的容量，一旦声明了则不能改变。 * limit：表示缓冲区中可以操作数据的大小。（limit后数据是不可以进行读写的） * position：位置，表示缓冲区正在操作数据的位置。 * mark：标记，表示记录当前position的位置，可以通过reset()恢复到mark的位置 * * 0 &lt;= mark &lt;= position &lt;= limit &lt;= capacity */public class TestBuffer &#123;    public void test2() &#123;        String str = \"abcde\";        ByteBuffer buf = ByteBuffer.allocate(1024);        buf.put(str.getBytes());        buf.flip();        byte[] dst = new byte[buf.limit()];        buf.get(dst,0,2);        System.out.println(new String(dst, 0, 2));        System.out.println(buf.position());        //mark()：标记        buf.mark();        buf.get(dst,2,2);        System.out.println(new String(dst,2,2));        System.out.println(buf.position());        //reset()        buf.reset();        System.out.println(buf.position());        //判断缓冲区中是否还有剩余数据        if (buf.hasRemaining()) &#123;            //如果有的话，那么获取缓冲区中可以操作的数量            System.out.println(buf.remaining());        &#125;    &#125;    public void test1() &#123;        String str = \"abcde\";        //1.分配一个指定大小的缓冲区        ByteBuffer buf = ByteBuffer.allocate(1024);        System.out.println(\"-------allocate()-------\");        System.out.println(\"正在操作的位置 \"+buf.position());        System.out.println(\"缓冲区中可操作数据的大小 \"+buf.limit());        System.out.println(\"容量 \"+buf.capacity());        //2.利用put()方法存入数据到缓冲区        buf.put(str.getBytes());        System.out.println(\"-------put()-------\");        System.out.println(\"正在操作的位置 \"+buf.position());        System.out.println(\"缓冲区中可操作数据的大小 \"+buf.limit());        System.out.println(\"容量 \"+buf.capacity());        //3.切换成读取数据的模式,利用flip()方法来进行读取数据        buf.flip();        System.out.println(\"-------flip()-------\");        System.out.println(\"正在操作的位置 \"+buf.position());        System.out.println(\"缓冲区中可操作数据的大小 \"+buf.limit());        System.out.println(\"容量 \"+buf.capacity());        //4.利用get()读取缓冲区中的数据        byte[] dst = new byte[buf.limit()];        buf.get(dst);        System.out.println(new String(dst,0,dst.length));        System.out.println(\"-------get()-------\");        System.out.println(\"正在操作的位置 \"+buf.position());        System.out.println(\"缓冲区中可操作数据的大小 \"+buf.limit());        System.out.println(\"容量 \"+buf.capacity());        //5.rewind():表示可以重复读取        buf.rewind();        System.out.println(\"-------rewind()-------\");        System.out.println(\"正在操作的位置 \"+buf.position());        System.out.println(\"缓冲区中可操作数据的大小 \"+buf.limit());        System.out.println(\"容量 \"+buf.capacity());        //6.清空缓冲区,但是缓冲区中的数据依然存在，只不过数据是处于被遗望的状态        buf.clear();        System.out.println(\"-------clear()-------\");        System.out.println(\"正在操作的位置 \"+buf.position());        System.out.println(\"缓冲区中可操作数据的大小 \"+buf.limit());        System.out.println(\"容量 \"+buf.capacity());        System.out.println((char)buf.get());    &#125;&#125;\n\n1.5 直接缓冲区与非直接缓冲区\n字节缓冲区要么是直接的，要么是非直接的。如果为直接字节缓冲区，则Java虚拟机会尽最大努力直接在此缓冲区上执行本机I/O操作。也就是说，在每次调用基础操作系统的一个本机I/O操作之前（或之后），虚拟机都会尽量避免将缓冲区的内容复制到中间缓冲区中（或从中间缓冲区中复制内容）。\n\n直接字节缓冲区可以通过调用此类的allocateDirect()工厂方法来创建。此方法返回的缓冲区进行分配和取消分配所需成本通常高于非直接缓冲区。直接缓冲区的内容可以驻留在常规的垃圾回收堆之外，因此，它们对应用程序的内存需求量造成的影响可能并不明显。所以，建议将直接缓冲区主要分配给那些易受基础系统的本机I/O操作影响的大型、持久的缓冲区。一般情况下，最好仅在直接缓冲区能在程序性能方面带来明显好处是分配它们。\n\n直接字节缓冲区还可以通过FileChannel的map()方法将文件区域直接映射到内存中来创建。该方法返回MappedByteBuffer。Java平台的实现有助于通过JNI从本机代码创建直接字节缓冲区。如果以上这些缓冲区中的某个缓冲区实例指的是不可访问的内存区域，则试图访问该区域不会更改该缓冲区的内容，并且将会在访问期间或稍后的某个时间导致抛出不确定的异常。\n\n字节缓冲区是直接缓冲区还是非直接缓冲区可通过调用其isDirect()方法来确定。提供此方法是为了能够在性能关键型代码中执行显示缓冲区管理。\n\n\n2. 通道（Channel）由java.nio.channels包定义。Channel表示IO源与目标打开的连接。Channel类似于传统的“流”。只不过Channel本身不能直接访问数据，Channel只能与Buffer进行交互。\n2.1 主要实现类2.1.1 FileChannel\n用于读取、写入、映射和操作文件的通道\n\n\nFileChannel的常用方法\n\n\n\n\n方法\n描述\n\n\n\nint read(ByteBuffer dst)\n从Channel中读取数据到ByteBuffer\n\n\nlong read(ByteBuffer[] dsts, int offset, int length)\n将Channel中的数据“分散”到ByteBuffer[]\n\n\nint write(ByteBuffer src)\n将ByteBuffer中的数据写入到Channel\n\n\nlong write(ByteBuffer[] srcs, int offset, int length)\n将ByteBuffer[]中的数据“聚集”到Channel\n\n\nlong position()\n返回此通道的文件位置\n\n\nFileChannel position(long newPosition)\n设置此通道的文件位置\n\n\nlong size()\n返回此通道的文件的当前大小\n\n\nFileChannel truncate(long size)\n将此通道的文件截取为给定大小\n\n\nvoid force(boolean metaData)\n强制将所有对此通道的文件更新写入到储存设备中\n\n\n2.1.2 DatagramChannel\n用过UDP读写网络中的数据通道\n操作步骤：打开DatagramChannel -&gt; 接收/发送数据\n\npublic class TestNonBlockingNIO2 &#123;    public void send() throws IOException&#123;        DatagramChannel dc = DatagramChannel.open();        dc.configureBlocking(false);        ByteBuffer buf = ByteBuffer.allocate(1024);        Scanner scan = new Scanner(System.in);        while(scan.hasNext())&#123;            String str = scan.next();            buf.put((new Date().toString() + \":\\n\" + str).getBytes());            buf.flip();            dc.send(buf, new InetSocketAddress(\"127.0.0.1\", 9898));            buf.clear();        &#125;        dc.close();    &#125;    public void receive() throws IOException&#123;        DatagramChannel dc = DatagramChannel.open();        dc.configureBlocking(false);        dc.bind(new InetSocketAddress(9898));        Selector selector = Selector.open();        dc.register(selector, SelectionKey.OP_READ);        while(selector.select() &gt; 0)&#123;            Iterator&lt;SelectionKey&gt; it = selector.selectedKeys().iterator();            while(it.hasNext())&#123;                SelectionKey sk = it.next();                if(sk.isReadable())&#123;                    ByteBuffer buf = ByteBuffer.allocate(1024);                    dc.receive(buf);                    buf.flip();                    System.out.println(new String(buf.array(), 0, buf.limit()));                    buf.clear();                &#125;            &#125;            it.remove();        &#125;    &#125;&#125;\n\n2.1.3 SocketChannel\nJava NIO中的SocketChannel是一个连接到TCP网络套接字的通道。通过TCP读写网络中的数据\n操作步骤：打开SocketChannel -&gt; 读写数据 -&gt; 关闭SocketChannel\n\npublic void client() throws IOException &#123;    //1. 获取通道    SocketChannel sChannel = SocketChannel.open(new InetSocketAddress(\"127.0.0.1\", 9898));    FileChannel inChannel = FileChannel.open(Paths.get(\"1.jpg\"), StandardOpenOption.READ);    //2. 分配指定大小的缓冲区    ByteBuffer buf = ByteBuffer.allocate(1024);    //3. 读取本地文件，并发送到服务端    while(inChannel.read(buf) != -1)&#123;        buf.flip();        sChannel.write(buf);        buf.clear();    &#125;    //4. 关闭通道    inChannel.close();    sChannel.close();&#125;\n\n2.1.4 ServerSocketChannel\nJava NIO中的ServerSocketChannel是一个可以监听新进来的TCP连接的通道，就像标准IO中的ServerSocket一样。可以监听新进来的TCP连接，对每一个新进来的连接都会创建一个SocketChannel。\n\npublic void server() throws IOException&#123;    //1. 获取通道    ServerSocketChannel ssChannel = ServerSocketChannel.open();    FileChannel outChannel = FileChannel.open(Paths.get(\"2.jpg\"), StandardOpenOption.WRITE, StandardOpenOption.CREATE);    //2. 绑定连接    ssChannel.bind(new InetSocketAddress(9898));    //3. 获取客户端连接的通道    SocketChannel sChannel = ssChannel.accept();    //4. 分配指定大小的缓冲区    ByteBuffer buf = ByteBuffer.allocate(1024);    //5. 接收客户端的数据，并保存到本地    while(sChannel.read(buf) != -1)&#123;        buf.flip();        outChannel.write(buf);        buf.clear();    &#125;    //6. 关闭通道    sChannel.close();    outChannel.close();    ssChannel.close();&#125;\n\n2.2 获取通道获取通道的一种方式是对支持通道的对象调用getChannel()方法。支持通道的类如下：\n\nFileInputStream\n\nFileOutputStream\n\nRandomAccessFile\n\nDatagramSocket\n\nSocket\n\nServerSocket\n\n\n获取通道的其他方式是使用Files类的静态方法newByteChannel()获取字节通道。或者通过通道的静态方法open()打开并返回指定通道。FileChannel.open(Path path, OpenOption... options)\n2.3 通道之间的数据传输2.3.1 缓冲区传输\n将Buffer中数据写入Channel\n\n// 将Buffer中数据写入Channel中int bytesWritten = inChannel.write(buf);\n\n\n从Channel读取数据到Buffer\n\n// 从Channel读取数据到Buffer中int bytesRead = inChannel.read(buf);\n\n\n使用示例\n\npublic class TestChannel &#123;    //1.利用通道来完成文件的复制    public void test1() &#123;        FileInputStream fis = null;        FileOutputStream fos = null;        FileChannel inChannel = null;        FileChannel outChannel = null;        try &#123;            fis = new FileInputStream(\"1.jpg\");            fos = new FileOutputStream(\"3.jpg\");            //2.获取通道            inChannel = fis.getChannel();            outChannel = fos.getChannel();            //3.分配一个指定大小的缓冲区            ByteBuffer buf = ByteBuffer.allocate(1024);            //4.将通道中的数据存入缓冲区中读取数据            while (inChannel.read(buf) != -1) &#123;                buf.flip();//切换成读取数据的模式                //5.将缓冲区中的数据再写入到通道                outChannel.write(buf);                //清空缓冲区                buf.clear();            &#125;        &#125; catch (IOException e) &#123;            e.printStackTrace();        &#125;finally &#123;            if ( outChannel != null) &#123;                try &#123;                    outChannel.close();                &#125; catch (IOException e) &#123;                    e.printStackTrace();                &#125;            &#125;            if (inChannel!=null) &#123;                try &#123;                    inChannel.close();                &#125; catch (IOException e) &#123;                    e.printStackTrace();                &#125;            &#125;            if (fos!=null) &#123;                try &#123;                    fos.close();                &#125; catch (IOException e) &#123;                    e.printStackTrace();                &#125;            &#125;            if (fis!=null) &#123;                try &#123;                    fis.close();                &#125; catch (IOException e) &#123;                    e.printStackTrace();                &#125;            &#125;        &#125;    &#125;&#125;\n\n//2.使用直接缓冲区完成文件的复制(内存映射文件的方式)public void test2() throws IOException &#123;    long start = System.currentTimeMillis();    FileChannel inChannel = FileChannel.open(Paths.get(\"1.jpg\"), StandardOpenOption.READ);    FileChannel outChannel = FileChannel.open(Paths.get(\"8.jpg\"), StandardOpenOption.WRITE, StandardOpenOption.READ, StandardOpenOption.CREATE_NEW);    //内存映射文件    MappedByteBuffer inMappedBuf = inChannel.map(MapMode.READ_ONLY, 0, inChannel.size());    MappedByteBuffer outMappedBuf = outChannel.map(MapMode.READ_WRITE, 0, inChannel.size());    //直接对缓冲区进行数据的读写操作    byte[] dst = new byte[inMappedBuf.limit()];    inMappedBuf.get(dst);    outMappedBuf.put(dst);    inChannel.close();    outChannel.close();    long end = System.currentTimeMillis();    System.out.println(\"内存映射文件所花时间：\"+(end-start));&#125;\n\n2.3.2 直接传输\ntransferFrom()\ntransferTo()\n\nRandomAccessFile fromFile = new RandomAccessFile(\"fromFile.txt\", \"rw\");// 获取FileChannelFileChannel fromChannel = fromFile.getChannel();RandomAccessFile toFile = new RandomAccessFile(\"toFile.txt\", \"rw\");FileChannel toChannel = toFile.getChannel();// 定义传输位置long position = 0L;// 最多传输的字节数long count = fromChannel.size();// 将数据从源通道传输到另一个通道toChannel.transferFrom(fromChannel, position, count);\n\n/**  * 通道之间的数据传输（直接缓冲区）  * @throws IOException  */public void test3() throws IOException &#123;    FileChannel inChannel = FileChannel.open(Paths.get(\"1.jpg\"), StandardOpenOption.READ);    FileChannel outChannel = FileChannel.open(Paths.get(\"9.jpg\"), StandardOpenOption.WRITE,StandardOpenOption.READ,StandardOpenOption.CREATE_NEW);    inChannel.transferTo(0, inChannel.size(), outChannel);    //outChannel.transferFrom(inChannel,0,inChannel.size());    inChannel.close();    outChannel.close();&#125;\n\n2.4 通道之间的内存映射\nJava IO操作中通常采用BufferedReader，BufferedInputStream等带缓冲的IO类处理大文件，不过Java NIO中引入了一种基于MappedByteBuffer操作大文件的方式，其读写性能极高\n\npublic void test2() throws IOException &#123;    long start = System.currentTimeMillis();    FileChannel inChannel = FileChannel.open(Paths.get(\"1.jpg\"), StandardOpenOption.READ);    FileChannel outChannel = FileChannel.open(Paths.get(\"8.jpg\"), StandardOpenOption.WRITE,StandardOpenOption.READ,StandardOpenOption.CREATE_NEW);    //内存映射文件    MappedByteBuffer inMappedBuf = inChannel.map(MapMode.READ_ONLY, 0, inChannel.size());    MappedByteBuffer outMappedBuf = outChannel.map(MapMode.READ_WRITE, 0, inChannel.size());    //直接对缓冲区进行数据的读写操作    byte[] dst = new byte[inMappedBuf.limit()];    inMappedBuf.get(dst);    outMappedBuf.put(dst);    inChannel.close();    outChannel.close();    long end = System.currentTimeMillis();    System.out.println(\"内存映射文件所花时间：\"+(end-start));&#125;\n\n3. 分散（Scatter）和聚集（Gather）分散读取（Scattering Reads）是指从Channel中读取的数据“分散”到多个Buffer中。\n聚集写入（Gathering Writes）是指将多个Buffer中的数据“聚集”到Channel。\n//分散和聚集public void test4() throws IOException&#123;    RandomAccessFile raf1 = new RandomAccessFile(\"1.txt\", \"rw\");    //1. 获取通道    FileChannel channel1 = raf1.getChannel();    //2. 分配指定大小的缓冲区    ByteBuffer buf1 = ByteBuffer.allocate(100);    ByteBuffer buf2 = ByteBuffer.allocate(1024);    //3. 分散读取    ByteBuffer[] bufs = &#123;buf1, buf2&#125;;    channel1.read(bufs);    for (ByteBuffer byteBuffer : bufs) &#123;        byteBuffer.flip();    &#125;    System.out.println(new String(bufs[0].array(), 0, bufs[0].limit()));    System.out.println(\"-----------------\");    System.out.println(new String(bufs[1].array(), 0, bufs[1].limit()));    //4. 聚集写入    RandomAccessFile raf2 = new RandomAccessFile(\"2.txt\", \"rw\");    FileChannel channel2 = raf2.getChannel();    channel2.write(bufs);&#125;\n\n4. 阻塞与非阻塞\n传统的IO流都是阻塞式的。也就是说，当一个线程调用read()或write()时，该线程被阻塞，直到有一些数据被读取或写入，该线程在此期间不能执行其他任务。因此，在完成网络通信进行IO操作时，由于线程会阻塞，所以服务器端必须为每个客户端都提供一个独立的线程进行处理，当服务器端需要处理大量客户端时，性能急剧下降。\nJava NIO是非阻塞模式的。当线程从某通道进行读写数据时，若没有数据可用时，该线程可以进行其他任务。线程通常将非阻塞IO的空闲时间用于在其他通道上执行IO操作，所以单独的线程可以管理多个输入和输出通道。因此，NIO可以让服务器端使用一个或有限几个线程来同时处理连接到服务器端的所有客户端。\n\n5. 选择器（Selector）选择器（Selector）是SelectableChannel对象的多路复用器，Selector可以同时监控多个SelectableChannel的IO状况，也就是说，利用Selector可使一个单独的线程管理多个Channel。Selector是非阻塞IO的核心。\n\n5.1 选择器的使用\n创建Selector：通过调用Selector.open()方法创建一个Selector\n\n//创建一个选择器，并把SocketChannel交给selector对象Selector selector = Selector.open();\n\n\n向选择器注册通道\n\n// 创建一个Socket套接字Socket socket = new Socket(InetAddress.getByName(\"127.0.0.1\"), 8888);// 获取SocketChannelSocketChannel channel = socket.getChannel();// 创建选择器Selector selector = Selector.open();// 将SocketChannel切换到非阻塞模式channel.configureBlocking(false);// 向Selector注释Channelchannel.register(selector, SelectionKey.OP_ACCEPT);\n\n当调用register(Selector sel, int ops)给通道注册选择器时，需要设置选择监听的事件类型，通过第二个参数ops指定。\n可以监听的事件类型（可使用SelectionKey的四个常量表示）：\n\n读：SelectionKey.OP_READ(1 &lt;&lt; 0 : 1)\n\n写：SelectionKey.OP_WRITE(1 &lt;&lt; 2 : 4)\n\n连接：SelectionKey.OP_CONNECT(1 &lt;&lt; 3 : 8)\n\n接受：SelectionKey.OP_ACCEPT(1&lt;&lt;4 : 16)\n\n\n若注册时不止监听一个事件，则可以使用“位或”操作符连接。\nint interestSet = SelectionKey.OP_READ | SelectionKey.OP_WRITE;\n\n5.2 选择键（SelectionKey）\n表示SelectableChannel和Selector之间的注册关系。\n\n\n\n\n方法\n描述\n\n\n\nint interestOps()\n获取感兴趣事件集合\n\n\nint readyOps()\n获取通道已经准备就绪的操作的集合\n\n\nSelectableChannel channel()\n获取注册通道\n\n\nSelector selector()\n返回选择器\n\n\nboolean isReadable()\n检测Channel中读事件是否就绪\n\n\nboolean isWritable()\n检测Channel中写事件是否就绪\n\n\nboolean isConnectable()\n检测Channel中连接是否就绪\n\n\nboolean isConnectable()\n检测Channel中接收是否就绪\n\n\nObject attach(Object ob)\n将给定的对象附加到此键\n\n\nObject attachment()\n获取当前的附加对象\n\n\nselectionKey.attach(theObject);Object attachedObj = selectionKey.attachment();\n\n5.3 选择器（Selector）的常用方法\n\n\n方法\n描述\n\n\n\nSet&lt;SelectionKey&gt; keys()\n所有的SelectionKey集合。代表注册在该Selector上的Channel\n\n\nSet&lt;SelectionKey&gt; selectedKeys()\n被选择的SelectionKey集合。返回次Selector的已选择键集\n\n\nint select()\n监控所有注册的Channel，当它们中间有需要处理的IO操作时，根据设置SelectionKey的集合，返回符合匹配的Channel的数量\n\n\nint select(long timeout)\n可以设置超时时长的select()操作\n\n\nint selectNow()\n执行一个立即返回的select()操作，该方法不会阻塞线程\n\n\nSelector wakeup()\n使一个还未返回的select()操作方法立即返回\n\n\nvoid close()\n关闭该选择器\n\n\n6. 管道（Pipe）\nJava NIO管道是2个线程之间的单向数据连接。Pipe有一个source通道和一个sink通道。数据会被写到sink通道，从source通道读取。\n\n\n向管道写数据\n\npublic void write(String str) throws IOException &#123;    // 创建管道    Pipe pipe = Pipe.open();    // 向管道写输入    Pipe.SinkChannel sink = pipe.sink();    // 通过sink的write()方法写数据    ByteBuffer buf = ByteBuffer.allocate(1024);    buf.clear();    buf.put(str.getBytes());    buf.flip();    while (buf.hasRemaining()) &#123;        sink.write(buf);    &#125;&#125;\n\n\n从管道读数据\n\npublic void read(Pipe pipe) throws IOException &#123;    Pipe.SourceChannel source = pipe.source();    ByteBuffer buffer = ByteBuffer.allocate(1024);    source.read(buffer);&#125;\n\n7. Path与Paths\njava.nio.file.Path接口代表一个平台无关的平台路径，描述了目录结构中文件的位置\n\nPaths提供get()方法用来获取Path对象\nPath get(String first, String... more)：用于将多个字符串连接成路径\n\nPath常用方法：\nboolean endsWith(String other)：判断是否以other路径结束\nboolean startsWith(String other)：判断是否以other路径开始\nboolean isAbsolute()：判断是否是绝对路径\nPath getFileName()：返回与调用Path对象关联的文件名\nPath getName(int index)：返回的指定索引位置index的路径名称\nint getNameCount()：返回Path根目录后面元素的数量\nPath getParent()：返回Path对象包含整个路径，不包含Path对象指定的文件路径\nPath getRoot()：返回调用Path对象的根路径\nPath resolve(String other)：将相对路径解析为绝对路径\nPath toAbsolutePath()：作为绝对路径返回调用Path对象\nString toString()：返回调用Path对象的字符串表示形式\n\n\n8. Files类\njava.nio.file.Files用于操作文件或目录的工具类\n\n\nFiles常用方法：\n\ncopy(InputStream in, Path target, CopyOption... options)：文件的复制\nPath createDirectory(Path dir, FileAttribute&lt;?&gt;... attrs)：创建一个目录\nPath createFile(Path path, FileAttribute&lt;?&gt;... attrs)：创建一个文件\nvoid delete(Path path)：删除一个文件\nPath move(Path source, Path target, CopyOption... options)：将src移动到target位置\nlong size(Path path)：返回指定文件的大小\n\n用于判断\n\nboolean exists(Path path, LinkOption... options)：判断文件是否存在\nboolean isDirectory(Path path, LinkOption... options)：判断是否是目录\nboolean isExecutable(Path path)：判断是否是可执行文件\nboolean isHidden(Path path)：判断是否是隐藏文件\nboolean isReadable(Path path)：判断是否是可读\nboolean isWritable(Path path)：判断是否是可写\nboolean notExists(Path path, LinkOption... options)：判断文件是否不存在\n&lt;A extends BasicFileAttributes&gt; A readAttributes(Path path, Class&lt;A&gt; type, LinkOption... options)：获取与path指定的文件相关联的属性\n\n用于操作内容\n\nSeekableByteChannel newByteChannel(Path path, OpenOption... options)：获取与指定文件的连接，options指定打开方式\nDirectoryStream&lt;Path&gt; newDirectoryStream(Path dir)：打开path指定的目录\nInputStream newInputStream(Path path, OpenOption... options)：获取InputStream对象\nOutputStream newOutputStream(Path path, OpenOption... options)：获取OutputStream对象\n","tags":["Java","NIO"]},{"title":"Linux常用命令","url":"/2019/10/22/Linux%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/","content":"常用技巧修改YUM源为国内源修改为阿里yum源-mirrors.aliyun.com\n\n1、首先备份系统自带yum源配置文件/etc/yum.repos.d/CentOS-Base.repo\n\nmv /etc/yum.repos.d/CentOS-Base.repo /etc/yum.repos.d/CentOS-Base.repo.backup\n\n\n2、查看CentOS系统版本\n\nlsb_release -a\n\n\n3、下载ailiyun的yum源配置文件到/etc/yum.repos.d/\n\n# CentOS 5wget -O /etc/yum.repos.d/CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-5.repo# CentOS 6wget -O /etc/yum.repos.d/CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-6.repo# CentOS 7wget -O /etc/yum.repos.d/CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-7.repo\n\n\n4、清理缓存\n\nyum clean all\n\n\n5、重新生成缓存\n\nyum makecache\n\n\n6、验证\n\nyum repolist\n\n查看磁盘占用du -sh *du -sh /var/lib/mysql\n\n查看Linux版本cat /etc/centos-releasecat /proc/versionuname -acat /etc/issue# 查看位数getconf LONG_BIT\n\n# 可以查看所有用户的列表cat /etc/passwd# 查看用户组cat /etc/group# 查看当前登录用户的组内成员groups# 查看gliethttp用户所在的组,以及组内成员groups gliethttp# 查看当前登录用户名whoami\n\n查看支持的Shell类型cat /etc/shells# 切换zsh模式chsh -s /bin/zsh\n\n修改IP# 通过修改配置文件vim /etc/sysconfig/network-scripts/ifcfg-eth0# 重启网络service network restart# 查看改动后的效果ip addr\n\n命令传参符号：``名称：反引号，上分隔符\n位置：反引号（`）这个字符一般在键盘的左上角，数字1的左边，不要将其同单引号（’）混淆\n作用：反引号括起来的字符串被shell解释为命令行，在执行时，shell首先执行该命令行，并以它的标准输出结果取代整个反引号（包括两个反引号）部分\n举例：\necho `rpm -qa|grep java`\n\n命令：xargsxargs是给命令传递参数的一个过滤器，也是组合多个命令的一个工具。它把一个数据流分割为一些足够小的块，以方便过滤器和命令进行处理。\n通常情况下，xargs从管道或者stdin中读取数据，但是它也能够从文件的输出中读取数据。\nxargs的默认命令是echo，这意味着通过管道传递给xargs的输入将会包含换行和空白，不过通过xargs的处理，换行和空白将被空格取代。\n举例：\nrpm -qa|grep java |xargs echo\n\n命令：awk就是把文件逐行的读入，以空格为默认分隔符将每行切片，切开的部分再进行各种分析处理。\nrpm -qa|grep java|awk '&#123;print $1&#125;'\n\n文件句柄数量查看Linux系统默认的最大文件句柄数，系统默认是1024\n查看Linux系统某个进程打开的文件句柄数量\nlsof -n | grep 5950 -c\n\n修改Linux系统的最大文件句柄数限制的方法：\n\nulimit -n 65535\n\n针对当前session有效，用户退出或者系统重新后恢复默认值\n\n修改profile文件：在profile文件中添加：ulimit -n 65535\n\n只对单个用户有效\n\n修改文件：/etc/security/limits.conf，在文件中添加：（立即生效-当前session中运行ulimit -a命令无法显示）\n\nsoft nofile 32768 #限制单个进程最大文件句柄数（到达此限制时系统报警）\n\nhard nofile 65536 #限制单个进程最大文件句柄数（到达此限制时系统报错）\n\n修改文件：/etc/sysctl.conf。在文件中添加：\n\nfs.file-max=655350 #限制整个系统最大文件句柄数\n\n\n运行命令：/sbin/sysctl -p 使配置生效\n某某人的心得#!/bin/bashsed -i 's/SELINUX=enforcing/SELINUX=disabled/g' /etc/selinux/config  #关闭selinuxsed -i 's/#GSSAPIAuthentication yes/GSSAPIAuthentication no/g' /etc/ssh/sshd_configsed -i 's/#UseDNS yes/UseDNS no/g' /etc/ssh/sshd_configsed -i 's/BOOTPROTO=\"dhcp\"/BOOTPROTO=\"static\"/g' /etc/sysconfig/network-scripts/ifcfg-eth0echo \"IPADDR='192.168.99.2'\"  &gt;&gt; /etc/sysconfig/network-scripts/ifcfg-eth0echo \"PREFIX=21\" &gt;&gt; /etc/sysconfig/network-scripts/ifcfg-eth0echo \"GATEWAY='192.168.100.1'\" &gt;&gt; /etc/sysconfig/network-scripts/ifcfg-eth0echo \"DNS1='219.141.136.10'\" &gt;&gt; /etc/sysconfig/network-scripts/ifcfg-eth0systemctl set-default multi-user.targetsystemctl stop firewalld.servicesystemctl disable firewalld.service\n\n命令文档useradd用法：useradd [选项] 登录      useradd -D      useradd -D [选项]选项：  -b, --base-dir BASE_DIR       新账户的主目录的基目录  -c, --comment COMMENT         新账户的 GECOS 字段  -d, --home-dir HOME_DIR       新账户的主目录  -D, --defaults                显示或更改默认的 useradd 配置  -e, --expiredate EXPIRE_DATE  新账户的过期日期  -f, --inactive INACTIVE       新账户的密码不活动期  -g, --gid GROUP               新账户主组的名称或 ID  -G, --groups GROUPS   \t\t新账户的附加组列表  -h, --help                    显示此帮助信息并推出  -k, --skel SKEL_DIR   \t\t使用此目录作为骨架目录  -K, --key KEY=VALUE           不使用 /etc/login.defs 中的默认值  -l, --no-log-init     \t\t不要将此用户添加到最近登录和登录失败数据库  -m, --create-home     \t\t创建用户的主目录  -M, --no-create-home          不创建用户的主目录  -N, --no-user-group   \t\t不创建同名的组  -o, --non-unique              允许使用重复的 UID 创建用户  -p, --password PASSWORD       加密后的新账户密码  -r, --system                  创建一个系统账户  -R, --root CHROOT_DIR         chroot 到的目录  -P, --prefix PREFIX_DIR       prefix directory where are located the /etc/* files  -s, --shell SHELL             新账户的登录 shell  -u, --uid UID                 新账户的用户 ID  -U, --user-group              创建与用户同名的组  -Z, --selinux-user SEUSER     为 SELinux 用户映射使用指定 SEUSER\n\nuserdel用法：userdel [选项] 登录选项：  -f, --force                   force some actions that would fail otherwise                                e.g. removal of user still logged in                                or files, even if not owned by the user  -h, --help                    显示此帮助信息并推出  -r, --remove                  删除主目录和邮件池  -R, --root CHROOT_DIR         chroot 到的目录  -P, --prefix PREFIX_DIR       prefix directory where are located the /etc/* files  -Z, --selinux-user            为用户删除所有的 SELinux 用户映射\n\nvim\nset nu    显示行号gg     跳转到文件开头&#x2F;     向后搜索?    向前搜索n    查找下一处N    查找上一处|     光标所在行行首L    屏幕所显示的底行&#123;    段首&#125;    段尾-    前一行行首+    后一行行首(    句首)    下一句首$    行末M    屏幕中间行0    行首（零）hjkl    左下上右x    删除光标所在字符R    替换模式（可以替换任意字符）r    单个替换dd     删除光标所在的行D    删除至行末（从光标位置开始）s    删除字符并插入（单个字符删除，并进入插入模式）S    删除行并插入（整行删除）&gt;&gt;     缩进（相当于一个tab）&lt;&lt;     反缩进&#x3D;    自动格式化J    合并上下两行I    插入到行首i     插入C    从光标处开始修改至行位a    在光标后附件或追加A    在行末追加p    粘贴（后）P    粘贴（前）Esc     命令模式ZZ     保存退出编辑(vi，含保存)ZQ    不保存退出编辑\n\n\n指定IP\nIPADDR=192.168.0.230 #静态IPGATEWAY=192.168.0.1 #默认网关NETMASK=255.255.255.0 #子网掩码DNS1=192.168.0.1 #DNS 配置DNS2=8.8.8.8\n\n自动获取IP\nBOOTPROTO=dhcpONBOOT=yes\nchmod\n\nchmod 更改权限o 所有者 g 组 o 其他r--4 w--2 x--1-R 处理指定目录以及其子目录下的所有文件chmod u+x,g+x index.htmlchmod 755 index.htmlchmod -R o+x fa\n\nchownchown 将指定文件的拥有者改为指定的用户或组chown [选项]... [所有者][:[组]] 文件...-R 处理指定目录以及其子目录下的所有文件chown weblogic:bea index.htmlchown -R weblogic:bea test1\n\nlsof# 查看使用某端口的进程lsof -i:8090netstat -ap|grep 8090# 查看到进程id之后，使用netstat命令查看其占用的端口netstat -nap|grep 7779# 查看PIDps -aux|grep chat.js| grep -v grep | awk '&#123;print $2&#125;'\n\nnohupnohup 加 &amp;大家都知道是后台运行并把stdout输出到文件nohup.out中。其实&amp;是后台运行的命令。一般都是在linux下nohup格式：nohup command_line或者nohup command_line &amp;这之间的差别是带&amp;的命令行，即使terminal关闭，或者电脑死机程序依然运行（前提是你把程序递交到服务器上）；它把标准输出（STDOUT）和标准错误（STDERR）结果输出到nohup.txt文件这个看似很方便，但是当输出很大的时候，nohup.txt文件会非常大，或者多个后台命令的时候大家都会输出到nohup.txt文件，不利于查找结果和调试程序。所以能够重定向输出会非常方便。下面要介绍标准输出，标准输入 和标准错误了。其实我门一直都在用，只是没有注意到，比如\\&gt;.&#x2F;command.sh &gt; output\\#这其中的&gt;就是标准输出符号，其实是 1&gt;output 的缩写\\&gt;.&#x2F;command.sh 2&gt; output＃这里的2&gt;就是将标准错误输出到output文件里。而0&lt; 则是标准输入了。下面步入正题，重定向后台命令\\&gt;nohup .&#x2F;command.sh &gt; output 2&gt;&amp;1 &amp;ls xxx &gt;out.txt 2&gt;&amp;1, 实际上可换成 ls xxx 1&gt;out.txt 2&gt;&amp;1；重定向符号&gt;默认是1,错误和输出都传到out.txt了。解释：前面的nohup 和后面的&amp;我想大家都能明白了把。主要是中间的 2&gt;&amp;1的意思这个意思是把标准错误（2）重定向到标准输出中（1），而标准输出又导入文件output里面，所以结果是标准错误和标准输出都导入文件output里面了。至于为什么需要将标准错误重定向到标准输出的原因，那就归结为标准错误没有缓冲区，而stdout有。这就会导致 &gt;output 2&gt;output 文件output被两次打开，而stdout和stderr将会竞争覆盖，这肯定不是我门想要的.这就是为什么有人会写成：nohup .&#x2F;command.sh &gt;output 2&gt;output出错的原因了\\##########################最后谈一下&#x2F;dev&#x2F;null文件的作用这是一个无底洞，任何东西都可以定向到这里，但是却无法打开。所以一般很大的stdou和stderr当你不关心的时候可以利用stdout和stderr定向到这里&gt;.&#x2F;command.sh &gt;&#x2F;dev&#x2F;null 2&gt;&amp;1\n\nps\nps -aux\n\nUSER: 行程拥有者PID: pid%CPU: 占用的 CPU 使用率%MEM: 占用的内存使用率VSZ: 占用的虚拟内存大小，申请内存值RSS: 占用的内存大小 ，实际使用的物理内存TTY: 终端的次要装置号码 (minor device number of tty)STAT: 该行程的状态:D: 不可中断的静止 (通悸□□缜b进行 I/O 动作)R: 正在执行中S: 静止状态T: 暂停执行Z: 不存在但暂时无法消除W: 没有足够的内存分页可分配&lt;: 高优先序的行程N: 低优先序的行程L: 有内存分页分配并锁在内存内 (实时系统或捱A I/O)START: 行程开始时间TIME: 执行的时间COMMAND:所执行的指令\n\n\nps aux | sort -k3nr |head -n 10 按照消耗CPU前10排序的进程\n\nps aux | sort -k4nr |head -n 10 按照消耗内存前10排序的进程\n\n\nsort [-bcdfimMnr][-o&lt;输出文件&gt;][-t&lt;分隔字符&gt;][+&lt;起始栏位&gt;-&lt;结束栏位&gt;][--help][--verison][文件]\n\n参数说明：\n\n-b 忽略每行前面开始出的空格字符。\n\n-c 检查文件是否已经按照顺序排序。\n\n-d 排序时，处理英文字母、数字及空格字符外，忽略其他的字符。\n\n-f 排序时，将小写字母视为大写字母。\n\n-i 排序时，除了040至176之间的ASCII字符外，忽略其他的字符。\n\n-m 将几个排序好的文件进行合并。\n\n-M 将前面3个字母依照月份的缩写进行排序。\n\n-n 依照数值的大小排序。\n\n-o&lt;输出文件&gt; 将排序后的结果存入指定的文件。\n\n-r 以相反的顺序来排序。\n\n-t&lt;分隔字符&gt; 指定排序时所用的栏位分隔字符。\n\n+&lt;起始栏位&gt;-&lt;结束栏位&gt; 以指定的栏位来排序，范围由起始栏位到结束栏位的前一栏位。\n\n–help 显示帮助。\n\n–version 显示版本信息。\n\n\nrpm\n安装\n\n# 安装 example.rpm 包rpm -i example.rpm# 安装 example.rpm 包并在安装过程中显示正在安装的文件信息rpm -iv example.rpm# 安装 example.rpm 包并在安装过程中显示正在安装的文件信息及安装进度rpm -ivh example.rpm\n\n\n卸载\n\nrpm -e --nodeps 要卸载的软件包\n\n\n查询系统已安装的软件\n\nrpm -q 软件名\n\n\n查看系统中所有已经安装的包\n\nrpm -qarpm -qa |morerpm -qa |grep abc\n\nrpm -qpl mysql-community-server-5.7.26-1.el7.x86_64.rpm\n\n\n查看安装包时间\n\nrpm -qi\n\n\n查看安装包路径\n\nrpm -ql\n\n\n按时间顺序列出rpm包\n\nrpm -q --all --last\n\ntartar filename.tar Dirname-c 创建新文件,-f 通常必选-v 操作过程显示到显示器-x 还原备份文件-r 追加文件到备份文件中-z 打包压缩---调用gzip#打包当前目录下的所有文件tar -cvf 20161226.tar *#还原tar包tar -xvf 20161226.tar#把file文件追加到tar中tar -rvf 2016.1226.tar file#打包后以gizp压缩tar -zcvf 20161226.tar.gz#解压缩tar -zxvf 20161226.tar.gz\n\nyum\n全称为 Yellow dog Updater Modified，它是一个在线的软件安装命令。\n\n# yum源配置路径/etc/yum.repos.d# 重新配置后需要生效yum cleancacheyum makecacheyum listyum list installedyum searchyum remove\n\nfirewall#查看所有打开的端口firewall-cmd --zone=public --list-ports#添加（--permanent永久生效，没有此参数重启后失效）firewall-cmd --zone=public --add-port=80/tcp --permanent#重新载入firewall-cmd --reload#查看firewall-cmd --zone=public --query-port=80/tcp#删除firewall-cmd --zone=public --remove-port=80/tcp --permanent#批量开放端口firewall-cmd --permanent --zone=public --add-port=100-500/tcpfirewall-cmd --permanent --zone=public --add-port=100-500/udpfirewall-cmd --reload\n\n# 查看防火状态systemctl status firewalldservice  iptables status# 暂时关闭防火墙systemctl stop firewalldservice  iptables stop# 永久关闭防火墙systemctl disable firewalldchkconfig iptables off# 重启防火墙systemctl enable firewalldservice iptables restart# 永久关闭后重启chkconfig iptables on\n\nwhichwhich命令的作用是在PATH变量指定的路径中搜索某个系统命令的位置并且返回第一个搜索结果。\nUsage: /usr/bin/which [options] [--] COMMAND [...]Write the full path of COMMAND(s) to standard output.--version, -[vV] Print version and exit successfully.--help,          Print this help and exit successfully.--skip-dot       Skip directories in PATH that start with a dot.--skip-tilde     Skip directories in PATH that start with a tilde.--show-dot       Don't expand a dot to current directory in output.--show-tilde     Output a tilde for HOME directory for non-root.--tty-only       Stop processing options on the right if not on tty.--all, -a        Print all matches in PATH, not just the first--read-alias, -i Read list of aliases from stdin.--skip-alias     Ignore option --read-alias; don't read stdin.--read-functions Read bash functions from stdin.--skip-functions Ignore option --read-functions; don't read stdin.Recommended use is to write the output of (alias; declare -f) to standardinput, so that which can show aliases and bash functions. See which(1) forexamples.If the options --read-alias and/or --read-functions are specified then theoutput can be a full alias or function definition, optionally followed bythe full path of each command used inside of those.Report bugs to &lt;which-bugs@gnu.org&gt;.\n\nhostnamectl\ncentos7\n\nhostnamectl [OPTIONS...] COMMAND ...Query or change system hostname.-h --help              Show this help--version           Show package version--no-ask-password   Do not prompt for password-H --host=[USER@]HOST  Operate on remote host-M --machine=CONTAINER Operate on local container--transient         Only set transient hostname--static            Only set static hostname--pretty            Only set pretty hostnameCommands:status                 Show current hostname settingsset-hostname NAME      Set system hostnameset-icon-name NAME     Set icon name for hostset-chassis NAME       Set chassis type for hostset-deployment NAME    Set deployment environment for hostset-location NAME      Set location for host\n\n例如：\nhostnamectl set-hostname namehostnamectl status\n\nwgetGNU Wget 1.14，非交互式的网络文件下载工具。用法： wget [选项]... [URL]...长选项所必须的参数在使用短选项时也是必须的。启动：-V,  --version           显示 Wget 的版本信息并退出。-h,  --help              打印此帮助。-b,  --background        启动后转入后台。-e,  --execute=COMMAND   运行一个“.wgetrc”风格的命令。日志和输入文件：-o,  --output-file=FILE    将日志信息写入 FILE。-a,  --append-output=FILE  将信息添加至 FILE。-d,  --debug               打印大量调试信息。-q,  --quiet               安静模式 (无信息输出)。-v,  --verbose             详尽的输出 (此为默认值)。-nv, --no-verbose          关闭详尽输出，但不进入安静模式。--report-speed=TYPE   Output bandwidth as TYPE.  TYPE can be bits.-i,  --input-file=FILE     下载本地或外部 FILE 中的 URLs。-F,  --force-html          把输入文件当成 HTML 文件。-B,  --base=URL            解析与 URL 相关的HTML 输入文件 (由 -i -F 选项指定)。--config=FILE         Specify config file to use.下载：-t,  --tries=NUMBER            设置重试次数为 NUMBER (0 代表无限制)。--retry-connrefused       即使拒绝连接也是重试。-O,  --output-document=FILE    将文档写入 FILE。-nc, --no-clobber              skip downloads that would download toexisting files (overwriting them).-c,  --continue                断点续传下载文件。--progress=TYPE           选择进度条类型。-N,  --timestamping            只获取比本地文件新的文件。--no-use-server-timestamps     不用服务器上的时间戳来设置本地文件。-S,  --server-response         打印服务器响应。--spider                  不下载任何文件。-T,  --timeout=SECONDS         将所有超时设为 SECONDS 秒。--dns-timeout=SECS        设置 DNS 查寻超时为 SECS 秒。--connect-timeout=SECS    设置连接超时为 SECS 秒。--read-timeout=SECS       设置读取超时为 SECS 秒。-w,  --wait=SECONDS            等待间隔为 SECONDS 秒。--waitretry=SECONDS       在获取文件的重试期间等待 1..SECONDS 秒。--random-wait             获取多个文件时，每次随机等待间隔0.5*WAIT...1.5*WAIT 秒。--no-proxy                禁止使用代理。-Q,  --quota=NUMBER            设置获取配额为 NUMBER 字节。--bind-address=ADDRESS    绑定至本地主机上的 ADDRESS (主机名或是 IP)。--limit-rate=RATE         限制下载速率为 RATE。--no-dns-cache            关闭 DNS 查寻缓存。--restrict-file-names=OS  限定文件名中的字符为 OS 允许的字符。--ignore-case             匹配文件/目录时忽略大小写。-4,  --inet4-only              仅连接至 IPv4 地址。-6,  --inet6-only              仅连接至 IPv6 地址。--prefer-family=FAMILY    首先连接至指定协议的地址FAMILY 为 IPv6，IPv4 或是 none。--user=USER               将 ftp 和 http 的用户名均设置为 USER。--password=PASS           将 ftp 和 http 的密码均设置为 PASS。--ask-password            提示输入密码。--no-iri                  关闭 IRI 支持。--local-encoding=ENC      IRI (国际化资源标识符) 使用 ENC 作为本地编码。--remote-encoding=ENC     使用 ENC 作为默认远程编码。--unlink                  remove file before clobber.目录：-nd, --no-directories           不创建目录。-x,  --force-directories        强制创建目录。-nH, --no-host-directories      不要创建主目录。--protocol-directories     在目录中使用协议名称。-P,  --directory-prefix=PREFIX  以 PREFIX/... 保存文件--cut-dirs=NUMBER          忽略远程目录中 NUMBER 个目录层。HTTP 选项：--http-user=USER        设置 http 用户名为 USER。--http-password=PASS    设置 http 密码为 PASS。--no-cache              不在服务器上缓存数据。--default-page=NAME     改变默认页(默认页通常是“index.html”)。-E,  --adjust-extension      以合适的扩展名保存 HTML/CSS 文档。--ignore-length         忽略头部的‘Content-Length’区域。--header=STRING         在头部插入 STRING。--max-redirect          每页所允许的最大重定向。--proxy-user=USER       使用 USER 作为代理用户名。--proxy-password=PASS   使用 PASS 作为代理密码。--referer=URL           在 HTTP 请求头包含‘Referer: URL’。--save-headers          将 HTTP 头保存至文件。-U,  --user-agent=AGENT      标识为 AGENT 而不是 Wget/VERSION。--no-http-keep-alive    禁用 HTTP keep-alive (永久连接)。--no-cookies            不使用 cookies。--load-cookies=FILE     会话开始前从 FILE 中载入 cookies。--save-cookies=FILE     会话结束后保存 cookies 至 FILE。--keep-session-cookies  载入并保存会话 (非永久) cookies。--post-data=STRING      使用 POST 方式；把 STRING 作为数据发送。--post-file=FILE        使用 POST 方式；发送 FILE 内容。--content-disposition   当选中本地文件名时允许 Content-Disposition 头部 (尚在实验)。--content-on-error      output the received content on server errors.--auth-no-challenge     发送不含服务器询问的首次等待的基本 HTTP 验证信息。HTTPS (SSL/TLS) 选项：--secure-protocol=PR     choose secure protocol, one of auto, SSLv2,SSLv3, TLSv1, TLSv1_1 and TLSv1_2.--no-check-certificate   不要验证服务器的证书。--certificate=FILE       客户端证书文件。--certificate-type=TYPE  客户端证书类型，PEM 或 DER。--private-key=FILE       私钥文件。--private-key-type=TYPE  私钥文件类型，PEM 或 DER。--ca-certificate=FILE    带有一组 CA 认证的文件。--ca-directory=DIR       保存 CA 认证的哈希列表的目录。--random-file=FILE       带有生成 SSL PRNG 的随机数据的文件。--egd-file=FILE          用于命名带有随机数据的 EGD 套接字的文件。FTP 选项：--ftp-user=USER         设置 ftp 用户名为 USER。--ftp-password=PASS     设置 ftp 密码为 PASS。--no-remove-listing     不要删除‘.listing’文件。--no-glob               不在 FTP 文件名中使用通配符展开。--no-passive-ftp        禁用“passive”传输模式。--preserve-permissions  保留远程文件的权限。--retr-symlinks         递归目录时，获取链接的文件 (而非目录)。WARC options:--warc-file=FILENAME      save request/response data to a .warc.gz file.--warc-header=STRING      insert STRING into the warcinfo record.--warc-max-size=NUMBER    set maximum size of WARC files to NUMBER.--warc-cdx                write CDX index files.--warc-dedup=FILENAME     do not store records listed in this CDX file.--no-warc-compression     do not compress WARC files with GZIP.--no-warc-digests         do not calculate SHA1 digests.--no-warc-keep-log        do not store the log file in a WARC record.--warc-tempdir=DIRECTORY  location for temporary files created by theWARC writer.递归下载：-r,  --recursive          指定递归下载。-l,  --level=NUMBER       最大递归深度 (inf 或 0 代表无限制，即全部下载)。--delete-after       下载完成后删除本地文件。-k,  --convert-links      让下载得到的 HTML 或 CSS 中的链接指向本地文件。--backups=N   before writing file X, rotate up to N backup files.-K,  --backup-converted   在转换文件 X 前先将它备份为 X.orig。-m,  --mirror             -N -r -l inf --no-remove-listing 的缩写形式。-p,  --page-requisites    下载所有用于显示 HTML 页面的图片之类的元素。--strict-comments    用严格方式 (SGML) 处理 HTML 注释。递归接受/拒绝：-A,  --accept=LIST               逗号分隔的可接受的扩展名列表。-R,  --reject=LIST               逗号分隔的要拒绝的扩展名列表。--accept-regex=REGEX        regex matching accepted URLs.--reject-regex=REGEX        regex matching rejected URLs.--regex-type=TYPE           regex type (posix|pcre).-D,  --domains=LIST              逗号分隔的可接受的域列表。--exclude-domains=LIST      逗号分隔的要拒绝的域列表。--follow-ftp                跟踪 HTML 文档中的 FTP 链接。--follow-tags=LIST          逗号分隔的跟踪的 HTML 标识列表。--ignore-tags=LIST          逗号分隔的忽略的 HTML 标识列表。-H,  --span-hosts                递归时转向外部主机。-L,  --relative                  只跟踪有关系的链接。-I,  --include-directories=LIST  允许目录的列表。--trust-server-names             use the name specified by the redirectionurl last component.-X,  --exclude-directories=LIST  排除目录的列表。-np, --no-parent                 不追溯至父目录。\n\ncurlUsage: curl [options...] &lt;url&gt;Options: (H) means HTTP/HTTPS only, (F) means FTP only--anyauth       Pick \"any\" authentication method (H)-a, --append        Append to target file when uploading (F/SFTP)--basic         Use HTTP Basic Authentication (H)--cacert FILE   CA certificate to verify peer against (SSL)--capath DIR    CA directory to verify peer against (SSL)-E, --cert CERT[:PASSWD] Client certificate file and password (SSL)--cert-type TYPE Certificate file type (DER/PEM/ENG) (SSL)--ciphers LIST  SSL ciphers to use (SSL)--compressed    Request compressed response (using deflate or gzip)-K, --config FILE   Specify which config file to read--connect-timeout SECONDS  Maximum time allowed for connection-C, --continue-at OFFSET  Resumed transfer offset-b, --cookie STRING/FILE  String or file to read cookies from (H)-c, --cookie-jar FILE  Write cookies to this file after operation (H)--create-dirs   Create necessary local directory hierarchy--crlf          Convert LF to CRLF in upload--crlfile FILE  Get a CRL list in PEM format from the given file-d, --data DATA     HTTP POST data (H)--data-ascii DATA  HTTP POST ASCII data (H)--data-binary DATA  HTTP POST binary data (H)--data-urlencode DATA  HTTP POST data url encoded (H)--delegation STRING GSS-API delegation permission--digest        Use HTTP Digest Authentication (H)--disable-eprt  Inhibit using EPRT or LPRT (F)--disable-epsv  Inhibit using EPSV (F)-D, --dump-header FILE  Write the headers to this file--egd-file FILE  EGD socket path for random data (SSL)--engine ENGINGE  Crypto engine (SSL). \"--engine list\" for list-f, --fail          Fail silently (no output at all) on HTTP errors (H)-F, --form CONTENT  Specify HTTP multipart POST data (H)--form-string STRING  Specify HTTP multipart POST data (H)--ftp-account DATA  Account data string (F)--ftp-alternative-to-user COMMAND  String to replace \"USER [name]\" (F)--ftp-create-dirs  Create the remote dirs if not present (F)--ftp-method [MULTICWD/NOCWD/SINGLECWD] Control CWD usage (F)--ftp-pasv      Use PASV/EPSV instead of PORT (F)-P, --ftp-port ADR  Use PORT with given address instead of PASV (F)--ftp-skip-pasv-ip Skip the IP address for PASV (F)--ftp-pret      Send PRET before PASV (for drftpd) (F)--ftp-ssl-ccc   Send CCC after authenticating (F)--ftp-ssl-ccc-mode ACTIVE/PASSIVE  Set CCC mode (F)--ftp-ssl-control Require SSL/TLS for ftp login, clear for transfer (F)-G, --get           Send the -d data with a HTTP GET (H)-g, --globoff       Disable URL sequences and ranges using &#123;&#125; and []-H, --header LINE   Custom header to pass to server (H)-I, --head          Show document info only-h, --help          This help text--hostpubmd5 MD5  Hex encoded MD5 string of the host public key. (SSH)-0, --http1.0       Use HTTP 1.0 (H)--ignore-content-length  Ignore the HTTP Content-Length header-i, --include       Include protocol headers in the output (H/F)-k, --insecure      Allow connections to SSL sites without certs (H)--interface INTERFACE  Specify network interface/address to use-4, --ipv4          Resolve name to IPv4 address-6, --ipv6          Resolve name to IPv6 address-j, --junk-session-cookies Ignore session cookies read from file (H)--keepalive-time SECONDS  Interval between keepalive probes--key KEY       Private key file name (SSL/SSH)--key-type TYPE Private key file type (DER/PEM/ENG) (SSL)--krb LEVEL     Enable Kerberos with specified security level (F)--libcurl FILE  Dump libcurl equivalent code of this command line--limit-rate RATE  Limit transfer speed to this rate-l, --list-only     List only names of an FTP directory (F)--local-port RANGE  Force use of these local port numbers-L, --location      Follow redirects (H)--location-trusted like --location and send auth to other hosts (H)-M, --manual        Display the full manual--mail-from FROM  Mail from this address--mail-rcpt TO  Mail to this receiver(s)--mail-auth AUTH  Originator address of the original email--max-filesize BYTES  Maximum file size to download (H/F)--max-redirs NUM  Maximum number of redirects allowed (H)-m, --max-time SECONDS  Maximum time allowed for the transfer--metalink      Process given URLs as metalink XML file--negotiate     Use HTTP Negotiate Authentication (H)-n, --netrc         Must read .netrc for user name and password--netrc-optional Use either .netrc or URL; overrides -n--netrc-file FILE  Set up the netrc filename to use-N, --no-buffer     Disable buffering of the output stream--no-keepalive  Disable keepalive use on the connection--no-sessionid  Disable SSL session-ID reusing (SSL)--noproxy       List of hosts which do not use proxy--ntlm          Use HTTP NTLM authentication (H)-o, --output FILE   Write output to &lt;file&gt; instead of stdout--pass PASS     Pass phrase for the private key (SSL/SSH)--post301       Do not switch to GET after following a 301 redirect (H)--post302       Do not switch to GET after following a 302 redirect (H)--post303       Do not switch to GET after following a 303 redirect (H)-#, --progress-bar  Display transfer progress as a progress bar--proto PROTOCOLS  Enable/disable specified protocols--proto-redir PROTOCOLS  Enable/disable specified protocols on redirect-x, --proxy [PROTOCOL://]HOST[:PORT] Use proxy on given port--proxy-anyauth Pick \"any\" proxy authentication method (H)--proxy-basic   Use Basic authentication on the proxy (H)--proxy-digest  Use Digest authentication on the proxy (H)--proxy-negotiate Use Negotiate authentication on the proxy (H)--proxy-ntlm    Use NTLM authentication on the proxy (H)-U, --proxy-user USER[:PASSWORD]  Proxy user and password--proxy1.0 HOST[:PORT]  Use HTTP/1.0 proxy on given port-p, --proxytunnel   Operate through a HTTP proxy tunnel (using CONNECT)--pubkey KEY    Public key file name (SSH)-Q, --quote CMD     Send command(s) to server before transfer (F/SFTP)--random-file FILE  File for reading random data from (SSL)-r, --range RANGE   Retrieve only the bytes within a range--raw           Do HTTP \"raw\", without any transfer decoding (H)-e, --referer       Referer URL (H)-J, --remote-header-name Use the header-provided filename (H)-O, --remote-name   Write output to a file named as the remote file--remote-name-all Use the remote file name for all URLs-R, --remote-time   Set the remote file's time on the local output-X, --request COMMAND  Specify request command to use--resolve HOST:PORT:ADDRESS  Force resolve of HOST:PORT to ADDRESS--retry NUM   Retry request NUM times if transient problems occur--retry-delay SECONDS When retrying, wait this many seconds between each--retry-max-time SECONDS  Retry only within this period-S, --show-error    Show error. With -s, make curl show errors when they occur-s, --silent        Silent mode. Don't output anything--socks4 HOST[:PORT]  SOCKS4 proxy on given host + port--socks4a HOST[:PORT]  SOCKS4a proxy on given host + port--socks5 HOST[:PORT]  SOCKS5 proxy on given host + port--socks5-basic  Enable username/password auth for SOCKS5 proxies--socks5-gssapi Enable GSS-API auth for SOCKS5 proxies--socks5-hostname HOST[:PORT] SOCKS5 proxy, pass host name to proxy--socks5-gssapi-service NAME  SOCKS5 proxy service name for gssapi--socks5-gssapi-nec  Compatibility with NEC SOCKS5 server-Y, --speed-limit RATE  Stop transfers below speed-limit for 'speed-time' secs-y, --speed-time SECONDS  Time for trig speed-limit abort. Defaults to 30--ssl           Try SSL/TLS (FTP, IMAP, POP3, SMTP)--ssl-reqd      Require SSL/TLS (FTP, IMAP, POP3, SMTP)-2, --sslv2         Use SSLv2 (SSL)-3, --sslv3         Use SSLv3 (SSL)--ssl-allow-beast Allow security flaw to improve interop (SSL)--stderr FILE   Where to redirect stderr. - means stdout--tcp-nodelay   Use the TCP_NODELAY option-t, --telnet-option OPT=VAL  Set telnet option--tftp-blksize VALUE  Set TFTP BLKSIZE option (must be &gt;512)-z, --time-cond TIME  Transfer based on a time condition-1, --tlsv1         Use =&gt; TLSv1 (SSL)--tlsv1.0       Use TLSv1.0 (SSL)--tlsv1.1       Use TLSv1.1 (SSL)--tlsv1.2       Use TLSv1.2 (SSL)--tlsv1.3       Use TLSv1.3 (SSL)--tls-max VERSION  Use TLS up to VERSION (SSL)--trace FILE    Write a debug trace to the given file--trace-ascii FILE  Like --trace but without the hex output--trace-time    Add time stamps to trace/verbose output--tr-encoding   Request compressed transfer encoding (H)-T, --upload-file FILE  Transfer FILE to destination--url URL       URL to work with-B, --use-ascii     Use ASCII/text transfer-u, --user USER[:PASSWORD]  Server user and password--tlsuser USER  TLS username--tlspassword STRING TLS password--tlsauthtype STRING  TLS authentication type (default SRP)--unix-socket FILE    Connect through this UNIX domain socket-A, --user-agent STRING  User-Agent to send to server (H)-v, --verbose       Make the operation more talkative-V, --version       Show version number and quit-w, --write-out FORMAT  What to output after completion--xattr        Store metadata in extended file attributes-q                 If used as the first parameter disables .curlrc\n","tags":["Linux"]}]